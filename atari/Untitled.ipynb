{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://deeplearningcourses.com/c/deep-reinforcement-learning-in-python\n",
    "# https://www.udemy.com/deep-reinforcement-learning-in-python\n",
    "from __future__ import print_function, division\n",
    "from builtins import range\n",
    "# Note: you may need to update your version of future\n",
    "# sudo pip install -U future\n",
    "\n",
    "import copy\n",
    "import gym\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from gym import wrappers\n",
    "from datetime import datetime\n",
    "from scipy.misc import imresize\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##### testing only\n",
    "# MAX_EXPERIENCES = 10000\n",
    "# MIN_EXPERIENCES = 1000\n",
    "\n",
    "\n",
    "MAX_EXPERIENCES = 500000\n",
    "MIN_EXPERIENCES = 50000\n",
    "TARGET_UPDATE_PERIOD = 10000\n",
    "IM_SIZE = 80\n",
    "K = 4 #env.action_space.n\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def downsample_image(A):\n",
    "  B = A[31:195] # select the important parts of the image\n",
    "  B = B.mean(axis=2) # convert to grayscale\n",
    "\n",
    "  # downsample image\n",
    "  # changing aspect ratio doesn't significantly distort the image\n",
    "  # nearest neighbor interpolation produces a much sharper image\n",
    "  # than default bilinear\n",
    "  B = imresize(B, size=(IM_SIZE, IM_SIZE), interp='nearest')\n",
    "  return B\n",
    "\n",
    "\n",
    "def update_state(state, obs):\n",
    "  obs_small = downsample_image(obs)\n",
    "  return np.append(state[1:], np.expand_dims(obs_small, 0), axis=0)\n",
    "\n",
    "\n",
    "class DQN:\n",
    "  def __init__(self, K, conv_layer_sizes, hidden_layer_sizes, gamma, scope):\n",
    "\n",
    "    self.K = K\n",
    "    self.scope = scope\n",
    "\n",
    "    with tf.variable_scope(scope):\n",
    "\n",
    "      # inputs and targets\n",
    "      self.X = tf.placeholder(tf.float32, shape=(None, 4, IM_SIZE, IM_SIZE), name='X')\n",
    "\n",
    "      # tensorflow convolution needs the order to be:\n",
    "      # (num_samples, height, width, \"color\")\n",
    "      # so we need to tranpose later\n",
    "      self.G = tf.placeholder(tf.float32, shape=(None,), name='G')\n",
    "      self.actions = tf.placeholder(tf.int32, shape=(None,), name='actions')\n",
    "\n",
    "      # calculate output and cost\n",
    "      # convolutional layers\n",
    "      # these built-in layers are faster and don't require us to\n",
    "      # calculate the size of the output of the final conv layer!\n",
    "      Z = self.X / 255.0\n",
    "      Z = tf.transpose(Z, [0, 2, 3, 1])\n",
    "      for num_output_filters, filtersz, poolsz in conv_layer_sizes:\n",
    "        Z = tf.contrib.layers.conv2d(\n",
    "          Z,\n",
    "          num_output_filters,\n",
    "          filtersz,\n",
    "          poolsz,\n",
    "          activation_fn=tf.nn.relu\n",
    "        )\n",
    "\n",
    "      # fully connected layers\n",
    "      Z = tf.contrib.layers.flatten(Z)\n",
    "      for M in hidden_layer_sizes:\n",
    "        Z = tf.contrib.layers.fully_connected(Z, M)\n",
    "\n",
    "      # final output layer\n",
    "      self.predict_op = tf.contrib.layers.fully_connected(Z, K)\n",
    "\n",
    "      selected_action_values = tf.reduce_sum(\n",
    "        self.predict_op * tf.one_hot(self.actions, K),\n",
    "        reduction_indices=[1]\n",
    "      )\n",
    "\n",
    "      cost = tf.reduce_mean(tf.square(self.G - selected_action_values))\n",
    "      # self.train_op = tf.train.AdamOptimizer(1e-2).minimize(cost)\n",
    "      # self.train_op = tf.train.AdagradOptimizer(1e-2).minimize(cost)\n",
    "      # self.train_op = tf.train.RMSPropOptimizer(2.5e-4, decay=0.99, epsilon=10e-3).minimize(cost)\n",
    "      self.train_op = tf.train.RMSPropOptimizer(0.00025, 0.99, 0.0, 1e-6).minimize(cost)\n",
    "      # self.train_op = tf.train.MomentumOptimizer(1e-3, momentum=0.9).minimize(cost)\n",
    "      # self.train_op = tf.train.GradientDescentOptimizer(1e-4).minimize(cost)\n",
    "\n",
    "      self.cost = cost\n",
    "\n",
    "  def copy_from(self, other):\n",
    "    mine = [t for t in tf.trainable_variables() if t.name.startswith(self.scope)]\n",
    "    mine = sorted(mine, key=lambda v: v.name)\n",
    "    theirs = [t for t in tf.trainable_variables() if t.name.startswith(other.scope)]\n",
    "    theirs = sorted(theirs, key=lambda v: v.name)\n",
    "\n",
    "    ops = []\n",
    "    for p, q in zip(mine, theirs):\n",
    "      actual = self.session.run(q)\n",
    "      op = p.assign(actual)\n",
    "      ops.append(op)\n",
    "\n",
    "    self.session.run(ops)\n",
    "\n",
    "  def set_session(self, session):\n",
    "    self.session = session\n",
    "\n",
    "  def predict(self, states):\n",
    "    return self.session.run(self.predict_op, feed_dict={self.X: states})\n",
    "\n",
    "  def update(self, states, actions, targets):\n",
    "    c, _ = self.session.run(\n",
    "      [self.cost, self.train_op],\n",
    "      feed_dict={\n",
    "        self.X: states,\n",
    "        self.G: targets,\n",
    "        self.actions: actions\n",
    "      }\n",
    "    )\n",
    "    return c\n",
    "\n",
    "  def sample_action(self, x, eps):\n",
    "    if np.random.random() < eps:\n",
    "      return np.random.choice(self.K)\n",
    "    else:\n",
    "      return np.argmax(self.predict([x])[0])\n",
    "\n",
    "\n",
    "def learn(model, target_model, experience_replay_buffer, gamma, batch_size):\n",
    "  # Sample experiences\n",
    "  samples = random.sample(experience_replay_buffer, batch_size)\n",
    "  states, actions, rewards, next_states, dones = map(np.array, zip(*samples))\n",
    "\n",
    "  # Calculate targets\n",
    "  next_Qs = target_model.predict(next_states)\n",
    "  next_Q = np.amax(next_Qs, axis=1)\n",
    "  targets = rewards + np.invert(dones).astype(np.float32) * gamma * next_Q\n",
    "\n",
    "  # Update model\n",
    "  loss = model.update(states, actions, targets)\n",
    "  return loss\n",
    "\n",
    "\n",
    "def play_one(\n",
    "  env,\n",
    "  total_t,\n",
    "  experience_replay_buffer,\n",
    "  model,\n",
    "  target_model,\n",
    "  gamma,\n",
    "  batch_size,\n",
    "  epsilon,\n",
    "  epsilon_change,\n",
    "  epsilon_min):\n",
    "\n",
    "  t0 = datetime.now()\n",
    "\n",
    "  # Reset the environment\n",
    "  obs = env.reset()\n",
    "  obs_small = downsample_image(obs)\n",
    "  state = np.stack([obs_small] * 4, axis=0)\n",
    "  assert(state.shape == (4, 80, 80))\n",
    "  loss = None\n",
    "\n",
    "\n",
    "  total_time_training = 0\n",
    "  num_steps_in_episode = 0\n",
    "  episode_reward = 0\n",
    "\n",
    "  done = False\n",
    "  while not done:\n",
    "\n",
    "    # Update target network\n",
    "    if total_t % TARGET_UPDATE_PERIOD == 0:\n",
    "      target_model.copy_from(model)\n",
    "      print(\"Copied model parameters to target network. total_t = %s, period = %s\" % (total_t, TARGET_UPDATE_PERIOD))\n",
    "\n",
    "\n",
    "    # Take action\n",
    "    action = model.sample_action(state, epsilon)\n",
    "    obs, reward, done, _ = env.step(action)\n",
    "    obs_small = downsample_image(obs)\n",
    "    next_state = np.append(state[1:], np.expand_dims(obs_small, 0), axis=0)\n",
    "    # assert(state.shape == (4, 80, 80))\n",
    "\n",
    "\n",
    "\n",
    "    episode_reward += reward\n",
    "\n",
    "    # Remove oldest experience if replay buffer is full\n",
    "    if len(experience_replay_buffer) == MAX_EXPERIENCES:\n",
    "      experience_replay_buffer.pop(0)\n",
    "\n",
    "    # Save the latest experience\n",
    "    experience_replay_buffer.append((state, action, reward, next_state, done))\n",
    "\n",
    "    # Train the model, keep track of time\n",
    "    t0_2 = datetime.now()\n",
    "    loss = learn(model, target_model, experience_replay_buffer, gamma, batch_size)\n",
    "    dt = datetime.now() - t0_2\n",
    "\n",
    "    total_time_training += dt.total_seconds()\n",
    "    num_steps_in_episode += 1\n",
    "\n",
    "\n",
    "    state = next_state\n",
    "    total_t += 1\n",
    "\n",
    "    epsilon = max(epsilon - epsilon_change, epsilon_min)\n",
    "\n",
    "  return total_t, episode_reward, (datetime.now() - t0), num_steps_in_episode, total_time_training/num_steps_in_episode, epsilon\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "  # hyperparams and initialize stuff\n",
    "  conv_layer_sizes = [(32, 8, 4), (64, 4, 2), (64, 3, 1)]\n",
    "  hidden_layer_sizes = [512]\n",
    "  gamma = 0.99\n",
    "  batch_sz = 32\n",
    "  num_episodes = 10000\n",
    "  total_t = 0\n",
    "  experience_replay_buffer = []\n",
    "  episode_rewards = np.zeros(num_episodes)\n",
    "\n",
    "\n",
    "\n",
    "  # epsilon\n",
    "  # decays linearly until 0.1\n",
    "  epsilon = 1.0\n",
    "  epsilon_min = 0.1\n",
    "  epsilon_change = (epsilon - epsilon_min) / 500000\n",
    "\n",
    "\n",
    "\n",
    "  # Create environment\n",
    "  env = gym.envs.make(\"Breakout-v0\")\n",
    " \n",
    "\n",
    "\n",
    "  # Create models\n",
    "  model = DQN(\n",
    "    K=K,\n",
    "    conv_layer_sizes=conv_layer_sizes,\n",
    "    hidden_layer_sizes=hidden_layer_sizes,\n",
    "    gamma=gamma,\n",
    "    scope=\"model\")\n",
    "  target_model = DQN(\n",
    "    K=K,\n",
    "    conv_layer_sizes=conv_layer_sizes,\n",
    "    hidden_layer_sizes=hidden_layer_sizes,\n",
    "    gamma=gamma,\n",
    "    scope=\"target_model\"\n",
    "  )\n",
    "\n",
    "\n",
    "\n",
    "  with tf.Session() as sess:\n",
    "    model.set_session(sess)\n",
    "    target_model.set_session(sess)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "\n",
    "    print(\"Populating experience replay buffer...\")\n",
    "    obs = env.reset()\n",
    "    obs_small = downsample_image(obs)\n",
    "    state = np.stack([obs_small] * 4, axis=0)\n",
    "    # assert(state.shape == (4, 80, 80))\n",
    "    for i in range(MIN_EXPERIENCES):\n",
    "\n",
    "        action = np.random.choice(K)\n",
    "        obs, reward, done, _ = env.step(action)\n",
    "        next_state = update_state(state, obs)\n",
    "        # assert(state.shape == (4, 80, 80))\n",
    "        experience_replay_buffer.append((state, action, reward, next_state, done))\n",
    "\n",
    "        if done:\n",
    "            obs = env.reset()\n",
    "            obs_small = downsample_image(obs)\n",
    "            state = np.stack([obs_small] * 4, axis=0)\n",
    "            # assert(state.shape == (4, 80, 80))\n",
    "        else:\n",
    "            state = next_state\n",
    "\n",
    "\n",
    "    # Play a number of episodes and learn!\n",
    "    for i in range(num_episodes):\n",
    "\n",
    "      total_t, episode_reward, duration, num_steps_in_episode, time_per_step, epsilon = play_one(\n",
    "        env,\n",
    "        total_t,\n",
    "        experience_replay_buffer,\n",
    "        model,\n",
    "        target_model,\n",
    "        gamma,\n",
    "        batch_sz,\n",
    "        epsilon,\n",
    "        epsilon_change,\n",
    "        epsilon_min,\n",
    "      )\n",
    "      episode_rewards[i] = episode_reward\n",
    "\n",
    "      last_100_avg = episode_rewards[max(0, i - 100):i + 1].mean()\n",
    "      print(\"Episode:\", i,\n",
    "        \"Duration:\", duration,\n",
    "        \"Num steps:\", num_steps_in_episode,\n",
    "        \"Reward:\", episode_reward,\n",
    "        \"Training time per step:\", \"%.3f\" % time_per_step,\n",
    "        \"Avg Reward (Last 100):\", \"%.3f\" % last_100_avg,\n",
    "        \"Epsilon:\", \"%.3f\" % epsilon\n",
    "      )\n",
    "      sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating experience replay buffer...\n",
      "Copied model parameters to target network. total_t = 0, period = 10000\n",
      "Episode: 0 Duration: 0:00:03.988829 Num steps: 199 Reward: 1.0 Training time per step: 0.017 Avg Reward (Last 100): 1.000 Epsilon: 1.000\n",
      "Episode: 1 Duration: 0:00:02.731743 Num steps: 241 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.000 Epsilon: 0.999\n",
      "Episode: 2 Duration: 0:00:02.923278 Num steps: 256 Reward: 1.0 Training time per step: 0.010 Avg Reward (Last 100): 1.000 Epsilon: 0.999\n",
      "Episode: 3 Duration: 0:00:02.612389 Num steps: 229 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.000 Epsilon: 0.998\n",
      "Episode: 4 Duration: 0:00:01.889264 Num steps: 165 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 0.800 Epsilon: 0.998\n",
      "Episode: 5 Duration: 0:00:05.518013 Num steps: 489 Reward: 9.0 Training time per step: 0.009 Avg Reward (Last 100): 2.167 Epsilon: 0.997\n",
      "Episode: 6 Duration: 0:00:02.779699 Num steps: 246 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 2.143 Epsilon: 0.997\n",
      "Episode: 7 Duration: 0:00:01.990035 Num steps: 174 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.875 Epsilon: 0.996\n",
      "Episode: 8 Duration: 0:00:02.404742 Num steps: 214 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.778 Epsilon: 0.996\n",
      "Episode: 9 Duration: 0:00:02.127749 Num steps: 187 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.600 Epsilon: 0.996\n",
      "Episode: 10 Duration: 0:00:02.397023 Num steps: 212 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.545 Epsilon: 0.995\n",
      "Episode: 11 Duration: 0:00:01.872629 Num steps: 166 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.417 Epsilon: 0.995\n",
      "Episode: 12 Duration: 0:00:02.077607 Num steps: 183 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.308 Epsilon: 0.995\n",
      "Episode: 13 Duration: 0:00:03.341108 Num steps: 296 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.357 Epsilon: 0.994\n",
      "Episode: 14 Duration: 0:00:03.916695 Num steps: 346 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.467 Epsilon: 0.994\n",
      "Episode: 15 Duration: 0:00:02.040513 Num steps: 180 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.375 Epsilon: 0.993\n",
      "Episode: 16 Duration: 0:00:02.392010 Num steps: 213 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.353 Epsilon: 0.993\n",
      "Episode: 17 Duration: 0:00:02.941254 Num steps: 259 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.333 Epsilon: 0.992\n",
      "Episode: 18 Duration: 0:00:02.959467 Num steps: 261 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.316 Epsilon: 0.992\n",
      "Episode: 19 Duration: 0:00:02.749869 Num steps: 243 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.300 Epsilon: 0.991\n",
      "Episode: 20 Duration: 0:00:01.813799 Num steps: 161 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.238 Epsilon: 0.991\n",
      "Episode: 21 Duration: 0:00:01.942425 Num steps: 172 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.182 Epsilon: 0.991\n",
      "Episode: 22 Duration: 0:00:03.152303 Num steps: 278 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.217 Epsilon: 0.990\n",
      "Episode: 23 Duration: 0:00:04.213551 Num steps: 370 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.292 Epsilon: 0.990\n",
      "Episode: 24 Duration: 0:00:02.860613 Num steps: 252 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.280 Epsilon: 0.989\n",
      "Episode: 25 Duration: 0:00:04.068123 Num steps: 359 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.346 Epsilon: 0.989\n",
      "Episode: 26 Duration: 0:00:03.693319 Num steps: 328 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.407 Epsilon: 0.988\n",
      "Episode: 27 Duration: 0:00:03.377697 Num steps: 299 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.429 Epsilon: 0.987\n",
      "Episode: 28 Duration: 0:00:04.290864 Num steps: 380 Reward: 4.0 Training time per step: 0.009 Avg Reward (Last 100): 1.517 Epsilon: 0.987\n",
      "Episode: 29 Duration: 0:00:02.000778 Num steps: 176 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.467 Epsilon: 0.986\n",
      "Episode: 30 Duration: 0:00:04.187451 Num steps: 370 Reward: 4.0 Training time per step: 0.009 Avg Reward (Last 100): 1.548 Epsilon: 0.986\n",
      "Episode: 31 Duration: 0:00:02.692319 Num steps: 236 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.531 Epsilon: 0.985\n",
      "Episode: 32 Duration: 0:00:01.934332 Num steps: 170 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.485 Epsilon: 0.985\n",
      "Episode: 33 Duration: 0:00:03.066526 Num steps: 268 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.500 Epsilon: 0.985\n",
      "Episode: 34 Duration: 0:00:01.890249 Num steps: 166 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.457 Epsilon: 0.984\n",
      "Episode: 35 Duration: 0:00:02.025071 Num steps: 178 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.417 Epsilon: 0.984\n",
      "Episode: 36 Duration: 0:00:04.475542 Num steps: 396 Reward: 4.0 Training time per step: 0.009 Avg Reward (Last 100): 1.486 Epsilon: 0.983\n",
      "Episode: 37 Duration: 0:00:02.109378 Num steps: 185 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.447 Epsilon: 0.983\n",
      "Episode: 38 Duration: 0:00:02.089847 Num steps: 184 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.410 Epsilon: 0.983\n",
      "Episode: 39 Duration: 0:00:02.358003 Num steps: 209 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.400 Epsilon: 0.982\n",
      "Copied model parameters to target network. total_t = 10000, period = 10000\n",
      "Episode: 40 Duration: 0:00:02.554332 Num steps: 211 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.390 Epsilon: 0.982\n",
      "Episode: 41 Duration: 0:00:03.907347 Num steps: 343 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.429 Epsilon: 0.981\n",
      "Episode: 42 Duration: 0:00:01.842395 Num steps: 163 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.395 Epsilon: 0.981\n",
      "Episode: 43 Duration: 0:00:03.486202 Num steps: 306 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.432 Epsilon: 0.980\n",
      "Episode: 44 Duration: 0:00:02.006688 Num steps: 177 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.400 Epsilon: 0.980\n",
      "Episode: 45 Duration: 0:00:01.931780 Num steps: 170 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.370 Epsilon: 0.980\n",
      "Episode: 46 Duration: 0:00:02.781976 Num steps: 244 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.362 Epsilon: 0.979\n",
      "Episode: 47 Duration: 0:00:02.977324 Num steps: 263 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.354 Epsilon: 0.979\n",
      "Episode: 48 Duration: 0:00:04.309516 Num steps: 379 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.388 Epsilon: 0.978\n",
      "Episode: 49 Duration: 0:00:03.125938 Num steps: 279 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.400 Epsilon: 0.978\n",
      "Episode: 50 Duration: 0:00:02.611248 Num steps: 230 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.392 Epsilon: 0.977\n",
      "Episode: 51 Duration: 0:00:01.950442 Num steps: 173 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.365 Epsilon: 0.977\n",
      "Episode: 52 Duration: 0:00:01.901199 Num steps: 168 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.340 Epsilon: 0.977\n",
      "Episode: 53 Duration: 0:00:04.448280 Num steps: 390 Reward: 4.0 Training time per step: 0.009 Avg Reward (Last 100): 1.389 Epsilon: 0.976\n",
      "Episode: 54 Duration: 0:00:03.496985 Num steps: 310 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.400 Epsilon: 0.975\n",
      "Episode: 55 Duration: 0:00:02.718152 Num steps: 238 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.393 Epsilon: 0.975\n",
      "Episode: 56 Duration: 0:00:02.000003 Num steps: 176 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.368 Epsilon: 0.975\n",
      "Episode: 57 Duration: 0:00:02.892122 Num steps: 253 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.362 Epsilon: 0.974\n",
      "Episode: 58 Duration: 0:00:02.784347 Num steps: 244 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.356 Epsilon: 0.974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 59 Duration: 0:00:01.870559 Num steps: 164 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.333 Epsilon: 0.973\n",
      "Episode: 60 Duration: 0:00:02.781739 Num steps: 244 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.328 Epsilon: 0.973\n",
      "Episode: 61 Duration: 0:00:02.640798 Num steps: 233 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.323 Epsilon: 0.973\n",
      "Episode: 62 Duration: 0:00:03.163880 Num steps: 280 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.333 Epsilon: 0.972\n",
      "Episode: 63 Duration: 0:00:01.945819 Num steps: 171 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.312 Epsilon: 0.972\n",
      "Episode: 64 Duration: 0:00:02.952333 Num steps: 259 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.323 Epsilon: 0.971\n",
      "Episode: 65 Duration: 0:00:02.008837 Num steps: 176 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.303 Epsilon: 0.971\n",
      "Episode: 66 Duration: 0:00:01.933116 Num steps: 169 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.284 Epsilon: 0.971\n",
      "Episode: 67 Duration: 0:00:04.706747 Num steps: 413 Reward: 4.0 Training time per step: 0.009 Avg Reward (Last 100): 1.324 Epsilon: 0.970\n",
      "Episode: 68 Duration: 0:00:03.475358 Num steps: 306 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.333 Epsilon: 0.969\n",
      "Episode: 69 Duration: 0:00:04.528489 Num steps: 397 Reward: 4.0 Training time per step: 0.009 Avg Reward (Last 100): 1.371 Epsilon: 0.969\n",
      "Episode: 70 Duration: 0:00:03.548909 Num steps: 314 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.394 Epsilon: 0.968\n",
      "Episode: 71 Duration: 0:00:02.052418 Num steps: 179 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.375 Epsilon: 0.968\n",
      "Episode: 72 Duration: 0:00:02.363181 Num steps: 207 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.370 Epsilon: 0.967\n",
      "Episode: 73 Duration: 0:00:01.974574 Num steps: 174 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.351 Epsilon: 0.967\n",
      "Episode: 74 Duration: 0:00:03.263767 Num steps: 286 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.360 Epsilon: 0.967\n",
      "Episode: 75 Duration: 0:00:02.705888 Num steps: 240 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.355 Epsilon: 0.966\n",
      "Episode: 76 Duration: 0:00:02.423975 Num steps: 213 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.351 Epsilon: 0.966\n",
      "Episode: 77 Duration: 0:00:02.025234 Num steps: 178 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.333 Epsilon: 0.965\n",
      "Episode: 78 Duration: 0:00:02.224705 Num steps: 197 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.316 Epsilon: 0.965\n",
      "Episode: 79 Duration: 0:00:02.578780 Num steps: 226 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.312 Epsilon: 0.965\n",
      "Episode: 80 Duration: 0:00:03.932002 Num steps: 347 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.333 Epsilon: 0.964\n",
      "Copied model parameters to target network. total_t = 20000, period = 10000\n",
      "Episode: 81 Duration: 0:00:03.305188 Num steps: 272 Reward: 2.0 Training time per step: 0.010 Avg Reward (Last 100): 1.341 Epsilon: 0.964\n",
      "Episode: 82 Duration: 0:00:01.991602 Num steps: 172 Reward: 0.0 Training time per step: 0.010 Avg Reward (Last 100): 1.325 Epsilon: 0.963\n",
      "Episode: 83 Duration: 0:00:03.188790 Num steps: 279 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.333 Epsilon: 0.963\n",
      "Episode: 84 Duration: 0:00:02.140819 Num steps: 187 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.318 Epsilon: 0.962\n",
      "Episode: 85 Duration: 0:00:02.821264 Num steps: 244 Reward: 1.0 Training time per step: 0.010 Avg Reward (Last 100): 1.314 Epsilon: 0.962\n",
      "Episode: 86 Duration: 0:00:02.442618 Num steps: 213 Reward: 1.0 Training time per step: 0.010 Avg Reward (Last 100): 1.310 Epsilon: 0.962\n",
      "Episode: 87 Duration: 0:00:03.010128 Num steps: 265 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.318 Epsilon: 0.961\n",
      "Episode: 88 Duration: 0:00:02.658486 Num steps: 232 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.315 Epsilon: 0.961\n",
      "Episode: 89 Duration: 0:00:02.483009 Num steps: 216 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.311 Epsilon: 0.960\n",
      "Episode: 90 Duration: 0:00:05.090890 Num steps: 446 Reward: 7.0 Training time per step: 0.009 Avg Reward (Last 100): 1.374 Epsilon: 0.959\n",
      "Episode: 91 Duration: 0:00:03.104960 Num steps: 272 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.380 Epsilon: 0.959\n",
      "Episode: 92 Duration: 0:00:03.074879 Num steps: 269 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.387 Epsilon: 0.959\n",
      "Episode: 93 Duration: 0:00:02.720135 Num steps: 240 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.383 Epsilon: 0.958\n",
      "Episode: 94 Duration: 0:00:02.320158 Num steps: 204 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.368 Epsilon: 0.958\n",
      "Episode: 95 Duration: 0:00:02.013051 Num steps: 176 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.354 Epsilon: 0.957\n",
      "Episode: 96 Duration: 0:00:03.239944 Num steps: 284 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.361 Epsilon: 0.957\n",
      "Episode: 97 Duration: 0:00:03.470539 Num steps: 303 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.367 Epsilon: 0.956\n",
      "Episode: 98 Duration: 0:00:02.080099 Num steps: 182 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.354 Epsilon: 0.956\n",
      "Episode: 99 Duration: 0:00:02.381919 Num steps: 209 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.350 Epsilon: 0.956\n",
      "Episode: 100 Duration: 0:00:02.019907 Num steps: 177 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.337 Epsilon: 0.955\n",
      "Episode: 101 Duration: 0:00:02.080525 Num steps: 181 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.327 Epsilon: 0.955\n",
      "Episode: 102 Duration: 0:00:02.611084 Num steps: 229 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.327 Epsilon: 0.955\n",
      "Episode: 103 Duration: 0:00:02.143069 Num steps: 188 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.317 Epsilon: 0.954\n",
      "Episode: 104 Duration: 0:00:01.897619 Num steps: 164 Reward: 0.0 Training time per step: 0.010 Avg Reward (Last 100): 1.307 Epsilon: 0.954\n",
      "Episode: 105 Duration: 0:00:04.186382 Num steps: 367 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.337 Epsilon: 0.953\n",
      "Episode: 106 Duration: 0:00:02.483857 Num steps: 218 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.257 Epsilon: 0.953\n",
      "Episode: 107 Duration: 0:00:02.193144 Num steps: 193 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.238 Epsilon: 0.953\n",
      "Episode: 108 Duration: 0:00:03.032484 Num steps: 265 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.257 Epsilon: 0.952\n",
      "Episode: 109 Duration: 0:00:01.966076 Num steps: 172 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.248 Epsilon: 0.952\n",
      "Episode: 110 Duration: 0:00:02.816959 Num steps: 247 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.267 Epsilon: 0.951\n",
      "Episode: 111 Duration: 0:00:03.409977 Num steps: 298 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.277 Epsilon: 0.951\n",
      "Episode: 112 Duration: 0:00:03.774238 Num steps: 329 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.307 Epsilon: 0.950\n",
      "Episode: 113 Duration: 0:00:02.664475 Num steps: 233 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.317 Epsilon: 0.950\n",
      "Episode: 114 Duration: 0:00:01.963747 Num steps: 172 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.297 Epsilon: 0.949\n",
      "Episode: 115 Duration: 0:00:02.634639 Num steps: 231 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.277 Epsilon: 0.949\n",
      "Episode: 116 Duration: 0:00:01.941050 Num steps: 169 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.277 Epsilon: 0.949\n",
      "Episode: 117 Duration: 0:00:03.495840 Num steps: 304 Reward: 2.0 Training time per step: 0.010 Avg Reward (Last 100): 1.287 Epsilon: 0.948\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 118 Duration: 0:00:02.641456 Num steps: 231 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.287 Epsilon: 0.948\n",
      "Episode: 119 Duration: 0:00:03.021705 Num steps: 265 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.297 Epsilon: 0.947\n",
      "Episode: 120 Duration: 0:00:02.654519 Num steps: 233 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.297 Epsilon: 0.947\n",
      "Episode: 121 Duration: 0:00:03.214489 Num steps: 281 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.317 Epsilon: 0.946\n",
      "Episode: 122 Duration: 0:00:02.159770 Num steps: 188 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.317 Epsilon: 0.946\n",
      "Copied model parameters to target network. total_t = 30000, period = 10000\n",
      "Episode: 123 Duration: 0:00:03.319191 Num steps: 275 Reward: 2.0 Training time per step: 0.010 Avg Reward (Last 100): 1.317 Epsilon: 0.946\n",
      "Episode: 124 Duration: 0:00:05.855161 Num steps: 513 Reward: 6.0 Training time per step: 0.010 Avg Reward (Last 100): 1.347 Epsilon: 0.945\n",
      "Episode: 125 Duration: 0:00:01.953359 Num steps: 171 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.337 Epsilon: 0.944\n",
      "Episode: 126 Duration: 0:00:02.624031 Num steps: 231 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.317 Epsilon: 0.944\n",
      "Episode: 127 Duration: 0:00:03.678055 Num steps: 322 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.307 Epsilon: 0.943\n",
      "Episode: 128 Duration: 0:00:02.012413 Num steps: 177 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.287 Epsilon: 0.943\n",
      "Episode: 129 Duration: 0:00:03.479991 Num steps: 306 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.267 Epsilon: 0.942\n",
      "Episode: 130 Duration: 0:00:02.475900 Num steps: 217 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.277 Epsilon: 0.942\n",
      "Episode: 131 Duration: 0:00:02.512551 Num steps: 220 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.248 Epsilon: 0.942\n",
      "Episode: 132 Duration: 0:00:02.126592 Num steps: 186 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.238 Epsilon: 0.941\n",
      "Episode: 133 Duration: 0:00:03.345137 Num steps: 293 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.257 Epsilon: 0.941\n",
      "Episode: 134 Duration: 0:00:02.399089 Num steps: 209 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.248 Epsilon: 0.940\n",
      "Episode: 135 Duration: 0:00:02.147412 Num steps: 188 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.248 Epsilon: 0.940\n",
      "Episode: 136 Duration: 0:00:04.227885 Num steps: 371 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.277 Epsilon: 0.939\n",
      "Episode: 137 Duration: 0:00:02.394255 Num steps: 210 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.248 Epsilon: 0.939\n",
      "Episode: 138 Duration: 0:00:03.383724 Num steps: 296 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.267 Epsilon: 0.938\n",
      "Episode: 139 Duration: 0:00:03.826754 Num steps: 335 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.297 Epsilon: 0.938\n",
      "Episode: 140 Duration: 0:00:02.641626 Num steps: 231 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.297 Epsilon: 0.937\n",
      "Episode: 141 Duration: 0:00:02.015553 Num steps: 175 Reward: 0.0 Training time per step: 0.010 Avg Reward (Last 100): 1.287 Epsilon: 0.937\n",
      "Episode: 142 Duration: 0:00:02.883898 Num steps: 250 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.267 Epsilon: 0.937\n",
      "Episode: 143 Duration: 0:00:01.981179 Num steps: 171 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.267 Epsilon: 0.936\n",
      "Episode: 144 Duration: 0:00:02.037518 Num steps: 180 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.238 Epsilon: 0.936\n",
      "Episode: 145 Duration: 0:00:03.567250 Num steps: 311 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.267 Epsilon: 0.936\n",
      "Episode: 146 Duration: 0:00:02.611307 Num steps: 230 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.277 Epsilon: 0.935\n",
      "Episode: 147 Duration: 0:00:03.179815 Num steps: 276 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.287 Epsilon: 0.935\n",
      "Episode: 148 Duration: 0:00:02.746791 Num steps: 242 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.287 Epsilon: 0.934\n",
      "Episode: 149 Duration: 0:00:02.600738 Num steps: 224 Reward: 1.0 Training time per step: 0.010 Avg Reward (Last 100): 1.267 Epsilon: 0.934\n",
      "Episode: 150 Duration: 0:00:02.880109 Num steps: 253 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.257 Epsilon: 0.933\n",
      "Episode: 151 Duration: 0:00:02.047634 Num steps: 177 Reward: 0.0 Training time per step: 0.010 Avg Reward (Last 100): 1.248 Epsilon: 0.933\n",
      "Episode: 152 Duration: 0:00:03.736170 Num steps: 327 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.277 Epsilon: 0.932\n",
      "Episode: 153 Duration: 0:00:03.481368 Num steps: 302 Reward: 2.0 Training time per step: 0.010 Avg Reward (Last 100): 1.297 Epsilon: 0.932\n",
      "Episode: 154 Duration: 0:00:01.915298 Num steps: 166 Reward: 0.0 Training time per step: 0.010 Avg Reward (Last 100): 1.257 Epsilon: 0.932\n",
      "Episode: 155 Duration: 0:00:03.859627 Num steps: 338 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.267 Epsilon: 0.931\n",
      "Episode: 156 Duration: 0:00:02.316044 Num steps: 202 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.267 Epsilon: 0.931\n",
      "Episode: 157 Duration: 0:00:03.191380 Num steps: 280 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.287 Epsilon: 0.930\n",
      "Episode: 158 Duration: 0:00:02.063049 Num steps: 180 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.277 Epsilon: 0.930\n",
      "Episode: 159 Duration: 0:00:02.463865 Num steps: 214 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.277 Epsilon: 0.929\n",
      "Episode: 160 Duration: 0:00:02.128153 Num steps: 185 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.277 Epsilon: 0.929\n",
      "Episode: 161 Duration: 0:00:02.174120 Num steps: 190 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.267 Epsilon: 0.929\n",
      "Episode: 162 Duration: 0:00:04.253285 Num steps: 371 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.287 Epsilon: 0.928\n",
      "Copied model parameters to target network. total_t = 40000, period = 10000\n",
      "Episode: 163 Duration: 0:00:02.203259 Num steps: 178 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.267 Epsilon: 0.928\n",
      "Episode: 164 Duration: 0:00:03.196739 Num steps: 278 Reward: 2.0 Training time per step: 0.010 Avg Reward (Last 100): 1.287 Epsilon: 0.927\n",
      "Episode: 165 Duration: 0:00:02.377571 Num steps: 207 Reward: 1.0 Training time per step: 0.010 Avg Reward (Last 100): 1.277 Epsilon: 0.927\n",
      "Episode: 166 Duration: 0:00:03.660535 Num steps: 318 Reward: 3.0 Training time per step: 0.010 Avg Reward (Last 100): 1.307 Epsilon: 0.926\n",
      "Episode: 167 Duration: 0:00:01.909279 Num steps: 167 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.307 Epsilon: 0.926\n",
      "Episode: 168 Duration: 0:00:02.858552 Num steps: 250 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.277 Epsilon: 0.926\n",
      "Episode: 169 Duration: 0:00:02.230987 Num steps: 194 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.257 Epsilon: 0.925\n",
      "Episode: 170 Duration: 0:00:02.157628 Num steps: 189 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.218 Epsilon: 0.925\n",
      "Episode: 171 Duration: 0:00:02.193032 Num steps: 192 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.188 Epsilon: 0.924\n",
      "Episode: 172 Duration: 0:00:02.713747 Num steps: 233 Reward: 1.0 Training time per step: 0.010 Avg Reward (Last 100): 1.198 Epsilon: 0.924\n",
      "Episode: 173 Duration: 0:00:02.407301 Num steps: 210 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.198 Epsilon: 0.924\n",
      "Episode: 174 Duration: 0:00:02.055412 Num steps: 177 Reward: 0.0 Training time per step: 0.010 Avg Reward (Last 100): 1.198 Epsilon: 0.923\n",
      "Episode: 175 Duration: 0:00:01.899408 Num steps: 166 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.178 Epsilon: 0.923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 176 Duration: 0:00:04.226740 Num steps: 367 Reward: 3.0 Training time per step: 0.010 Avg Reward (Last 100): 1.198 Epsilon: 0.922\n",
      "Episode: 177 Duration: 0:00:02.667795 Num steps: 232 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.198 Epsilon: 0.922\n",
      "Episode: 178 Duration: 0:00:02.464492 Num steps: 216 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.208 Epsilon: 0.922\n",
      "Episode: 179 Duration: 0:00:03.253854 Num steps: 283 Reward: 2.0 Training time per step: 0.010 Avg Reward (Last 100): 1.228 Epsilon: 0.921\n",
      "Episode: 180 Duration: 0:00:03.878109 Num steps: 340 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.248 Epsilon: 0.920\n",
      "Episode: 181 Duration: 0:00:02.464377 Num steps: 214 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.228 Epsilon: 0.920\n",
      "Episode: 182 Duration: 0:00:02.055880 Num steps: 179 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.208 Epsilon: 0.920\n",
      "Episode: 183 Duration: 0:00:02.456579 Num steps: 213 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.218 Epsilon: 0.919\n",
      "Episode: 184 Duration: 0:00:01.930483 Num steps: 167 Reward: 0.0 Training time per step: 0.010 Avg Reward (Last 100): 1.198 Epsilon: 0.919\n",
      "Episode: 185 Duration: 0:00:02.037986 Num steps: 180 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.198 Epsilon: 0.919\n",
      "Episode: 186 Duration: 0:00:04.231039 Num steps: 368 Reward: 4.0 Training time per step: 0.009 Avg Reward (Last 100): 1.228 Epsilon: 0.918\n",
      "Episode: 187 Duration: 0:00:01.838695 Num steps: 161 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.218 Epsilon: 0.918\n",
      "Episode: 188 Duration: 0:00:03.185992 Num steps: 277 Reward: 2.0 Training time per step: 0.010 Avg Reward (Last 100): 1.218 Epsilon: 0.917\n",
      "Episode: 189 Duration: 0:00:02.691633 Num steps: 235 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.218 Epsilon: 0.917\n",
      "Episode: 190 Duration: 0:00:01.903301 Num steps: 166 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.208 Epsilon: 0.917\n",
      "Episode: 191 Duration: 0:00:01.914556 Num steps: 165 Reward: 0.0 Training time per step: 0.010 Avg Reward (Last 100): 1.139 Epsilon: 0.916\n",
      "Episode: 192 Duration: 0:00:02.039106 Num steps: 178 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.119 Epsilon: 0.916\n",
      "Episode: 193 Duration: 0:00:02.387492 Num steps: 208 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.109 Epsilon: 0.916\n",
      "Episode: 194 Duration: 0:00:02.800190 Num steps: 242 Reward: 1.0 Training time per step: 0.010 Avg Reward (Last 100): 1.109 Epsilon: 0.915\n",
      "Episode: 195 Duration: 0:00:03.499327 Num steps: 304 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.129 Epsilon: 0.915\n",
      "Episode: 196 Duration: 0:00:02.670198 Num steps: 233 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.139 Epsilon: 0.914\n",
      "Episode: 197 Duration: 0:00:03.119111 Num steps: 273 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.139 Epsilon: 0.914\n",
      "Episode: 198 Duration: 0:00:02.613112 Num steps: 229 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.129 Epsilon: 0.913\n",
      "Episode: 199 Duration: 0:00:01.964396 Num steps: 170 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.129 Epsilon: 0.913\n",
      "Episode: 200 Duration: 0:00:02.788778 Num steps: 242 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.129 Epsilon: 0.913\n",
      "Episode: 201 Duration: 0:00:02.637886 Num steps: 231 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.139 Epsilon: 0.912\n",
      "Episode: 202 Duration: 0:00:02.451113 Num steps: 214 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.149 Epsilon: 0.912\n",
      "Episode: 203 Duration: 0:00:02.851978 Num steps: 249 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.149 Epsilon: 0.911\n",
      "Episode: 204 Duration: 0:00:03.167397 Num steps: 275 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.168 Epsilon: 0.911\n",
      "Episode: 205 Duration: 0:00:04.258126 Num steps: 373 Reward: 4.0 Training time per step: 0.009 Avg Reward (Last 100): 1.208 Epsilon: 0.910\n",
      "Copied model parameters to target network. total_t = 50000, period = 10000\n",
      "Episode: 206 Duration: 0:00:04.557203 Num steps: 377 Reward: 4.0 Training time per step: 0.010 Avg Reward (Last 100): 1.218 Epsilon: 0.909\n",
      "Episode: 207 Duration: 0:00:02.028014 Num steps: 175 Reward: 0.0 Training time per step: 0.010 Avg Reward (Last 100): 1.208 Epsilon: 0.909\n",
      "Episode: 208 Duration: 0:00:05.187817 Num steps: 453 Reward: 5.0 Training time per step: 0.010 Avg Reward (Last 100): 1.257 Epsilon: 0.908\n",
      "Episode: 209 Duration: 0:00:02.830222 Num steps: 246 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.248 Epsilon: 0.908\n",
      "Episode: 210 Duration: 0:00:04.049494 Num steps: 352 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.277 Epsilon: 0.907\n",
      "Episode: 211 Duration: 0:00:02.818152 Num steps: 247 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.267 Epsilon: 0.907\n",
      "Episode: 212 Duration: 0:00:01.966652 Num steps: 170 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.248 Epsilon: 0.907\n",
      "Episode: 213 Duration: 0:00:02.395072 Num steps: 208 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.228 Epsilon: 0.906\n",
      "Episode: 214 Duration: 0:00:03.206685 Num steps: 279 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.238 Epsilon: 0.906\n",
      "Episode: 215 Duration: 0:00:04.382542 Num steps: 381 Reward: 4.0 Training time per step: 0.009 Avg Reward (Last 100): 1.277 Epsilon: 0.905\n",
      "Episode: 216 Duration: 0:00:01.869651 Num steps: 163 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.267 Epsilon: 0.905\n",
      "Episode: 217 Duration: 0:00:02.804625 Num steps: 243 Reward: 1.0 Training time per step: 0.010 Avg Reward (Last 100): 1.277 Epsilon: 0.904\n",
      "Episode: 218 Duration: 0:00:02.018273 Num steps: 175 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.257 Epsilon: 0.904\n",
      "Episode: 219 Duration: 0:00:02.414764 Num steps: 210 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.257 Epsilon: 0.904\n",
      "Episode: 220 Duration: 0:00:01.851492 Num steps: 160 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.238 Epsilon: 0.903\n",
      "Episode: 221 Duration: 0:00:02.860561 Num steps: 251 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.248 Epsilon: 0.903\n",
      "Episode: 222 Duration: 0:00:03.263486 Num steps: 285 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.248 Epsilon: 0.902\n",
      "Episode: 223 Duration: 0:00:04.546411 Num steps: 398 Reward: 4.0 Training time per step: 0.009 Avg Reward (Last 100): 1.287 Epsilon: 0.902\n",
      "Episode: 224 Duration: 0:00:01.950012 Num steps: 170 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.267 Epsilon: 0.901\n",
      "Episode: 225 Duration: 0:00:02.731988 Num steps: 237 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.218 Epsilon: 0.901\n",
      "Episode: 226 Duration: 0:00:03.693697 Num steps: 321 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.248 Epsilon: 0.900\n",
      "Episode: 227 Duration: 0:00:03.565510 Num steps: 310 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.267 Epsilon: 0.900\n",
      "Episode: 228 Duration: 0:00:03.626833 Num steps: 319 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.267 Epsilon: 0.899\n",
      "Episode: 229 Duration: 0:00:03.225253 Num steps: 282 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.287 Epsilon: 0.899\n",
      "Episode: 230 Duration: 0:00:02.703112 Num steps: 233 Reward: 1.0 Training time per step: 0.010 Avg Reward (Last 100): 1.277 Epsilon: 0.898\n",
      "Episode: 231 Duration: 0:00:02.482984 Num steps: 217 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.277 Epsilon: 0.898\n",
      "Episode: 232 Duration: 0:00:02.217697 Num steps: 193 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.267 Epsilon: 0.897\n",
      "Episode: 233 Duration: 0:00:03.613714 Num steps: 317 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.287 Epsilon: 0.897\n",
      "Episode: 234 Duration: 0:00:03.096934 Num steps: 268 Reward: 2.0 Training time per step: 0.010 Avg Reward (Last 100): 1.287 Epsilon: 0.896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 235 Duration: 0:00:02.006951 Num steps: 174 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.277 Epsilon: 0.896\n",
      "Episode: 236 Duration: 0:00:01.818981 Num steps: 159 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.277 Epsilon: 0.896\n",
      "Episode: 237 Duration: 0:00:02.424067 Num steps: 211 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.257 Epsilon: 0.895\n",
      "Episode: 238 Duration: 0:00:03.367845 Num steps: 295 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.267 Epsilon: 0.895\n",
      "Episode: 239 Duration: 0:00:03.834287 Num steps: 333 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.277 Epsilon: 0.894\n",
      "Episode: 240 Duration: 0:00:02.880398 Num steps: 249 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.267 Epsilon: 0.894\n",
      "Episode: 241 Duration: 0:00:02.068585 Num steps: 179 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.257 Epsilon: 0.894\n",
      "Episode: 242 Duration: 0:00:02.801996 Num steps: 242 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.267 Epsilon: 0.893\n",
      "Episode: 243 Duration: 0:00:03.130621 Num steps: 270 Reward: 2.0 Training time per step: 0.010 Avg Reward (Last 100): 1.277 Epsilon: 0.893\n",
      "Episode: 244 Duration: 0:00:03.241390 Num steps: 283 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.297 Epsilon: 0.892\n",
      "Copied model parameters to target network. total_t = 60000, period = 10000\n",
      "Episode: 245 Duration: 0:00:02.174248 Num steps: 174 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.297 Epsilon: 0.892\n",
      "Episode: 246 Duration: 0:00:02.880675 Num steps: 245 Reward: 1.0 Training time per step: 0.010 Avg Reward (Last 100): 1.277 Epsilon: 0.891\n",
      "Episode: 247 Duration: 0:00:02.129293 Num steps: 185 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.267 Epsilon: 0.891\n",
      "Episode: 248 Duration: 0:00:03.598306 Num steps: 311 Reward: 2.0 Training time per step: 0.010 Avg Reward (Last 100): 1.267 Epsilon: 0.890\n",
      "Episode: 249 Duration: 0:00:02.124138 Num steps: 184 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.257 Epsilon: 0.890\n",
      "Episode: 250 Duration: 0:00:01.900928 Num steps: 165 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.248 Epsilon: 0.890\n",
      "Episode: 251 Duration: 0:00:02.033403 Num steps: 178 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.238 Epsilon: 0.889\n",
      "Episode: 252 Duration: 0:00:02.779175 Num steps: 242 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.248 Epsilon: 0.889\n",
      "Episode: 253 Duration: 0:00:04.160562 Num steps: 364 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.248 Epsilon: 0.888\n",
      "Episode: 254 Duration: 0:00:02.074531 Num steps: 180 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.228 Epsilon: 0.888\n",
      "Episode: 255 Duration: 0:00:01.909132 Num steps: 167 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.228 Epsilon: 0.888\n",
      "Episode: 256 Duration: 0:00:02.724069 Num steps: 238 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.208 Epsilon: 0.887\n",
      "Episode: 257 Duration: 0:00:02.521376 Num steps: 220 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.208 Epsilon: 0.887\n",
      "Episode: 258 Duration: 0:00:02.039914 Num steps: 176 Reward: 0.0 Training time per step: 0.010 Avg Reward (Last 100): 1.188 Epsilon: 0.887\n",
      "Episode: 259 Duration: 0:00:04.258673 Num steps: 371 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.218 Epsilon: 0.886\n",
      "Episode: 260 Duration: 0:00:01.983986 Num steps: 173 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.208 Epsilon: 0.886\n",
      "Episode: 261 Duration: 0:00:01.932169 Num steps: 168 Reward: 0.0 Training time per step: 0.010 Avg Reward (Last 100): 1.208 Epsilon: 0.885\n",
      "Episode: 262 Duration: 0:00:02.104437 Num steps: 182 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.208 Epsilon: 0.885\n",
      "Episode: 263 Duration: 0:00:02.707302 Num steps: 234 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.188 Epsilon: 0.885\n",
      "Episode: 264 Duration: 0:00:02.096820 Num steps: 181 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.188 Epsilon: 0.884\n",
      "Episode: 265 Duration: 0:00:02.562199 Num steps: 224 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.178 Epsilon: 0.884\n",
      "Episode: 266 Duration: 0:00:02.518082 Num steps: 218 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.178 Epsilon: 0.883\n",
      "Episode: 267 Duration: 0:00:02.482844 Num steps: 217 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.158 Epsilon: 0.883\n",
      "Episode: 268 Duration: 0:00:03.435427 Num steps: 300 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.178 Epsilon: 0.883\n",
      "Episode: 269 Duration: 0:00:02.254638 Num steps: 195 Reward: 0.0 Training time per step: 0.010 Avg Reward (Last 100): 1.168 Epsilon: 0.882\n",
      "Episode: 270 Duration: 0:00:02.691971 Num steps: 235 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.178 Epsilon: 0.882\n",
      "Episode: 271 Duration: 0:00:02.690522 Num steps: 234 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.188 Epsilon: 0.881\n",
      "Episode: 272 Duration: 0:00:01.957635 Num steps: 169 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.188 Epsilon: 0.881\n",
      "Episode: 273 Duration: 0:00:02.106451 Num steps: 183 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.178 Epsilon: 0.881\n",
      "Episode: 274 Duration: 0:00:01.910558 Num steps: 165 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.168 Epsilon: 0.880\n",
      "Episode: 275 Duration: 0:00:03.263087 Num steps: 285 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.188 Epsilon: 0.880\n",
      "Episode: 276 Duration: 0:00:03.289054 Num steps: 286 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.208 Epsilon: 0.879\n",
      "Episode: 277 Duration: 0:00:04.392536 Num steps: 380 Reward: 4.0 Training time per step: 0.009 Avg Reward (Last 100): 1.218 Epsilon: 0.879\n",
      "Episode: 278 Duration: 0:00:02.487917 Num steps: 217 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.218 Epsilon: 0.878\n",
      "Episode: 279 Duration: 0:00:02.699718 Num steps: 236 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.218 Epsilon: 0.878\n",
      "Episode: 280 Duration: 0:00:02.150748 Num steps: 187 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.198 Epsilon: 0.878\n",
      "Episode: 281 Duration: 0:00:02.530258 Num steps: 220 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.178 Epsilon: 0.877\n",
      "Episode: 282 Duration: 0:00:01.916177 Num steps: 164 Reward: 0.0 Training time per step: 0.010 Avg Reward (Last 100): 1.168 Epsilon: 0.877\n",
      "Episode: 283 Duration: 0:00:02.005225 Num steps: 172 Reward: 0.0 Training time per step: 0.010 Avg Reward (Last 100): 1.168 Epsilon: 0.877\n",
      "Episode: 284 Duration: 0:00:02.031795 Num steps: 177 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.158 Epsilon: 0.876\n",
      "Episode: 285 Duration: 0:00:03.133083 Num steps: 273 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.178 Epsilon: 0.876\n",
      "Episode: 286 Duration: 0:00:04.075425 Num steps: 355 Reward: 4.0 Training time per step: 0.009 Avg Reward (Last 100): 1.218 Epsilon: 0.875\n",
      "Episode: 287 Duration: 0:00:03.798347 Num steps: 329 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.208 Epsilon: 0.875\n",
      "Episode: 288 Duration: 0:00:02.835054 Num steps: 246 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.218 Epsilon: 0.874\n",
      "Copied model parameters to target network. total_t = 70000, period = 10000\n",
      "Episode: 289 Duration: 0:00:04.073840 Num steps: 333 Reward: 3.0 Training time per step: 0.010 Avg Reward (Last 100): 1.228 Epsilon: 0.873\n",
      "Episode: 290 Duration: 0:00:01.999363 Num steps: 171 Reward: 0.0 Training time per step: 0.010 Avg Reward (Last 100): 1.218 Epsilon: 0.873\n",
      "Episode: 291 Duration: 0:00:02.200571 Num steps: 191 Reward: 0.0 Training time per step: 0.010 Avg Reward (Last 100): 1.218 Epsilon: 0.873\n",
      "Episode: 292 Duration: 0:00:02.633038 Num steps: 225 Reward: 1.0 Training time per step: 0.010 Avg Reward (Last 100): 1.228 Epsilon: 0.872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 293 Duration: 0:00:03.163306 Num steps: 275 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.248 Epsilon: 0.872\n",
      "Episode: 294 Duration: 0:00:02.009854 Num steps: 174 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.238 Epsilon: 0.872\n",
      "Episode: 295 Duration: 0:00:01.929301 Num steps: 167 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.228 Epsilon: 0.871\n",
      "Episode: 296 Duration: 0:00:02.046548 Num steps: 177 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.208 Epsilon: 0.871\n",
      "Episode: 297 Duration: 0:00:03.358813 Num steps: 290 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.218 Epsilon: 0.870\n",
      "Episode: 298 Duration: 0:00:02.759218 Num steps: 241 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.208 Epsilon: 0.870\n",
      "Episode: 299 Duration: 0:00:02.069036 Num steps: 179 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.198 Epsilon: 0.870\n",
      "Episode: 300 Duration: 0:00:02.861159 Num steps: 248 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.208 Epsilon: 0.869\n",
      "Episode: 301 Duration: 0:00:04.357679 Num steps: 381 Reward: 4.0 Training time per step: 0.009 Avg Reward (Last 100): 1.238 Epsilon: 0.869\n",
      "Episode: 302 Duration: 0:00:03.333219 Num steps: 290 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.257 Epsilon: 0.868\n",
      "Episode: 303 Duration: 0:00:01.952383 Num steps: 169 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.248 Epsilon: 0.868\n",
      "Episode: 304 Duration: 0:00:02.198272 Num steps: 187 Reward: 0.0 Training time per step: 0.010 Avg Reward (Last 100): 1.238 Epsilon: 0.867\n",
      "Episode: 305 Duration: 0:00:02.162415 Num steps: 186 Reward: 0.0 Training time per step: 0.010 Avg Reward (Last 100): 1.218 Epsilon: 0.867\n",
      "Episode: 306 Duration: 0:00:02.108015 Num steps: 181 Reward: 0.0 Training time per step: 0.010 Avg Reward (Last 100): 1.178 Epsilon: 0.867\n",
      "Episode: 307 Duration: 0:00:02.704446 Num steps: 232 Reward: 1.0 Training time per step: 0.010 Avg Reward (Last 100): 1.149 Epsilon: 0.866\n",
      "Episode: 308 Duration: 0:00:02.112488 Num steps: 184 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.149 Epsilon: 0.866\n",
      "Episode: 309 Duration: 0:00:02.795423 Num steps: 244 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.109 Epsilon: 0.866\n",
      "Episode: 310 Duration: 0:00:02.687859 Num steps: 234 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.109 Epsilon: 0.865\n",
      "Episode: 311 Duration: 0:00:01.926207 Num steps: 167 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.079 Epsilon: 0.865\n",
      "Episode: 312 Duration: 0:00:04.630077 Num steps: 406 Reward: 4.0 Training time per step: 0.009 Avg Reward (Last 100): 1.109 Epsilon: 0.864\n",
      "Episode: 313 Duration: 0:00:03.168804 Num steps: 277 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.129 Epsilon: 0.864\n",
      "Episode: 314 Duration: 0:00:03.098554 Num steps: 268 Reward: 2.0 Training time per step: 0.010 Avg Reward (Last 100): 1.139 Epsilon: 0.863\n",
      "Episode: 315 Duration: 0:00:03.532381 Num steps: 309 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.139 Epsilon: 0.863\n",
      "Episode: 316 Duration: 0:00:04.032691 Num steps: 351 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.129 Epsilon: 0.862\n",
      "Episode: 317 Duration: 0:00:03.635728 Num steps: 316 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.158 Epsilon: 0.861\n",
      "Episode: 318 Duration: 0:00:02.360200 Num steps: 206 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.158 Epsilon: 0.861\n",
      "Episode: 319 Duration: 0:00:04.600625 Num steps: 398 Reward: 4.0 Training time per step: 0.009 Avg Reward (Last 100): 1.198 Epsilon: 0.860\n",
      "Episode: 320 Duration: 0:00:03.823428 Num steps: 332 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.208 Epsilon: 0.860\n",
      "Episode: 321 Duration: 0:00:02.554747 Num steps: 223 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.218 Epsilon: 0.859\n",
      "Episode: 322 Duration: 0:00:03.012001 Num steps: 261 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.218 Epsilon: 0.859\n",
      "Episode: 323 Duration: 0:00:03.033881 Num steps: 261 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.218 Epsilon: 0.858\n",
      "Episode: 324 Duration: 0:00:04.642130 Num steps: 403 Reward: 4.0 Training time per step: 0.009 Avg Reward (Last 100): 1.218 Epsilon: 0.858\n",
      "Episode: 325 Duration: 0:00:02.169584 Num steps: 188 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.218 Epsilon: 0.857\n",
      "Episode: 326 Duration: 0:00:02.217669 Num steps: 193 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.208 Epsilon: 0.857\n",
      "Episode: 327 Duration: 0:00:04.378168 Num steps: 380 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.208 Epsilon: 0.856\n",
      "Copied model parameters to target network. total_t = 80000, period = 10000\n",
      "Episode: 328 Duration: 0:00:02.785954 Num steps: 227 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.188 Epsilon: 0.856\n",
      "Episode: 329 Duration: 0:00:02.442792 Num steps: 210 Reward: 1.0 Training time per step: 0.010 Avg Reward (Last 100): 1.178 Epsilon: 0.855\n",
      "Episode: 330 Duration: 0:00:02.311161 Num steps: 199 Reward: 0.0 Training time per step: 0.010 Avg Reward (Last 100): 1.158 Epsilon: 0.855\n",
      "Episode: 331 Duration: 0:00:01.889780 Num steps: 162 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.149 Epsilon: 0.855\n",
      "Episode: 332 Duration: 0:00:02.027512 Num steps: 173 Reward: 0.0 Training time per step: 0.010 Avg Reward (Last 100): 1.139 Epsilon: 0.855\n",
      "Episode: 333 Duration: 0:00:02.090430 Num steps: 180 Reward: 0.0 Training time per step: 0.010 Avg Reward (Last 100): 1.139 Epsilon: 0.854\n",
      "Episode: 334 Duration: 0:00:02.120435 Num steps: 182 Reward: 0.0 Training time per step: 0.010 Avg Reward (Last 100): 1.119 Epsilon: 0.854\n",
      "Episode: 335 Duration: 0:00:03.260886 Num steps: 281 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.119 Epsilon: 0.853\n",
      "Episode: 336 Duration: 0:00:02.478086 Num steps: 216 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.129 Epsilon: 0.853\n",
      "Episode: 337 Duration: 0:00:02.673407 Num steps: 232 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.139 Epsilon: 0.853\n",
      "Episode: 338 Duration: 0:00:02.599226 Num steps: 226 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.139 Epsilon: 0.852\n",
      "Episode: 339 Duration: 0:00:02.647962 Num steps: 230 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.129 Epsilon: 0.852\n",
      "Episode: 340 Duration: 0:00:02.005638 Num steps: 174 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.099 Epsilon: 0.851\n",
      "Episode: 341 Duration: 0:00:03.031099 Num steps: 265 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.099 Epsilon: 0.851\n",
      "Episode: 342 Duration: 0:00:02.012452 Num steps: 172 Reward: 0.0 Training time per step: 0.010 Avg Reward (Last 100): 1.099 Epsilon: 0.851\n",
      "Episode: 343 Duration: 0:00:02.024471 Num steps: 175 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.089 Epsilon: 0.850\n",
      "Episode: 344 Duration: 0:00:02.048135 Num steps: 178 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.069 Epsilon: 0.850\n",
      "Episode: 345 Duration: 0:00:02.671198 Num steps: 231 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.059 Epsilon: 0.850\n",
      "Episode: 346 Duration: 0:00:02.599527 Num steps: 226 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.069 Epsilon: 0.849\n",
      "Episode: 347 Duration: 0:00:03.155715 Num steps: 275 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.079 Epsilon: 0.849\n",
      "Episode: 348 Duration: 0:00:02.170710 Num steps: 189 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.079 Epsilon: 0.848\n",
      "Episode: 349 Duration: 0:00:03.292999 Num steps: 285 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.079 Epsilon: 0.848\n",
      "Episode: 350 Duration: 0:00:03.003926 Num steps: 259 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.099 Epsilon: 0.847\n",
      "Episode: 351 Duration: 0:00:02.107393 Num steps: 184 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.099 Epsilon: 0.847\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 352 Duration: 0:00:02.393027 Num steps: 206 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.109 Epsilon: 0.847\n",
      "Episode: 353 Duration: 0:00:03.279164 Num steps: 286 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.119 Epsilon: 0.846\n",
      "Episode: 354 Duration: 0:00:02.064697 Num steps: 180 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.089 Epsilon: 0.846\n",
      "Episode: 355 Duration: 0:00:02.038619 Num steps: 178 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.089 Epsilon: 0.845\n",
      "Episode: 356 Duration: 0:00:03.602750 Num steps: 313 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.119 Epsilon: 0.845\n",
      "Episode: 357 Duration: 0:00:01.891949 Num steps: 165 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.109 Epsilon: 0.845\n",
      "Episode: 358 Duration: 0:00:04.662237 Num steps: 405 Reward: 4.0 Training time per step: 0.009 Avg Reward (Last 100): 1.139 Epsilon: 0.844\n",
      "Episode: 359 Duration: 0:00:04.819534 Num steps: 418 Reward: 4.0 Training time per step: 0.009 Avg Reward (Last 100): 1.178 Epsilon: 0.843\n",
      "Episode: 360 Duration: 0:00:02.769174 Num steps: 239 Reward: 1.0 Training time per step: 0.010 Avg Reward (Last 100): 1.158 Epsilon: 0.843\n",
      "Episode: 361 Duration: 0:00:02.125854 Num steps: 184 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.158 Epsilon: 0.842\n",
      "Episode: 362 Duration: 0:00:02.679769 Num steps: 232 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.168 Epsilon: 0.842\n",
      "Episode: 363 Duration: 0:00:01.952380 Num steps: 170 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.168 Epsilon: 0.842\n",
      "Episode: 364 Duration: 0:00:02.562809 Num steps: 222 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.168 Epsilon: 0.841\n",
      "Episode: 365 Duration: 0:00:04.100542 Num steps: 357 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.198 Epsilon: 0.841\n",
      "Episode: 366 Duration: 0:00:02.103286 Num steps: 180 Reward: 0.0 Training time per step: 0.010 Avg Reward (Last 100): 1.188 Epsilon: 0.840\n",
      "Episode: 367 Duration: 0:00:02.190825 Num steps: 189 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.178 Epsilon: 0.840\n",
      "Episode: 368 Duration: 0:00:03.379587 Num steps: 292 Reward: 2.0 Training time per step: 0.010 Avg Reward (Last 100): 1.188 Epsilon: 0.839\n",
      "Episode: 369 Duration: 0:00:02.017274 Num steps: 175 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.168 Epsilon: 0.839\n",
      "Episode: 370 Duration: 0:00:02.464188 Num steps: 212 Reward: 1.0 Training time per step: 0.010 Avg Reward (Last 100): 1.178 Epsilon: 0.839\n",
      "Episode: 371 Duration: 0:00:02.581515 Num steps: 224 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.178 Epsilon: 0.838\n",
      "Copied model parameters to target network. total_t = 90000, period = 10000\n",
      "Episode: 372 Duration: 0:00:02.784579 Num steps: 223 Reward: 1.0 Training time per step: 0.010 Avg Reward (Last 100): 1.178 Epsilon: 0.838\n",
      "Episode: 373 Duration: 0:00:02.803034 Num steps: 242 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.188 Epsilon: 0.837\n",
      "Episode: 374 Duration: 0:00:02.084521 Num steps: 178 Reward: 0.0 Training time per step: 0.010 Avg Reward (Last 100): 1.188 Epsilon: 0.837\n",
      "Episode: 375 Duration: 0:00:01.946251 Num steps: 169 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.188 Epsilon: 0.837\n",
      "Episode: 376 Duration: 0:00:03.357643 Num steps: 288 Reward: 2.0 Training time per step: 0.010 Avg Reward (Last 100): 1.188 Epsilon: 0.836\n",
      "Episode: 377 Duration: 0:00:02.674457 Num steps: 232 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.178 Epsilon: 0.836\n",
      "Episode: 378 Duration: 0:00:02.092677 Num steps: 182 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.139 Epsilon: 0.836\n",
      "Episode: 379 Duration: 0:00:01.947192 Num steps: 167 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.129 Epsilon: 0.835\n",
      "Episode: 380 Duration: 0:00:01.990669 Num steps: 171 Reward: 0.0 Training time per step: 0.010 Avg Reward (Last 100): 1.119 Epsilon: 0.835\n",
      "Episode: 381 Duration: 0:00:03.164231 Num steps: 274 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.139 Epsilon: 0.834\n",
      "Episode: 382 Duration: 0:00:01.989421 Num steps: 172 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.129 Epsilon: 0.834\n",
      "Episode: 383 Duration: 0:00:02.266680 Num steps: 196 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.129 Epsilon: 0.834\n",
      "Episode: 384 Duration: 0:00:03.356149 Num steps: 291 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.149 Epsilon: 0.833\n",
      "Episode: 385 Duration: 0:00:03.236500 Num steps: 279 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.168 Epsilon: 0.833\n",
      "Episode: 386 Duration: 0:00:03.855300 Num steps: 334 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.168 Epsilon: 0.832\n",
      "Episode: 387 Duration: 0:00:02.664773 Num steps: 231 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.139 Epsilon: 0.832\n",
      "Episode: 388 Duration: 0:00:03.517655 Num steps: 303 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.129 Epsilon: 0.831\n",
      "Episode: 389 Duration: 0:00:01.997706 Num steps: 174 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.119 Epsilon: 0.831\n",
      "Episode: 390 Duration: 0:00:03.290892 Num steps: 283 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.109 Epsilon: 0.830\n",
      "Episode: 391 Duration: 0:00:01.914791 Num steps: 166 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.109 Epsilon: 0.830\n",
      "Episode: 392 Duration: 0:00:03.276978 Num steps: 282 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.129 Epsilon: 0.830\n",
      "Episode: 393 Duration: 0:00:02.700468 Num steps: 231 Reward: 1.0 Training time per step: 0.010 Avg Reward (Last 100): 1.129 Epsilon: 0.829\n",
      "Episode: 394 Duration: 0:00:03.911694 Num steps: 340 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.139 Epsilon: 0.829\n",
      "Episode: 395 Duration: 0:00:04.301147 Num steps: 373 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.168 Epsilon: 0.828\n",
      "Episode: 396 Duration: 0:00:02.847936 Num steps: 248 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.178 Epsilon: 0.827\n",
      "Episode: 397 Duration: 0:00:02.113208 Num steps: 183 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.178 Epsilon: 0.827\n",
      "Episode: 398 Duration: 0:00:03.894119 Num steps: 340 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.188 Epsilon: 0.827\n",
      "Episode: 399 Duration: 0:00:03.298458 Num steps: 286 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.198 Epsilon: 0.826\n",
      "Episode: 400 Duration: 0:00:02.980696 Num steps: 256 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.208 Epsilon: 0.826\n",
      "Episode: 401 Duration: 0:00:02.118090 Num steps: 183 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.198 Epsilon: 0.825\n",
      "Episode: 402 Duration: 0:00:03.410450 Num steps: 298 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.178 Epsilon: 0.825\n",
      "Episode: 403 Duration: 0:00:02.033535 Num steps: 173 Reward: 0.0 Training time per step: 0.010 Avg Reward (Last 100): 1.149 Epsilon: 0.824\n",
      "Episode: 404 Duration: 0:00:02.099974 Num steps: 181 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.149 Epsilon: 0.824\n",
      "Episode: 405 Duration: 0:00:02.144656 Num steps: 185 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.149 Epsilon: 0.824\n",
      "Episode: 406 Duration: 0:00:02.107946 Num steps: 183 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.149 Epsilon: 0.823\n",
      "Episode: 407 Duration: 0:00:02.165146 Num steps: 185 Reward: 0.0 Training time per step: 0.010 Avg Reward (Last 100): 1.149 Epsilon: 0.823\n",
      "Episode: 408 Duration: 0:00:04.712642 Num steps: 409 Reward: 4.0 Training time per step: 0.009 Avg Reward (Last 100): 1.178 Epsilon: 0.822\n",
      "Episode: 409 Duration: 0:00:03.487588 Num steps: 301 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.198 Epsilon: 0.822\n",
      "Episode: 410 Duration: 0:00:03.154190 Num steps: 274 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.208 Epsilon: 0.821\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 411 Duration: 0:00:01.970421 Num steps: 169 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.198 Epsilon: 0.821\n",
      "Episode: 412 Duration: 0:00:03.881245 Num steps: 338 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.228 Epsilon: 0.820\n",
      "Episode: 413 Duration: 0:00:02.114903 Num steps: 183 Reward: 0.0 Training time per step: 0.010 Avg Reward (Last 100): 1.188 Epsilon: 0.820\n",
      "Copied model parameters to target network. total_t = 100000, period = 10000\n",
      "Episode: 414 Duration: 0:00:03.084864 Num steps: 252 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.178 Epsilon: 0.820\n",
      "Episode: 415 Duration: 0:00:03.358572 Num steps: 288 Reward: 2.0 Training time per step: 0.010 Avg Reward (Last 100): 1.178 Epsilon: 0.819\n",
      "Episode: 416 Duration: 0:00:02.160033 Num steps: 184 Reward: 0.0 Training time per step: 0.010 Avg Reward (Last 100): 1.158 Epsilon: 0.819\n",
      "Episode: 417 Duration: 0:00:02.356242 Num steps: 201 Reward: 0.0 Training time per step: 0.010 Avg Reward (Last 100): 1.129 Epsilon: 0.818\n",
      "Episode: 418 Duration: 0:00:02.980071 Num steps: 259 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.119 Epsilon: 0.818\n",
      "Episode: 419 Duration: 0:00:01.948324 Num steps: 166 Reward: 0.0 Training time per step: 0.010 Avg Reward (Last 100): 1.109 Epsilon: 0.818\n",
      "Episode: 420 Duration: 0:00:02.878242 Num steps: 250 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.089 Epsilon: 0.817\n",
      "Episode: 421 Duration: 0:00:02.054131 Num steps: 177 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.069 Epsilon: 0.817\n",
      "Episode: 422 Duration: 0:00:04.041628 Num steps: 350 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.089 Epsilon: 0.816\n",
      "Episode: 423 Duration: 0:00:02.831487 Num steps: 244 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.079 Epsilon: 0.816\n",
      "Episode: 424 Duration: 0:00:03.946232 Num steps: 342 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.089 Epsilon: 0.815\n",
      "Episode: 425 Duration: 0:00:02.869766 Num steps: 249 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.059 Epsilon: 0.815\n",
      "Episode: 426 Duration: 0:00:01.910489 Num steps: 165 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.059 Epsilon: 0.814\n",
      "Episode: 427 Duration: 0:00:02.347291 Num steps: 202 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.069 Epsilon: 0.814\n",
      "Episode: 428 Duration: 0:00:02.678775 Num steps: 233 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.050 Epsilon: 0.814\n",
      "Episode: 429 Duration: 0:00:03.224131 Num steps: 282 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.059 Epsilon: 0.813\n",
      "Episode: 430 Duration: 0:00:03.316570 Num steps: 289 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.079 Epsilon: 0.813\n",
      "Episode: 431 Duration: 0:00:02.192207 Num steps: 187 Reward: 0.0 Training time per step: 0.010 Avg Reward (Last 100): 1.079 Epsilon: 0.812\n",
      "Episode: 432 Duration: 0:00:03.160764 Num steps: 273 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.099 Epsilon: 0.812\n",
      "Episode: 433 Duration: 0:00:02.121454 Num steps: 182 Reward: 0.0 Training time per step: 0.010 Avg Reward (Last 100): 1.099 Epsilon: 0.811\n",
      "Episode: 434 Duration: 0:00:04.166545 Num steps: 361 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.129 Epsilon: 0.811\n",
      "Episode: 435 Duration: 0:00:02.222505 Num steps: 193 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.129 Epsilon: 0.810\n",
      "Episode: 436 Duration: 0:00:03.132311 Num steps: 273 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.129 Epsilon: 0.810\n",
      "Episode: 437 Duration: 0:00:02.786398 Num steps: 240 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.129 Epsilon: 0.810\n",
      "Episode: 438 Duration: 0:00:02.808985 Num steps: 244 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.129 Epsilon: 0.809\n",
      "Episode: 439 Duration: 0:00:03.190147 Num steps: 277 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.139 Epsilon: 0.809\n",
      "Episode: 440 Duration: 0:00:02.671611 Num steps: 231 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.139 Epsilon: 0.808\n",
      "Episode: 441 Duration: 0:00:03.410256 Num steps: 297 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.158 Epsilon: 0.808\n",
      "Episode: 442 Duration: 0:00:02.023168 Num steps: 175 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.139 Epsilon: 0.807\n",
      "Episode: 443 Duration: 0:00:03.782374 Num steps: 325 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.168 Epsilon: 0.807\n",
      "Episode: 444 Duration: 0:00:02.132131 Num steps: 185 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.168 Epsilon: 0.806\n",
      "Episode: 445 Duration: 0:00:02.913174 Num steps: 252 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.188 Epsilon: 0.806\n",
      "Episode: 446 Duration: 0:00:03.205886 Num steps: 278 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.198 Epsilon: 0.805\n",
      "Episode: 447 Duration: 0:00:03.591746 Num steps: 310 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.208 Epsilon: 0.805\n",
      "Episode: 448 Duration: 0:00:04.115025 Num steps: 356 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.218 Epsilon: 0.804\n",
      "Episode: 449 Duration: 0:00:03.140154 Num steps: 271 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.238 Epsilon: 0.804\n",
      "Episode: 450 Duration: 0:00:02.104096 Num steps: 179 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.218 Epsilon: 0.803\n",
      "Episode: 451 Duration: 0:00:03.451608 Num steps: 297 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.228 Epsilon: 0.803\n",
      "Episode: 452 Duration: 0:00:02.891996 Num steps: 250 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.248 Epsilon: 0.802\n",
      "Copied model parameters to target network. total_t = 110000, period = 10000\n",
      "Episode: 453 Duration: 0:00:03.316900 Num steps: 271 Reward: 2.0 Training time per step: 0.010 Avg Reward (Last 100): 1.257 Epsilon: 0.802\n",
      "Episode: 454 Duration: 0:00:02.164428 Num steps: 183 Reward: 0.0 Training time per step: 0.010 Avg Reward (Last 100): 1.238 Epsilon: 0.802\n",
      "Episode: 455 Duration: 0:00:02.187003 Num steps: 167 Reward: 0.0 Training time per step: 0.011 Avg Reward (Last 100): 1.238 Epsilon: 0.801\n",
      "Episode: 456 Duration: 0:00:02.228045 Num steps: 186 Reward: 0.0 Training time per step: 0.010 Avg Reward (Last 100): 1.238 Epsilon: 0.801\n",
      "Episode: 457 Duration: 0:00:02.313081 Num steps: 174 Reward: 0.0 Training time per step: 0.011 Avg Reward (Last 100): 1.208 Epsilon: 0.801\n",
      "Episode: 458 Duration: 0:00:02.695399 Num steps: 217 Reward: 1.0 Training time per step: 0.010 Avg Reward (Last 100): 1.218 Epsilon: 0.800\n",
      "Episode: 459 Duration: 0:00:02.939312 Num steps: 253 Reward: 2.0 Training time per step: 0.010 Avg Reward (Last 100): 1.198 Epsilon: 0.800\n",
      "Episode: 460 Duration: 0:00:02.359625 Num steps: 183 Reward: 0.0 Training time per step: 0.011 Avg Reward (Last 100): 1.158 Epsilon: 0.800\n",
      "Episode: 461 Duration: 0:00:02.621231 Num steps: 227 Reward: 1.0 Training time per step: 0.010 Avg Reward (Last 100): 1.158 Epsilon: 0.799\n",
      "Episode: 462 Duration: 0:00:02.038832 Num steps: 177 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.158 Epsilon: 0.799\n",
      "Episode: 463 Duration: 0:00:02.014069 Num steps: 166 Reward: 0.0 Training time per step: 0.010 Avg Reward (Last 100): 1.149 Epsilon: 0.798\n",
      "Episode: 464 Duration: 0:00:01.861557 Num steps: 158 Reward: 0.0 Training time per step: 0.010 Avg Reward (Last 100): 1.149 Epsilon: 0.798\n",
      "Episode: 465 Duration: 0:00:02.074315 Num steps: 177 Reward: 0.0 Training time per step: 0.010 Avg Reward (Last 100): 1.139 Epsilon: 0.798\n",
      "Episode: 466 Duration: 0:00:02.028724 Num steps: 175 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.109 Epsilon: 0.798\n",
      "Episode: 467 Duration: 0:00:02.627147 Num steps: 226 Reward: 1.0 Training time per step: 0.010 Avg Reward (Last 100): 1.119 Epsilon: 0.797\n",
      "Episode: 468 Duration: 0:00:03.590377 Num steps: 310 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.149 Epsilon: 0.797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 469 Duration: 0:00:02.392681 Num steps: 206 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.139 Epsilon: 0.796\n",
      "Episode: 470 Duration: 0:00:02.944844 Num steps: 255 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.158 Epsilon: 0.796\n",
      "Episode: 471 Duration: 0:00:02.152472 Num steps: 186 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.149 Epsilon: 0.795\n",
      "Episode: 472 Duration: 0:00:02.757310 Num steps: 234 Reward: 1.0 Training time per step: 0.010 Avg Reward (Last 100): 1.149 Epsilon: 0.795\n",
      "Episode: 473 Duration: 0:00:04.370852 Num steps: 377 Reward: 3.0 Training time per step: 0.010 Avg Reward (Last 100): 1.168 Epsilon: 0.794\n",
      "Episode: 474 Duration: 0:00:03.668222 Num steps: 314 Reward: 2.0 Training time per step: 0.010 Avg Reward (Last 100): 1.178 Epsilon: 0.794\n",
      "Episode: 475 Duration: 0:00:03.986692 Num steps: 343 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.208 Epsilon: 0.793\n",
      "Episode: 476 Duration: 0:00:02.444656 Num steps: 212 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.218 Epsilon: 0.793\n",
      "Episode: 477 Duration: 0:00:02.424280 Num steps: 206 Reward: 0.0 Training time per step: 0.010 Avg Reward (Last 100): 1.198 Epsilon: 0.792\n",
      "Episode: 478 Duration: 0:00:03.226391 Num steps: 271 Reward: 2.0 Training time per step: 0.010 Avg Reward (Last 100): 1.208 Epsilon: 0.792\n",
      "Episode: 479 Duration: 0:00:02.674428 Num steps: 231 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.218 Epsilon: 0.792\n",
      "Episode: 480 Duration: 0:00:02.651492 Num steps: 228 Reward: 1.0 Training time per step: 0.010 Avg Reward (Last 100): 1.228 Epsilon: 0.791\n",
      "Episode: 481 Duration: 0:00:03.594079 Num steps: 309 Reward: 2.0 Training time per step: 0.010 Avg Reward (Last 100): 1.248 Epsilon: 0.791\n",
      "Episode: 482 Duration: 0:00:02.671366 Num steps: 231 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.238 Epsilon: 0.790\n",
      "Episode: 483 Duration: 0:00:02.775250 Num steps: 238 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.248 Epsilon: 0.790\n",
      "Episode: 484 Duration: 0:00:02.089713 Num steps: 180 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.248 Epsilon: 0.789\n",
      "Episode: 485 Duration: 0:00:02.574526 Num steps: 223 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.238 Epsilon: 0.789\n",
      "Episode: 486 Duration: 0:00:03.285119 Num steps: 284 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.238 Epsilon: 0.788\n",
      "Episode: 487 Duration: 0:00:02.417838 Num steps: 208 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.228 Epsilon: 0.788\n",
      "Episode: 488 Duration: 0:00:02.192572 Num steps: 189 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.218 Epsilon: 0.788\n",
      "Episode: 489 Duration: 0:00:02.081848 Num steps: 179 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.198 Epsilon: 0.787\n",
      "Episode: 490 Duration: 0:00:02.086007 Num steps: 180 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.198 Epsilon: 0.787\n",
      "Episode: 491 Duration: 0:00:03.311663 Num steps: 287 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.198 Epsilon: 0.787\n",
      "Episode: 492 Duration: 0:00:02.749790 Num steps: 236 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.208 Epsilon: 0.786\n",
      "Episode: 493 Duration: 0:00:01.998846 Num steps: 171 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.188 Epsilon: 0.786\n",
      "Episode: 494 Duration: 0:00:02.628965 Num steps: 227 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.188 Epsilon: 0.785\n",
      "Episode: 495 Duration: 0:00:03.888764 Num steps: 336 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.188 Epsilon: 0.785\n",
      "Episode: 496 Duration: 0:00:02.428678 Num steps: 209 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.168 Epsilon: 0.784\n",
      "Copied model parameters to target network. total_t = 120000, period = 10000\n",
      "Episode: 497 Duration: 0:00:03.765740 Num steps: 309 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.188 Epsilon: 0.784\n",
      "Episode: 498 Duration: 0:00:03.324200 Num steps: 287 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.208 Epsilon: 0.783\n",
      "Episode: 499 Duration: 0:00:02.431153 Num steps: 208 Reward: 1.0 Training time per step: 0.010 Avg Reward (Last 100): 1.188 Epsilon: 0.783\n",
      "Episode: 500 Duration: 0:00:03.389956 Num steps: 291 Reward: 2.0 Training time per step: 0.010 Avg Reward (Last 100): 1.188 Epsilon: 0.782\n",
      "Episode: 501 Duration: 0:00:01.977154 Num steps: 170 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.178 Epsilon: 0.782\n",
      "Episode: 502 Duration: 0:00:03.814065 Num steps: 329 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.208 Epsilon: 0.782\n",
      "Episode: 503 Duration: 0:00:02.743956 Num steps: 238 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.198 Epsilon: 0.781\n",
      "Episode: 504 Duration: 0:00:02.114194 Num steps: 182 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.198 Epsilon: 0.781\n",
      "Episode: 505 Duration: 0:00:03.862744 Num steps: 333 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.228 Epsilon: 0.780\n",
      "Episode: 506 Duration: 0:00:04.194610 Num steps: 362 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.257 Epsilon: 0.780\n",
      "Episode: 507 Duration: 0:00:02.652485 Num steps: 225 Reward: 1.0 Training time per step: 0.010 Avg Reward (Last 100): 1.267 Epsilon: 0.779\n",
      "Episode: 508 Duration: 0:00:03.262869 Num steps: 280 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.287 Epsilon: 0.779\n",
      "Episode: 509 Duration: 0:00:02.388079 Num steps: 205 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.257 Epsilon: 0.778\n",
      "Episode: 510 Duration: 0:00:02.407281 Num steps: 207 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.248 Epsilon: 0.778\n",
      "Episode: 511 Duration: 0:00:02.062591 Num steps: 178 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.228 Epsilon: 0.778\n",
      "Episode: 512 Duration: 0:00:03.910952 Num steps: 337 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.257 Epsilon: 0.777\n",
      "Episode: 513 Duration: 0:00:03.950432 Num steps: 342 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.257 Epsilon: 0.776\n",
      "Episode: 514 Duration: 0:00:03.345643 Num steps: 286 Reward: 2.0 Training time per step: 0.010 Avg Reward (Last 100): 1.277 Epsilon: 0.776\n",
      "Episode: 515 Duration: 0:00:02.926028 Num steps: 252 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.277 Epsilon: 0.775\n",
      "Episode: 516 Duration: 0:00:05.157610 Num steps: 445 Reward: 6.0 Training time per step: 0.009 Avg Reward (Last 100): 1.317 Epsilon: 0.775\n",
      "Episode: 517 Duration: 0:00:05.944434 Num steps: 512 Reward: 6.0 Training time per step: 0.009 Avg Reward (Last 100): 1.376 Epsilon: 0.774\n",
      "Episode: 518 Duration: 0:00:02.637892 Num steps: 228 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.386 Epsilon: 0.773\n",
      "Episode: 519 Duration: 0:00:03.934901 Num steps: 338 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.396 Epsilon: 0.773\n",
      "Episode: 520 Duration: 0:00:02.020611 Num steps: 174 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.396 Epsilon: 0.772\n",
      "Episode: 521 Duration: 0:00:01.956377 Num steps: 169 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.376 Epsilon: 0.772\n",
      "Episode: 522 Duration: 0:00:03.712098 Num steps: 320 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.406 Epsilon: 0.771\n",
      "Episode: 523 Duration: 0:00:02.780581 Num steps: 241 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.386 Epsilon: 0.771\n",
      "Episode: 524 Duration: 0:00:03.229043 Num steps: 279 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.396 Epsilon: 0.771\n",
      "Episode: 525 Duration: 0:00:03.224487 Num steps: 279 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.386 Epsilon: 0.770\n",
      "Episode: 526 Duration: 0:00:02.575525 Num steps: 221 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.386 Epsilon: 0.770\n",
      "Episode: 527 Duration: 0:00:02.791626 Num steps: 239 Reward: 1.0 Training time per step: 0.010 Avg Reward (Last 100): 1.396 Epsilon: 0.769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 528 Duration: 0:00:02.560312 Num steps: 217 Reward: 1.0 Training time per step: 0.010 Avg Reward (Last 100): 1.396 Epsilon: 0.769\n",
      "Episode: 529 Duration: 0:00:02.243020 Num steps: 193 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.386 Epsilon: 0.768\n",
      "Episode: 530 Duration: 0:00:02.635149 Num steps: 226 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.376 Epsilon: 0.768\n",
      "Episode: 531 Duration: 0:00:03.113268 Num steps: 270 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.366 Epsilon: 0.768\n",
      "Episode: 532 Duration: 0:00:01.954393 Num steps: 169 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.366 Epsilon: 0.767\n",
      "Episode: 533 Duration: 0:00:02.465119 Num steps: 212 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.356 Epsilon: 0.767\n",
      "Episode: 534 Duration: 0:00:02.448431 Num steps: 211 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.366 Epsilon: 0.767\n",
      "Copied model parameters to target network. total_t = 130000, period = 10000\n",
      "Episode: 535 Duration: 0:00:04.145128 Num steps: 341 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.366 Epsilon: 0.766\n",
      "Episode: 536 Duration: 0:00:01.922235 Num steps: 166 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.366 Epsilon: 0.766\n",
      "Episode: 537 Duration: 0:00:03.814196 Num steps: 326 Reward: 2.0 Training time per step: 0.010 Avg Reward (Last 100): 1.366 Epsilon: 0.765\n",
      "Episode: 538 Duration: 0:00:02.190740 Num steps: 187 Reward: 0.0 Training time per step: 0.010 Avg Reward (Last 100): 1.356 Epsilon: 0.765\n",
      "Episode: 539 Duration: 0:00:03.988375 Num steps: 342 Reward: 3.0 Training time per step: 0.010 Avg Reward (Last 100): 1.376 Epsilon: 0.764\n",
      "Episode: 540 Duration: 0:00:02.771966 Num steps: 239 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.366 Epsilon: 0.764\n",
      "Episode: 541 Duration: 0:00:01.988638 Num steps: 171 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.356 Epsilon: 0.763\n",
      "Episode: 542 Duration: 0:00:01.995174 Num steps: 172 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.337 Epsilon: 0.763\n",
      "Episode: 543 Duration: 0:00:02.052597 Num steps: 175 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.337 Epsilon: 0.763\n",
      "Episode: 544 Duration: 0:00:03.028949 Num steps: 261 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.317 Epsilon: 0.762\n",
      "Episode: 545 Duration: 0:00:01.979546 Num steps: 172 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.317 Epsilon: 0.762\n",
      "Episode: 546 Duration: 0:00:03.524131 Num steps: 305 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.317 Epsilon: 0.761\n",
      "Episode: 547 Duration: 0:00:01.973303 Num steps: 170 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.297 Epsilon: 0.761\n",
      "Episode: 548 Duration: 0:00:03.398593 Num steps: 292 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.297 Epsilon: 0.761\n",
      "Episode: 549 Duration: 0:00:02.080056 Num steps: 179 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.267 Epsilon: 0.760\n",
      "Episode: 550 Duration: 0:00:03.236497 Num steps: 278 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.267 Epsilon: 0.760\n",
      "Episode: 551 Duration: 0:00:02.539037 Num steps: 216 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.277 Epsilon: 0.759\n",
      "Episode: 552 Duration: 0:00:02.124775 Num steps: 183 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.248 Epsilon: 0.759\n",
      "Episode: 553 Duration: 0:00:02.055293 Num steps: 178 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.228 Epsilon: 0.759\n",
      "Episode: 554 Duration: 0:00:03.176484 Num steps: 273 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.228 Epsilon: 0.758\n",
      "Episode: 555 Duration: 0:00:02.043583 Num steps: 175 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.228 Epsilon: 0.758\n",
      "Episode: 556 Duration: 0:00:03.872446 Num steps: 333 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.257 Epsilon: 0.757\n",
      "Episode: 557 Duration: 0:00:02.696574 Num steps: 231 Reward: 1.0 Training time per step: 0.010 Avg Reward (Last 100): 1.267 Epsilon: 0.757\n",
      "Episode: 558 Duration: 0:00:02.449462 Num steps: 210 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.277 Epsilon: 0.756\n",
      "Episode: 559 Duration: 0:00:02.695624 Num steps: 231 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.277 Epsilon: 0.756\n",
      "Episode: 560 Duration: 0:00:02.010028 Num steps: 174 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.257 Epsilon: 0.756\n",
      "Episode: 561 Duration: 0:00:02.631348 Num steps: 226 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.267 Epsilon: 0.755\n",
      "Episode: 562 Duration: 0:00:03.131028 Num steps: 268 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.277 Epsilon: 0.755\n",
      "Episode: 563 Duration: 0:00:02.669666 Num steps: 229 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.287 Epsilon: 0.754\n",
      "Episode: 564 Duration: 0:00:03.311944 Num steps: 286 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.307 Epsilon: 0.754\n",
      "Episode: 565 Duration: 0:00:01.933361 Num steps: 166 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.307 Epsilon: 0.754\n",
      "Episode: 566 Duration: 0:00:03.594902 Num steps: 310 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.327 Epsilon: 0.753\n",
      "Episode: 567 Duration: 0:00:02.774753 Num steps: 238 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.337 Epsilon: 0.753\n",
      "Episode: 568 Duration: 0:00:01.959284 Num steps: 169 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.327 Epsilon: 0.752\n",
      "Episode: 569 Duration: 0:00:02.054897 Num steps: 175 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.297 Epsilon: 0.752\n",
      "Episode: 570 Duration: 0:00:02.665820 Num steps: 228 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.297 Epsilon: 0.752\n",
      "Episode: 571 Duration: 0:00:02.155983 Num steps: 186 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.277 Epsilon: 0.751\n",
      "Episode: 572 Duration: 0:00:03.284262 Num steps: 283 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.297 Epsilon: 0.751\n",
      "Episode: 573 Duration: 0:00:03.181804 Num steps: 273 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.307 Epsilon: 0.750\n",
      "Episode: 574 Duration: 0:00:02.775373 Num steps: 239 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.287 Epsilon: 0.750\n",
      "Episode: 575 Duration: 0:00:02.074245 Num steps: 177 Reward: 0.0 Training time per step: 0.010 Avg Reward (Last 100): 1.267 Epsilon: 0.750\n",
      "Episode: 576 Duration: 0:00:02.633762 Num steps: 227 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.248 Epsilon: 0.749\n",
      "Episode: 577 Duration: 0:00:03.686725 Num steps: 317 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.267 Epsilon: 0.749\n",
      "Episode: 578 Duration: 0:00:02.457879 Num steps: 211 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.277 Epsilon: 0.748\n",
      "Copied model parameters to target network. total_t = 140000, period = 10000\n",
      "Episode: 579 Duration: 0:00:03.508124 Num steps: 281 Reward: 2.0 Training time per step: 0.010 Avg Reward (Last 100): 1.277 Epsilon: 0.748\n",
      "Episode: 580 Duration: 0:00:03.389758 Num steps: 289 Reward: 2.0 Training time per step: 0.010 Avg Reward (Last 100): 1.287 Epsilon: 0.747\n",
      "Episode: 581 Duration: 0:00:01.989610 Num steps: 165 Reward: 0.0 Training time per step: 0.010 Avg Reward (Last 100): 1.277 Epsilon: 0.747\n",
      "Episode: 582 Duration: 0:00:01.901016 Num steps: 164 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.257 Epsilon: 0.747\n",
      "Episode: 583 Duration: 0:00:03.585067 Num steps: 301 Reward: 2.0 Training time per step: 0.010 Avg Reward (Last 100): 1.267 Epsilon: 0.746\n",
      "Episode: 584 Duration: 0:00:02.901216 Num steps: 247 Reward: 2.0 Training time per step: 0.010 Avg Reward (Last 100): 1.277 Epsilon: 0.746\n",
      "Episode: 585 Duration: 0:00:04.260001 Num steps: 365 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.307 Epsilon: 0.745\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 586 Duration: 0:00:03.264321 Num steps: 280 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.317 Epsilon: 0.744\n",
      "Episode: 587 Duration: 0:00:02.683631 Num steps: 228 Reward: 1.0 Training time per step: 0.010 Avg Reward (Last 100): 1.307 Epsilon: 0.744\n",
      "Episode: 588 Duration: 0:00:01.970390 Num steps: 170 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.297 Epsilon: 0.744\n",
      "Episode: 589 Duration: 0:00:03.125206 Num steps: 268 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.317 Epsilon: 0.743\n",
      "Episode: 590 Duration: 0:00:02.859033 Num steps: 245 Reward: 1.0 Training time per step: 0.010 Avg Reward (Last 100): 1.327 Epsilon: 0.743\n",
      "Episode: 591 Duration: 0:00:02.236217 Num steps: 187 Reward: 0.0 Training time per step: 0.010 Avg Reward (Last 100): 1.327 Epsilon: 0.742\n",
      "Episode: 592 Duration: 0:00:02.063839 Num steps: 176 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.307 Epsilon: 0.742\n",
      "Episode: 593 Duration: 0:00:03.905767 Num steps: 337 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.327 Epsilon: 0.742\n",
      "Episode: 594 Duration: 0:00:03.344068 Num steps: 288 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.347 Epsilon: 0.741\n",
      "Episode: 595 Duration: 0:00:05.123937 Num steps: 443 Reward: 5.0 Training time per step: 0.009 Avg Reward (Last 100): 1.386 Epsilon: 0.740\n",
      "Episode: 596 Duration: 0:00:02.631785 Num steps: 227 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.366 Epsilon: 0.740\n",
      "Episode: 597 Duration: 0:00:02.157445 Num steps: 181 Reward: 0.0 Training time per step: 0.010 Avg Reward (Last 100): 1.356 Epsilon: 0.739\n",
      "Episode: 598 Duration: 0:00:02.010625 Num steps: 173 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.327 Epsilon: 0.739\n",
      "Episode: 599 Duration: 0:00:02.089185 Num steps: 179 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.307 Epsilon: 0.739\n",
      "Episode: 600 Duration: 0:00:02.648731 Num steps: 226 Reward: 1.0 Training time per step: 0.010 Avg Reward (Last 100): 1.307 Epsilon: 0.738\n",
      "Episode: 601 Duration: 0:00:02.650676 Num steps: 228 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.297 Epsilon: 0.738\n",
      "Episode: 602 Duration: 0:00:01.917610 Num steps: 163 Reward: 0.0 Training time per step: 0.010 Avg Reward (Last 100): 1.297 Epsilon: 0.738\n",
      "Episode: 603 Duration: 0:00:02.751314 Num steps: 234 Reward: 1.0 Training time per step: 0.010 Avg Reward (Last 100): 1.277 Epsilon: 0.737\n",
      "Episode: 604 Duration: 0:00:02.680369 Num steps: 228 Reward: 1.0 Training time per step: 0.010 Avg Reward (Last 100): 1.277 Epsilon: 0.737\n",
      "Episode: 605 Duration: 0:00:02.715702 Num steps: 230 Reward: 1.0 Training time per step: 0.010 Avg Reward (Last 100): 1.287 Epsilon: 0.736\n",
      "Episode: 606 Duration: 0:00:02.054969 Num steps: 177 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.257 Epsilon: 0.736\n",
      "Episode: 607 Duration: 0:00:02.823567 Num steps: 242 Reward: 2.0 Training time per step: 0.010 Avg Reward (Last 100): 1.248 Epsilon: 0.736\n",
      "Episode: 608 Duration: 0:00:02.012432 Num steps: 173 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.238 Epsilon: 0.735\n",
      "Episode: 609 Duration: 0:00:02.828939 Num steps: 242 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.228 Epsilon: 0.735\n",
      "Episode: 610 Duration: 0:00:02.791687 Num steps: 240 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.228 Epsilon: 0.735\n",
      "Episode: 611 Duration: 0:00:01.951634 Num steps: 168 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.218 Epsilon: 0.734\n",
      "Episode: 612 Duration: 0:00:04.126765 Num steps: 354 Reward: 4.0 Training time per step: 0.009 Avg Reward (Last 100): 1.257 Epsilon: 0.734\n",
      "Episode: 613 Duration: 0:00:02.685852 Num steps: 232 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.238 Epsilon: 0.733\n",
      "Episode: 614 Duration: 0:00:02.019349 Num steps: 174 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.208 Epsilon: 0.733\n",
      "Episode: 615 Duration: 0:00:03.815102 Num steps: 327 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.218 Epsilon: 0.732\n",
      "Episode: 616 Duration: 0:00:03.546869 Num steps: 306 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.228 Epsilon: 0.732\n",
      "Episode: 617 Duration: 0:00:03.137621 Num steps: 268 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.188 Epsilon: 0.731\n",
      "Episode: 618 Duration: 0:00:02.819222 Num steps: 242 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.139 Epsilon: 0.731\n",
      "Episode: 619 Duration: 0:00:03.727217 Num steps: 322 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.158 Epsilon: 0.730\n",
      "Copied model parameters to target network. total_t = 150000, period = 10000\n",
      "Episode: 620 Duration: 0:00:02.665171 Num steps: 210 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.139 Epsilon: 0.730\n",
      "Episode: 621 Duration: 0:00:03.195894 Num steps: 273 Reward: 2.0 Training time per step: 0.010 Avg Reward (Last 100): 1.158 Epsilon: 0.729\n",
      "Episode: 622 Duration: 0:00:03.132412 Num steps: 269 Reward: 2.0 Training time per step: 0.010 Avg Reward (Last 100): 1.178 Epsilon: 0.729\n",
      "Episode: 623 Duration: 0:00:02.645867 Num steps: 225 Reward: 1.0 Training time per step: 0.010 Avg Reward (Last 100): 1.158 Epsilon: 0.728\n",
      "Episode: 624 Duration: 0:00:03.080202 Num steps: 264 Reward: 2.0 Training time per step: 0.010 Avg Reward (Last 100): 1.168 Epsilon: 0.728\n",
      "Episode: 625 Duration: 0:00:02.059536 Num steps: 177 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.149 Epsilon: 0.728\n",
      "Episode: 626 Duration: 0:00:02.812019 Num steps: 241 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.139 Epsilon: 0.727\n",
      "Episode: 627 Duration: 0:00:02.013119 Num steps: 168 Reward: 0.0 Training time per step: 0.010 Avg Reward (Last 100): 1.129 Epsilon: 0.727\n",
      "Episode: 628 Duration: 0:00:01.979303 Num steps: 169 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.119 Epsilon: 0.727\n",
      "Episode: 629 Duration: 0:00:02.501599 Num steps: 214 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.119 Epsilon: 0.726\n",
      "Episode: 630 Duration: 0:00:03.455563 Num steps: 296 Reward: 2.0 Training time per step: 0.010 Avg Reward (Last 100): 1.139 Epsilon: 0.726\n",
      "Episode: 631 Duration: 0:00:02.056027 Num steps: 176 Reward: 0.0 Training time per step: 0.010 Avg Reward (Last 100): 1.129 Epsilon: 0.725\n",
      "Episode: 632 Duration: 0:00:02.336008 Num steps: 201 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.119 Epsilon: 0.725\n",
      "Episode: 633 Duration: 0:00:01.923940 Num steps: 161 Reward: 0.0 Training time per step: 0.010 Avg Reward (Last 100): 1.119 Epsilon: 0.725\n",
      "Episode: 634 Duration: 0:00:02.867586 Num steps: 245 Reward: 1.0 Training time per step: 0.010 Avg Reward (Last 100): 1.119 Epsilon: 0.724\n",
      "Episode: 635 Duration: 0:00:01.907800 Num steps: 163 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.109 Epsilon: 0.724\n",
      "Episode: 636 Duration: 0:00:03.996029 Num steps: 340 Reward: 3.0 Training time per step: 0.010 Avg Reward (Last 100): 1.109 Epsilon: 0.723\n",
      "Episode: 637 Duration: 0:00:02.021934 Num steps: 174 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.109 Epsilon: 0.723\n",
      "Episode: 638 Duration: 0:00:02.447282 Num steps: 209 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.099 Epsilon: 0.723\n",
      "Episode: 639 Duration: 0:00:02.419334 Num steps: 208 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.109 Epsilon: 0.722\n",
      "Episode: 640 Duration: 0:00:02.087804 Num steps: 177 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.079 Epsilon: 0.722\n",
      "Episode: 641 Duration: 0:00:03.983873 Num steps: 341 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.099 Epsilon: 0.721\n",
      "Episode: 642 Duration: 0:00:02.794798 Num steps: 240 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.109 Epsilon: 0.721\n",
      "Episode: 643 Duration: 0:00:02.311861 Num steps: 196 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.119 Epsilon: 0.721\n",
      "Episode: 644 Duration: 0:00:02.828613 Num steps: 243 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.129 Epsilon: 0.720\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 645 Duration: 0:00:03.136386 Num steps: 268 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.139 Epsilon: 0.720\n",
      "Episode: 646 Duration: 0:00:02.870861 Num steps: 245 Reward: 1.0 Training time per step: 0.010 Avg Reward (Last 100): 1.149 Epsilon: 0.719\n",
      "Episode: 647 Duration: 0:00:03.221683 Num steps: 277 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.149 Epsilon: 0.719\n",
      "Episode: 648 Duration: 0:00:02.626294 Num steps: 226 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.158 Epsilon: 0.718\n",
      "Episode: 649 Duration: 0:00:02.106121 Num steps: 182 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.139 Epsilon: 0.718\n",
      "Episode: 650 Duration: 0:00:03.178384 Num steps: 272 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.158 Epsilon: 0.718\n",
      "Episode: 651 Duration: 0:00:02.368019 Num steps: 203 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.149 Epsilon: 0.717\n",
      "Episode: 652 Duration: 0:00:01.964825 Num steps: 169 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.139 Epsilon: 0.717\n",
      "Episode: 653 Duration: 0:00:01.913827 Num steps: 163 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.139 Epsilon: 0.717\n",
      "Episode: 654 Duration: 0:00:02.042481 Num steps: 176 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.139 Epsilon: 0.716\n",
      "Episode: 655 Duration: 0:00:04.710733 Num steps: 407 Reward: 4.0 Training time per step: 0.009 Avg Reward (Last 100): 1.158 Epsilon: 0.716\n",
      "Episode: 656 Duration: 0:00:01.943227 Num steps: 166 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.158 Epsilon: 0.715\n",
      "Episode: 657 Duration: 0:00:02.716163 Num steps: 233 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.139 Epsilon: 0.715\n",
      "Episode: 658 Duration: 0:00:02.039394 Num steps: 174 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.129 Epsilon: 0.715\n",
      "Episode: 659 Duration: 0:00:01.950792 Num steps: 166 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.119 Epsilon: 0.714\n",
      "Episode: 660 Duration: 0:00:03.090666 Num steps: 264 Reward: 2.0 Training time per step: 0.010 Avg Reward (Last 100): 1.129 Epsilon: 0.714\n",
      "Episode: 661 Duration: 0:00:02.681195 Num steps: 230 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.139 Epsilon: 0.713\n",
      "Episode: 662 Duration: 0:00:01.989369 Num steps: 170 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.129 Epsilon: 0.713\n",
      "Episode: 663 Duration: 0:00:02.891651 Num steps: 248 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.119 Epsilon: 0.713\n",
      "Episode: 664 Duration: 0:00:02.073917 Num steps: 178 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.109 Epsilon: 0.712\n",
      "Copied model parameters to target network. total_t = 160000, period = 10000\n",
      "Episode: 665 Duration: 0:00:03.644050 Num steps: 296 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.109 Epsilon: 0.712\n",
      "Episode: 666 Duration: 0:00:02.100671 Num steps: 177 Reward: 0.0 Training time per step: 0.010 Avg Reward (Last 100): 1.109 Epsilon: 0.711\n",
      "Episode: 667 Duration: 0:00:02.031725 Num steps: 172 Reward: 0.0 Training time per step: 0.010 Avg Reward (Last 100): 1.089 Epsilon: 0.711\n",
      "Episode: 668 Duration: 0:00:02.976448 Num steps: 252 Reward: 1.0 Training time per step: 0.010 Avg Reward (Last 100): 1.089 Epsilon: 0.711\n",
      "Episode: 669 Duration: 0:00:02.128730 Num steps: 180 Reward: 0.0 Training time per step: 0.010 Avg Reward (Last 100): 1.089 Epsilon: 0.710\n",
      "Episode: 670 Duration: 0:00:02.937679 Num steps: 252 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.099 Epsilon: 0.710\n",
      "Episode: 671 Duration: 0:00:02.708215 Num steps: 230 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.099 Epsilon: 0.709\n",
      "Episode: 672 Duration: 0:00:02.918758 Num steps: 251 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.119 Epsilon: 0.709\n",
      "Episode: 673 Duration: 0:00:02.834296 Num steps: 245 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.109 Epsilon: 0.709\n",
      "Episode: 674 Duration: 0:00:02.151744 Num steps: 185 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.089 Epsilon: 0.708\n",
      "Episode: 675 Duration: 0:00:02.076028 Num steps: 178 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.079 Epsilon: 0.708\n",
      "Episode: 676 Duration: 0:00:02.799727 Num steps: 239 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.089 Epsilon: 0.707\n",
      "Episode: 677 Duration: 0:00:03.481555 Num steps: 300 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.099 Epsilon: 0.707\n",
      "Episode: 678 Duration: 0:00:03.617076 Num steps: 311 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.089 Epsilon: 0.706\n",
      "Episode: 679 Duration: 0:00:03.656667 Num steps: 312 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.109 Epsilon: 0.706\n",
      "Episode: 680 Duration: 0:00:02.475831 Num steps: 213 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.099 Epsilon: 0.705\n",
      "Episode: 681 Duration: 0:00:02.053794 Num steps: 176 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.079 Epsilon: 0.705\n",
      "Episode: 682 Duration: 0:00:03.155473 Num steps: 272 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.099 Epsilon: 0.705\n",
      "Episode: 683 Duration: 0:00:02.366749 Num steps: 202 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.109 Epsilon: 0.704\n",
      "Episode: 684 Duration: 0:00:02.423659 Num steps: 205 Reward: 1.0 Training time per step: 0.010 Avg Reward (Last 100): 1.099 Epsilon: 0.704\n",
      "Episode: 685 Duration: 0:00:02.448145 Num steps: 209 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.089 Epsilon: 0.704\n",
      "Episode: 686 Duration: 0:00:02.968358 Num steps: 254 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.069 Epsilon: 0.703\n",
      "Episode: 687 Duration: 0:00:02.472508 Num steps: 210 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.059 Epsilon: 0.703\n",
      "Episode: 688 Duration: 0:00:02.239198 Num steps: 189 Reward: 0.0 Training time per step: 0.010 Avg Reward (Last 100): 1.050 Epsilon: 0.702\n",
      "Episode: 689 Duration: 0:00:02.490044 Num steps: 214 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.059 Epsilon: 0.702\n",
      "Episode: 690 Duration: 0:00:02.641011 Num steps: 225 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.050 Epsilon: 0.702\n",
      "Episode: 691 Duration: 0:00:03.252967 Num steps: 279 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.059 Epsilon: 0.701\n",
      "Episode: 692 Duration: 0:00:02.599283 Num steps: 223 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.069 Epsilon: 0.701\n",
      "Episode: 693 Duration: 0:00:03.437200 Num steps: 293 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.089 Epsilon: 0.700\n",
      "Episode: 694 Duration: 0:00:01.957525 Num steps: 167 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.059 Epsilon: 0.700\n",
      "Episode: 695 Duration: 0:00:02.758754 Num steps: 236 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.050 Epsilon: 0.699\n",
      "Episode: 696 Duration: 0:00:03.813156 Num steps: 329 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.030 Epsilon: 0.699\n",
      "Episode: 697 Duration: 0:00:01.922930 Num steps: 163 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.020 Epsilon: 0.698\n",
      "Episode: 698 Duration: 0:00:03.613618 Num steps: 306 Reward: 2.0 Training time per step: 0.010 Avg Reward (Last 100): 1.040 Epsilon: 0.698\n",
      "Episode: 699 Duration: 0:00:02.654822 Num steps: 229 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.050 Epsilon: 0.698\n",
      "Episode: 700 Duration: 0:00:02.105068 Num steps: 179 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.050 Epsilon: 0.697\n",
      "Episode: 701 Duration: 0:00:03.076555 Num steps: 264 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.059 Epsilon: 0.697\n",
      "Episode: 702 Duration: 0:00:02.414135 Num steps: 206 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.059 Epsilon: 0.696\n",
      "Episode: 703 Duration: 0:00:02.670652 Num steps: 229 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.069 Epsilon: 0.696\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 704 Duration: 0:00:04.165396 Num steps: 356 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.089 Epsilon: 0.695\n",
      "Episode: 705 Duration: 0:00:02.061297 Num steps: 177 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.079 Epsilon: 0.695\n",
      "Episode: 706 Duration: 0:00:01.972874 Num steps: 168 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.069 Epsilon: 0.695\n",
      "Episode: 707 Duration: 0:00:01.920282 Num steps: 163 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.069 Epsilon: 0.694\n",
      "Episode: 708 Duration: 0:00:02.041083 Num steps: 176 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.050 Epsilon: 0.694\n",
      "Copied model parameters to target network. total_t = 170000, period = 10000\n",
      "Episode: 709 Duration: 0:00:02.237312 Num steps: 168 Reward: 0.0 Training time per step: 0.010 Avg Reward (Last 100): 1.050 Epsilon: 0.694\n",
      "Episode: 710 Duration: 0:00:02.061821 Num steps: 175 Reward: 0.0 Training time per step: 0.010 Avg Reward (Last 100): 1.040 Epsilon: 0.693\n",
      "Episode: 711 Duration: 0:00:02.063156 Num steps: 177 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.030 Epsilon: 0.693\n",
      "Episode: 712 Duration: 0:00:02.826827 Num steps: 242 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.040 Epsilon: 0.693\n",
      "Episode: 713 Duration: 0:00:02.124285 Num steps: 180 Reward: 0.0 Training time per step: 0.010 Avg Reward (Last 100): 1.000 Epsilon: 0.692\n",
      "Episode: 714 Duration: 0:00:02.143331 Num steps: 184 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 0.990 Epsilon: 0.692\n",
      "Episode: 715 Duration: 0:00:02.717102 Num steps: 233 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.000 Epsilon: 0.692\n",
      "Episode: 716 Duration: 0:00:01.984332 Num steps: 170 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 0.970 Epsilon: 0.691\n",
      "Episode: 717 Duration: 0:00:02.060085 Num steps: 176 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 0.950 Epsilon: 0.691\n",
      "Episode: 718 Duration: 0:00:02.714450 Num steps: 233 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 0.941 Epsilon: 0.691\n",
      "Episode: 719 Duration: 0:00:02.476964 Num steps: 212 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 0.941 Epsilon: 0.690\n",
      "Episode: 720 Duration: 0:00:02.450877 Num steps: 209 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 0.921 Epsilon: 0.690\n",
      "Episode: 721 Duration: 0:00:02.011550 Num steps: 171 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 0.911 Epsilon: 0.690\n",
      "Episode: 722 Duration: 0:00:02.578983 Num steps: 218 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 0.901 Epsilon: 0.689\n",
      "Episode: 723 Duration: 0:00:03.070013 Num steps: 264 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 0.901 Epsilon: 0.689\n",
      "Episode: 724 Duration: 0:00:02.558636 Num steps: 218 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 0.901 Epsilon: 0.688\n",
      "Episode: 725 Duration: 0:00:03.074537 Num steps: 265 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 0.901 Epsilon: 0.688\n",
      "Episode: 726 Duration: 0:00:02.108680 Num steps: 177 Reward: 0.0 Training time per step: 0.010 Avg Reward (Last 100): 0.901 Epsilon: 0.687\n",
      "Episode: 727 Duration: 0:00:03.293922 Num steps: 284 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 0.911 Epsilon: 0.687\n",
      "Episode: 728 Duration: 0:00:01.975882 Num steps: 169 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 0.911 Epsilon: 0.687\n",
      "Episode: 729 Duration: 0:00:03.028494 Num steps: 259 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 0.921 Epsilon: 0.686\n",
      "Episode: 730 Duration: 0:00:03.097413 Num steps: 266 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 0.931 Epsilon: 0.686\n",
      "Episode: 731 Duration: 0:00:02.411442 Num steps: 206 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 0.921 Epsilon: 0.685\n",
      "Episode: 732 Duration: 0:00:02.537540 Num steps: 216 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 0.931 Epsilon: 0.685\n",
      "Episode: 733 Duration: 0:00:04.085508 Num steps: 352 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 0.950 Epsilon: 0.684\n",
      "Episode: 734 Duration: 0:00:02.736288 Num steps: 234 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 0.960 Epsilon: 0.684\n",
      "Episode: 735 Duration: 0:00:01.993259 Num steps: 170 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 0.950 Epsilon: 0.684\n",
      "Episode: 736 Duration: 0:00:01.979412 Num steps: 170 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 0.950 Epsilon: 0.683\n",
      "Episode: 737 Duration: 0:00:03.179797 Num steps: 272 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 0.941 Epsilon: 0.683\n",
      "Episode: 738 Duration: 0:00:03.339576 Num steps: 285 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 0.960 Epsilon: 0.682\n",
      "Episode: 739 Duration: 0:00:02.028005 Num steps: 173 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 0.950 Epsilon: 0.682\n",
      "Episode: 740 Duration: 0:00:02.878050 Num steps: 246 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 0.950 Epsilon: 0.682\n",
      "Episode: 741 Duration: 0:00:02.766249 Num steps: 236 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 0.960 Epsilon: 0.681\n",
      "Episode: 742 Duration: 0:00:03.628636 Num steps: 312 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 0.950 Epsilon: 0.681\n",
      "Episode: 743 Duration: 0:00:02.457779 Num steps: 211 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 0.950 Epsilon: 0.680\n",
      "Episode: 744 Duration: 0:00:03.051790 Num steps: 262 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 0.960 Epsilon: 0.680\n",
      "Episode: 745 Duration: 0:00:02.791628 Num steps: 240 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 0.960 Epsilon: 0.679\n",
      "Episode: 746 Duration: 0:00:03.508265 Num steps: 301 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 0.960 Epsilon: 0.679\n",
      "Episode: 747 Duration: 0:00:02.719846 Num steps: 232 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 0.960 Epsilon: 0.678\n",
      "Episode: 748 Duration: 0:00:03.828100 Num steps: 327 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 0.970 Epsilon: 0.678\n",
      "Episode: 749 Duration: 0:00:03.282777 Num steps: 279 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 0.980 Epsilon: 0.677\n",
      "Episode: 750 Duration: 0:00:02.021663 Num steps: 174 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 0.980 Epsilon: 0.677\n",
      "Episode: 751 Duration: 0:00:03.105650 Num steps: 266 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 0.980 Epsilon: 0.676\n",
      "Copied model parameters to target network. total_t = 180000, period = 10000\n",
      "Episode: 752 Duration: 0:00:04.657438 Num steps: 384 Reward: 4.0 Training time per step: 0.009 Avg Reward (Last 100): 1.010 Epsilon: 0.676\n",
      "Episode: 753 Duration: 0:00:02.044778 Num steps: 173 Reward: 0.0 Training time per step: 0.010 Avg Reward (Last 100): 1.010 Epsilon: 0.675\n",
      "Episode: 754 Duration: 0:00:02.808135 Num steps: 239 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.020 Epsilon: 0.675\n",
      "Episode: 755 Duration: 0:00:03.272964 Num steps: 279 Reward: 2.0 Training time per step: 0.010 Avg Reward (Last 100): 1.040 Epsilon: 0.674\n",
      "Episode: 756 Duration: 0:00:03.066885 Num steps: 260 Reward: 1.0 Training time per step: 0.010 Avg Reward (Last 100): 1.010 Epsilon: 0.674\n",
      "Episode: 757 Duration: 0:00:02.792033 Num steps: 240 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.020 Epsilon: 0.674\n",
      "Episode: 758 Duration: 0:00:03.428336 Num steps: 291 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.030 Epsilon: 0.673\n",
      "Episode: 759 Duration: 0:00:02.735786 Num steps: 234 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.040 Epsilon: 0.673\n",
      "Episode: 760 Duration: 0:00:02.512292 Num steps: 215 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.050 Epsilon: 0.672\n",
      "Episode: 761 Duration: 0:00:02.582280 Num steps: 221 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.040 Epsilon: 0.672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 762 Duration: 0:00:02.044381 Num steps: 174 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.030 Epsilon: 0.672\n",
      "Episode: 763 Duration: 0:00:05.300301 Num steps: 454 Reward: 6.0 Training time per step: 0.009 Avg Reward (Last 100): 1.089 Epsilon: 0.671\n",
      "Episode: 764 Duration: 0:00:01.972877 Num steps: 168 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.079 Epsilon: 0.670\n",
      "Episode: 765 Duration: 0:00:01.962370 Num steps: 168 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.079 Epsilon: 0.670\n",
      "Episode: 766 Duration: 0:00:02.672794 Num steps: 229 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.069 Epsilon: 0.670\n",
      "Episode: 767 Duration: 0:00:01.941729 Num steps: 164 Reward: 0.0 Training time per step: 0.010 Avg Reward (Last 100): 1.069 Epsilon: 0.669\n",
      "Episode: 768 Duration: 0:00:02.498756 Num steps: 212 Reward: 1.0 Training time per step: 0.010 Avg Reward (Last 100): 1.079 Epsilon: 0.669\n",
      "Episode: 769 Duration: 0:00:02.721120 Num steps: 234 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.079 Epsilon: 0.669\n",
      "Episode: 770 Duration: 0:00:02.120093 Num steps: 180 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.079 Epsilon: 0.668\n",
      "Episode: 771 Duration: 0:00:04.000959 Num steps: 343 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.099 Epsilon: 0.668\n",
      "Episode: 772 Duration: 0:00:02.722604 Num steps: 232 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.099 Epsilon: 0.667\n",
      "Episode: 773 Duration: 0:00:03.993243 Num steps: 342 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.109 Epsilon: 0.667\n",
      "Episode: 774 Duration: 0:00:03.685111 Num steps: 315 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.119 Epsilon: 0.666\n",
      "Episode: 775 Duration: 0:00:03.080868 Num steps: 265 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.139 Epsilon: 0.666\n",
      "Episode: 776 Duration: 0:00:02.068652 Num steps: 177 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.139 Epsilon: 0.665\n",
      "Episode: 777 Duration: 0:00:02.436196 Num steps: 208 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.139 Epsilon: 0.665\n",
      "Episode: 778 Duration: 0:00:02.951466 Num steps: 251 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.129 Epsilon: 0.664\n",
      "Episode: 779 Duration: 0:00:02.735585 Num steps: 233 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.119 Epsilon: 0.664\n",
      "Episode: 780 Duration: 0:00:03.585354 Num steps: 306 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.109 Epsilon: 0.663\n",
      "Episode: 781 Duration: 0:00:02.388204 Num steps: 204 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.099 Epsilon: 0.663\n",
      "Episode: 782 Duration: 0:00:03.618988 Num steps: 310 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.119 Epsilon: 0.663\n",
      "Episode: 783 Duration: 0:00:03.577418 Num steps: 308 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.119 Epsilon: 0.662\n",
      "Episode: 784 Duration: 0:00:01.948058 Num steps: 167 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.109 Epsilon: 0.662\n",
      "Episode: 785 Duration: 0:00:03.171172 Num steps: 271 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.119 Epsilon: 0.661\n",
      "Episode: 786 Duration: 0:00:01.989629 Num steps: 169 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.109 Epsilon: 0.661\n",
      "Episode: 787 Duration: 0:00:03.382477 Num steps: 290 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.119 Epsilon: 0.660\n",
      "Episode: 788 Duration: 0:00:02.100098 Num steps: 179 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.109 Epsilon: 0.660\n",
      "Episode: 789 Duration: 0:00:04.288873 Num steps: 368 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.139 Epsilon: 0.659\n",
      "Episode: 790 Duration: 0:00:01.933813 Num steps: 166 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.129 Epsilon: 0.659\n",
      "Episode: 791 Duration: 0:00:03.088756 Num steps: 264 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.139 Epsilon: 0.659\n",
      "Episode: 792 Duration: 0:00:03.136211 Num steps: 268 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.129 Epsilon: 0.658\n",
      "Copied model parameters to target network. total_t = 190000, period = 10000\n",
      "Episode: 793 Duration: 0:00:02.740518 Num steps: 214 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.129 Epsilon: 0.658\n",
      "Episode: 794 Duration: 0:00:03.136729 Num steps: 267 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.129 Epsilon: 0.657\n",
      "Episode: 795 Duration: 0:00:05.060426 Num steps: 426 Reward: 5.0 Training time per step: 0.010 Avg Reward (Last 100): 1.178 Epsilon: 0.657\n",
      "Episode: 796 Duration: 0:00:02.291828 Num steps: 196 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.168 Epsilon: 0.656\n",
      "Episode: 797 Duration: 0:00:03.277447 Num steps: 281 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.158 Epsilon: 0.656\n",
      "Episode: 798 Duration: 0:00:03.208460 Num steps: 273 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.178 Epsilon: 0.655\n",
      "Episode: 799 Duration: 0:00:02.266782 Num steps: 194 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.158 Epsilon: 0.655\n",
      "Episode: 800 Duration: 0:00:02.073174 Num steps: 175 Reward: 0.0 Training time per step: 0.010 Avg Reward (Last 100): 1.149 Epsilon: 0.654\n",
      "Episode: 801 Duration: 0:00:03.199565 Num steps: 273 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.168 Epsilon: 0.654\n",
      "Episode: 802 Duration: 0:00:03.270245 Num steps: 277 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.168 Epsilon: 0.653\n",
      "Episode: 803 Duration: 0:00:02.767333 Num steps: 234 Reward: 1.0 Training time per step: 0.010 Avg Reward (Last 100): 1.168 Epsilon: 0.653\n",
      "Episode: 804 Duration: 0:00:04.275001 Num steps: 360 Reward: 3.0 Training time per step: 0.010 Avg Reward (Last 100): 1.188 Epsilon: 0.652\n",
      "Episode: 805 Duration: 0:00:02.847603 Num steps: 242 Reward: 1.0 Training time per step: 0.010 Avg Reward (Last 100): 1.168 Epsilon: 0.652\n",
      "Episode: 806 Duration: 0:00:02.109747 Num steps: 179 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.168 Epsilon: 0.652\n",
      "Episode: 807 Duration: 0:00:03.572851 Num steps: 304 Reward: 2.0 Training time per step: 0.010 Avg Reward (Last 100): 1.188 Epsilon: 0.651\n",
      "Episode: 808 Duration: 0:00:02.932008 Num steps: 249 Reward: 1.0 Training time per step: 0.010 Avg Reward (Last 100): 1.198 Epsilon: 0.651\n",
      "Episode: 809 Duration: 0:00:03.195304 Num steps: 270 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.218 Epsilon: 0.650\n",
      "Episode: 810 Duration: 0:00:03.587073 Num steps: 305 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.238 Epsilon: 0.650\n",
      "Episode: 811 Duration: 0:00:01.980755 Num steps: 169 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.238 Epsilon: 0.649\n",
      "Episode: 812 Duration: 0:00:02.848032 Num steps: 244 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.248 Epsilon: 0.649\n",
      "Episode: 813 Duration: 0:00:03.968383 Num steps: 340 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.267 Epsilon: 0.648\n",
      "Episode: 814 Duration: 0:00:02.187462 Num steps: 187 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.267 Epsilon: 0.648\n",
      "Episode: 815 Duration: 0:00:02.428967 Num steps: 207 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.277 Epsilon: 0.648\n",
      "Episode: 816 Duration: 0:00:02.545403 Num steps: 217 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.277 Epsilon: 0.647\n",
      "Episode: 817 Duration: 0:00:02.177590 Num steps: 186 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.277 Epsilon: 0.647\n",
      "Episode: 818 Duration: 0:00:03.307619 Num steps: 284 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.297 Epsilon: 0.646\n",
      "Episode: 819 Duration: 0:00:02.468215 Num steps: 208 Reward: 1.0 Training time per step: 0.010 Avg Reward (Last 100): 1.297 Epsilon: 0.646\n",
      "Episode: 820 Duration: 0:00:02.626828 Num steps: 223 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.297 Epsilon: 0.646\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 821 Duration: 0:00:02.481483 Num steps: 210 Reward: 0.0 Training time per step: 0.010 Avg Reward (Last 100): 1.287 Epsilon: 0.645\n",
      "Episode: 822 Duration: 0:00:02.098672 Num steps: 177 Reward: 0.0 Training time per step: 0.010 Avg Reward (Last 100): 1.287 Epsilon: 0.645\n",
      "Episode: 823 Duration: 0:00:01.996410 Num steps: 167 Reward: 0.0 Training time per step: 0.010 Avg Reward (Last 100): 1.277 Epsilon: 0.645\n",
      "Episode: 824 Duration: 0:00:04.437411 Num steps: 379 Reward: 4.0 Training time per step: 0.009 Avg Reward (Last 100): 1.297 Epsilon: 0.644\n",
      "Episode: 825 Duration: 0:00:02.990922 Num steps: 254 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.297 Epsilon: 0.643\n",
      "Episode: 826 Duration: 0:00:05.100430 Num steps: 435 Reward: 4.0 Training time per step: 0.009 Avg Reward (Last 100): 1.317 Epsilon: 0.643\n",
      "Episode: 827 Duration: 0:00:02.096097 Num steps: 180 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.317 Epsilon: 0.642\n",
      "Episode: 828 Duration: 0:00:03.683755 Num steps: 315 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.317 Epsilon: 0.642\n",
      "Episode: 829 Duration: 0:00:04.104597 Num steps: 347 Reward: 3.0 Training time per step: 0.010 Avg Reward (Last 100): 1.347 Epsilon: 0.641\n",
      "Episode: 830 Duration: 0:00:01.998347 Num steps: 171 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.337 Epsilon: 0.641\n",
      "Episode: 831 Duration: 0:00:03.282951 Num steps: 277 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.337 Epsilon: 0.640\n",
      "Copied model parameters to target network. total_t = 200000, period = 10000\n",
      "Episode: 832 Duration: 0:00:02.978159 Num steps: 237 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.337 Epsilon: 0.640\n",
      "Episode: 833 Duration: 0:00:02.558255 Num steps: 214 Reward: 1.0 Training time per step: 0.010 Avg Reward (Last 100): 1.337 Epsilon: 0.640\n",
      "Episode: 834 Duration: 0:00:02.321819 Num steps: 197 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.307 Epsilon: 0.639\n",
      "Episode: 835 Duration: 0:00:03.430534 Num steps: 290 Reward: 2.0 Training time per step: 0.010 Avg Reward (Last 100): 1.317 Epsilon: 0.639\n",
      "Episode: 836 Duration: 0:00:02.166574 Num steps: 185 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.317 Epsilon: 0.638\n",
      "Episode: 837 Duration: 0:00:04.439265 Num steps: 380 Reward: 4.0 Training time per step: 0.009 Avg Reward (Last 100): 1.356 Epsilon: 0.638\n",
      "Episode: 838 Duration: 0:00:02.889283 Num steps: 244 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.356 Epsilon: 0.637\n",
      "Episode: 839 Duration: 0:00:02.107918 Num steps: 179 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.337 Epsilon: 0.637\n",
      "Episode: 840 Duration: 0:00:02.864683 Num steps: 240 Reward: 1.0 Training time per step: 0.010 Avg Reward (Last 100): 1.347 Epsilon: 0.636\n",
      "Episode: 841 Duration: 0:00:01.992694 Num steps: 170 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.337 Epsilon: 0.636\n",
      "Episode: 842 Duration: 0:00:02.566511 Num steps: 217 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.337 Epsilon: 0.636\n",
      "Episode: 843 Duration: 0:00:03.214818 Num steps: 274 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.337 Epsilon: 0.635\n",
      "Episode: 844 Duration: 0:00:03.047064 Num steps: 260 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.337 Epsilon: 0.635\n",
      "Episode: 845 Duration: 0:00:02.740442 Num steps: 233 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.327 Epsilon: 0.634\n",
      "Episode: 846 Duration: 0:00:02.259149 Num steps: 192 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.317 Epsilon: 0.634\n",
      "Episode: 847 Duration: 0:00:02.612188 Num steps: 221 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.307 Epsilon: 0.634\n",
      "Episode: 848 Duration: 0:00:02.101656 Num steps: 179 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.297 Epsilon: 0.633\n",
      "Episode: 849 Duration: 0:00:02.154736 Num steps: 182 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.267 Epsilon: 0.633\n",
      "Episode: 850 Duration: 0:00:02.232593 Num steps: 191 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.248 Epsilon: 0.633\n",
      "Episode: 851 Duration: 0:00:02.390881 Num steps: 202 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.257 Epsilon: 0.632\n",
      "Episode: 852 Duration: 0:00:02.304626 Num steps: 195 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.238 Epsilon: 0.632\n",
      "Episode: 853 Duration: 0:00:03.294111 Num steps: 281 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.218 Epsilon: 0.631\n",
      "Episode: 854 Duration: 0:00:02.032738 Num steps: 173 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.218 Epsilon: 0.631\n",
      "Episode: 855 Duration: 0:00:02.400838 Num steps: 205 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.208 Epsilon: 0.631\n",
      "Episode: 856 Duration: 0:00:03.737205 Num steps: 317 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.208 Epsilon: 0.630\n",
      "Episode: 857 Duration: 0:00:03.360098 Num steps: 286 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.218 Epsilon: 0.630\n",
      "Episode: 858 Duration: 0:00:02.065646 Num steps: 176 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.208 Epsilon: 0.629\n",
      "Episode: 859 Duration: 0:00:02.804758 Num steps: 236 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.198 Epsilon: 0.629\n",
      "Episode: 860 Duration: 0:00:02.494774 Num steps: 212 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.198 Epsilon: 0.628\n",
      "Episode: 861 Duration: 0:00:02.670382 Num steps: 228 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.198 Epsilon: 0.628\n",
      "Episode: 862 Duration: 0:00:02.058005 Num steps: 172 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.188 Epsilon: 0.628\n",
      "Episode: 863 Duration: 0:00:02.036829 Num steps: 172 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.188 Epsilon: 0.627\n",
      "Episode: 864 Duration: 0:00:02.045433 Num steps: 174 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.129 Epsilon: 0.627\n",
      "Episode: 865 Duration: 0:00:02.978967 Num steps: 253 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.149 Epsilon: 0.627\n",
      "Episode: 866 Duration: 0:00:02.008006 Num steps: 170 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.149 Epsilon: 0.626\n",
      "Episode: 867 Duration: 0:00:02.534318 Num steps: 215 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.149 Epsilon: 0.626\n",
      "Episode: 868 Duration: 0:00:02.000532 Num steps: 170 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.149 Epsilon: 0.626\n",
      "Episode: 869 Duration: 0:00:04.855177 Num steps: 414 Reward: 5.0 Training time per step: 0.009 Avg Reward (Last 100): 1.188 Epsilon: 0.625\n",
      "Episode: 870 Duration: 0:00:02.003579 Num steps: 170 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.178 Epsilon: 0.625\n",
      "Episode: 871 Duration: 0:00:03.983652 Num steps: 342 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.208 Epsilon: 0.624\n",
      "Episode: 872 Duration: 0:00:03.284233 Num steps: 280 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.198 Epsilon: 0.624\n",
      "Episode: 873 Duration: 0:00:02.122669 Num steps: 180 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.188 Epsilon: 0.623\n",
      "Episode: 874 Duration: 0:00:03.133791 Num steps: 267 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.178 Epsilon: 0.623\n",
      "Episode: 875 Duration: 0:00:02.021514 Num steps: 173 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.158 Epsilon: 0.622\n",
      "Episode: 876 Duration: 0:00:02.263071 Num steps: 192 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.139 Epsilon: 0.622\n",
      "Copied model parameters to target network. total_t = 210000, period = 10000\n",
      "Episode: 877 Duration: 0:00:02.313001 Num steps: 178 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.139 Epsilon: 0.622\n",
      "Episode: 878 Duration: 0:00:04.081150 Num steps: 346 Reward: 4.0 Training time per step: 0.009 Avg Reward (Last 100): 1.168 Epsilon: 0.621\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 879 Duration: 0:00:04.122689 Num steps: 351 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.188 Epsilon: 0.620\n",
      "Episode: 880 Duration: 0:00:02.716621 Num steps: 232 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.188 Epsilon: 0.620\n",
      "Episode: 881 Duration: 0:00:01.938401 Num steps: 167 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.168 Epsilon: 0.620\n",
      "Episode: 882 Duration: 0:00:04.393328 Num steps: 372 Reward: 4.0 Training time per step: 0.009 Avg Reward (Last 100): 1.208 Epsilon: 0.619\n",
      "Episode: 883 Duration: 0:00:03.936421 Num steps: 336 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.218 Epsilon: 0.619\n",
      "Episode: 884 Duration: 0:00:02.156239 Num steps: 183 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.198 Epsilon: 0.618\n",
      "Episode: 885 Duration: 0:00:03.744985 Num steps: 317 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.228 Epsilon: 0.618\n",
      "Episode: 886 Duration: 0:00:02.977066 Num steps: 250 Reward: 1.0 Training time per step: 0.010 Avg Reward (Last 100): 1.218 Epsilon: 0.617\n",
      "Episode: 887 Duration: 0:00:01.963866 Num steps: 168 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.218 Epsilon: 0.617\n",
      "Episode: 888 Duration: 0:00:03.795720 Num steps: 323 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.228 Epsilon: 0.616\n",
      "Episode: 889 Duration: 0:00:02.587294 Num steps: 219 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.238 Epsilon: 0.616\n",
      "Episode: 890 Duration: 0:00:01.910728 Num steps: 163 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.208 Epsilon: 0.616\n",
      "Episode: 891 Duration: 0:00:03.237284 Num steps: 275 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.228 Epsilon: 0.615\n",
      "Episode: 892 Duration: 0:00:02.183400 Num steps: 186 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.208 Epsilon: 0.615\n",
      "Episode: 893 Duration: 0:00:02.869930 Num steps: 245 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.208 Epsilon: 0.614\n",
      "Episode: 894 Duration: 0:00:02.439912 Num steps: 204 Reward: 1.0 Training time per step: 0.010 Avg Reward (Last 100): 1.208 Epsilon: 0.614\n",
      "Episode: 895 Duration: 0:00:02.686927 Num steps: 229 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.198 Epsilon: 0.614\n",
      "Episode: 896 Duration: 0:00:02.082752 Num steps: 178 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.149 Epsilon: 0.613\n",
      "Episode: 897 Duration: 0:00:03.189037 Num steps: 272 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.168 Epsilon: 0.613\n",
      "Episode: 898 Duration: 0:00:01.959818 Num steps: 165 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.149 Epsilon: 0.612\n",
      "Episode: 899 Duration: 0:00:02.010309 Num steps: 170 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.129 Epsilon: 0.612\n",
      "Episode: 900 Duration: 0:00:02.957577 Num steps: 252 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.149 Epsilon: 0.612\n",
      "Episode: 901 Duration: 0:00:03.471357 Num steps: 296 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.168 Epsilon: 0.611\n",
      "Episode: 902 Duration: 0:00:01.941533 Num steps: 167 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.149 Epsilon: 0.611\n",
      "Episode: 903 Duration: 0:00:02.079406 Num steps: 176 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.129 Epsilon: 0.611\n",
      "Episode: 904 Duration: 0:00:04.629515 Num steps: 393 Reward: 4.0 Training time per step: 0.009 Avg Reward (Last 100): 1.158 Epsilon: 0.610\n",
      "Episode: 905 Duration: 0:00:02.042261 Num steps: 171 Reward: 0.0 Training time per step: 0.010 Avg Reward (Last 100): 1.129 Epsilon: 0.609\n",
      "Episode: 906 Duration: 0:00:02.766012 Num steps: 235 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.129 Epsilon: 0.609\n",
      "Episode: 907 Duration: 0:00:02.428757 Num steps: 207 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.139 Epsilon: 0.609\n",
      "Episode: 908 Duration: 0:00:02.102869 Num steps: 180 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.119 Epsilon: 0.608\n",
      "Episode: 909 Duration: 0:00:03.013018 Num steps: 258 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.129 Epsilon: 0.608\n",
      "Episode: 910 Duration: 0:00:02.528006 Num steps: 213 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.119 Epsilon: 0.608\n",
      "Episode: 911 Duration: 0:00:02.118163 Num steps: 179 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.099 Epsilon: 0.607\n",
      "Episode: 912 Duration: 0:00:02.404778 Num steps: 206 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.109 Epsilon: 0.607\n",
      "Episode: 913 Duration: 0:00:03.270137 Num steps: 278 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.119 Epsilon: 0.606\n",
      "Episode: 914 Duration: 0:00:02.087115 Num steps: 180 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.089 Epsilon: 0.606\n",
      "Episode: 915 Duration: 0:00:03.580749 Num steps: 307 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.109 Epsilon: 0.605\n",
      "Episode: 916 Duration: 0:00:03.125013 Num steps: 264 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.119 Epsilon: 0.605\n",
      "Episode: 917 Duration: 0:00:02.818686 Num steps: 240 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.119 Epsilon: 0.605\n",
      "Episode: 918 Duration: 0:00:02.008727 Num steps: 170 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.119 Epsilon: 0.604\n",
      "Copied model parameters to target network. total_t = 220000, period = 10000\n",
      "Episode: 919 Duration: 0:00:02.260082 Num steps: 168 Reward: 0.0 Training time per step: 0.010 Avg Reward (Last 100): 1.099 Epsilon: 0.604\n",
      "Episode: 920 Duration: 0:00:02.275748 Num steps: 194 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.089 Epsilon: 0.604\n",
      "Episode: 921 Duration: 0:00:02.584340 Num steps: 218 Reward: 1.0 Training time per step: 0.010 Avg Reward (Last 100): 1.089 Epsilon: 0.603\n",
      "Episode: 922 Duration: 0:00:02.711038 Num steps: 231 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.099 Epsilon: 0.603\n",
      "Episode: 923 Duration: 0:00:03.199787 Num steps: 270 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.119 Epsilon: 0.602\n",
      "Episode: 924 Duration: 0:00:02.546866 Num steps: 217 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.129 Epsilon: 0.602\n",
      "Episode: 925 Duration: 0:00:02.698141 Num steps: 227 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.099 Epsilon: 0.602\n",
      "Episode: 926 Duration: 0:00:02.446697 Num steps: 207 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.099 Epsilon: 0.601\n",
      "Episode: 927 Duration: 0:00:02.884632 Num steps: 245 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.069 Epsilon: 0.601\n",
      "Episode: 928 Duration: 0:00:02.658473 Num steps: 227 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.079 Epsilon: 0.600\n",
      "Episode: 929 Duration: 0:00:03.362529 Num steps: 284 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.079 Epsilon: 0.600\n",
      "Episode: 930 Duration: 0:00:02.069372 Num steps: 176 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.050 Epsilon: 0.599\n",
      "Episode: 931 Duration: 0:00:02.209023 Num steps: 187 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.050 Epsilon: 0.599\n",
      "Episode: 932 Duration: 0:00:02.207681 Num steps: 189 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.030 Epsilon: 0.599\n",
      "Episode: 933 Duration: 0:00:02.788774 Num steps: 240 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.030 Epsilon: 0.598\n",
      "Episode: 934 Duration: 0:00:02.806325 Num steps: 239 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.030 Epsilon: 0.598\n",
      "Episode: 935 Duration: 0:00:04.027609 Num steps: 342 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.059 Epsilon: 0.597\n",
      "Episode: 936 Duration: 0:00:05.869349 Num steps: 499 Reward: 5.0 Training time per step: 0.009 Avg Reward (Last 100): 1.089 Epsilon: 0.596\n",
      "Episode: 937 Duration: 0:00:02.137038 Num steps: 180 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.089 Epsilon: 0.596\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 938 Duration: 0:00:02.848650 Num steps: 241 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.069 Epsilon: 0.596\n",
      "Episode: 939 Duration: 0:00:04.517664 Num steps: 385 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.079 Epsilon: 0.595\n",
      "Episode: 940 Duration: 0:00:02.864812 Num steps: 245 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.089 Epsilon: 0.595\n",
      "Episode: 941 Duration: 0:00:03.261289 Num steps: 276 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.099 Epsilon: 0.594\n",
      "Episode: 942 Duration: 0:00:02.077034 Num steps: 178 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.099 Epsilon: 0.594\n",
      "Episode: 943 Duration: 0:00:02.623553 Num steps: 224 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.099 Epsilon: 0.593\n",
      "Episode: 944 Duration: 0:00:02.948835 Num steps: 251 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.089 Epsilon: 0.593\n",
      "Episode: 945 Duration: 0:00:03.788129 Num steps: 321 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.099 Epsilon: 0.592\n",
      "Episode: 946 Duration: 0:00:02.085127 Num steps: 176 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.089 Epsilon: 0.592\n",
      "Episode: 947 Duration: 0:00:04.112717 Num steps: 349 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.119 Epsilon: 0.591\n",
      "Episode: 948 Duration: 0:00:02.072951 Num steps: 176 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.109 Epsilon: 0.591\n",
      "Episode: 949 Duration: 0:00:02.507818 Num steps: 213 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.119 Epsilon: 0.591\n",
      "Episode: 950 Duration: 0:00:03.428866 Num steps: 291 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.139 Epsilon: 0.590\n",
      "Episode: 951 Duration: 0:00:02.617982 Num steps: 221 Reward: 1.0 Training time per step: 0.010 Avg Reward (Last 100): 1.149 Epsilon: 0.590\n",
      "Episode: 952 Duration: 0:00:02.491239 Num steps: 209 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.149 Epsilon: 0.589\n",
      "Episode: 953 Duration: 0:00:03.000783 Num steps: 254 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.158 Epsilon: 0.589\n",
      "Episode: 954 Duration: 0:00:02.168781 Num steps: 183 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.139 Epsilon: 0.589\n",
      "Episode: 955 Duration: 0:00:02.337729 Num steps: 197 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.139 Epsilon: 0.588\n",
      "Episode: 956 Duration: 0:00:01.974996 Num steps: 165 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.139 Epsilon: 0.588\n",
      "Episode: 957 Duration: 0:00:02.434676 Num steps: 206 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.129 Epsilon: 0.588\n",
      "Episode: 958 Duration: 0:00:01.979263 Num steps: 170 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.109 Epsilon: 0.587\n",
      "Episode: 959 Duration: 0:00:03.467539 Num steps: 295 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.129 Epsilon: 0.587\n",
      "Episode: 960 Duration: 0:00:04.077110 Num steps: 344 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.149 Epsilon: 0.586\n",
      "Copied model parameters to target network. total_t = 230000, period = 10000\n",
      "Episode: 961 Duration: 0:00:03.725190 Num steps: 298 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.158 Epsilon: 0.586\n",
      "Episode: 962 Duration: 0:00:03.514245 Num steps: 298 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.168 Epsilon: 0.585\n",
      "Episode: 963 Duration: 0:00:03.413168 Num steps: 289 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.188 Epsilon: 0.584\n",
      "Episode: 964 Duration: 0:00:03.328738 Num steps: 283 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.208 Epsilon: 0.584\n",
      "Episode: 965 Duration: 0:00:02.718673 Num steps: 230 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.218 Epsilon: 0.584\n",
      "Episode: 966 Duration: 0:00:02.990481 Num steps: 255 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.208 Epsilon: 0.583\n",
      "Episode: 967 Duration: 0:00:02.096318 Num steps: 180 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.208 Epsilon: 0.583\n",
      "Episode: 968 Duration: 0:00:02.685994 Num steps: 228 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.208 Epsilon: 0.582\n",
      "Episode: 969 Duration: 0:00:04.177544 Num steps: 356 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.238 Epsilon: 0.582\n",
      "Episode: 970 Duration: 0:00:03.753880 Num steps: 321 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.218 Epsilon: 0.581\n",
      "Episode: 971 Duration: 0:00:02.010955 Num steps: 170 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.218 Epsilon: 0.581\n",
      "Episode: 972 Duration: 0:00:02.706389 Num steps: 225 Reward: 1.0 Training time per step: 0.010 Avg Reward (Last 100): 1.198 Epsilon: 0.580\n",
      "Episode: 973 Duration: 0:00:02.463636 Num steps: 209 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.188 Epsilon: 0.580\n",
      "Episode: 974 Duration: 0:00:03.652542 Num steps: 311 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.208 Epsilon: 0.579\n",
      "Episode: 975 Duration: 0:00:03.247030 Num steps: 273 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.208 Epsilon: 0.579\n",
      "Episode: 976 Duration: 0:00:03.568582 Num steps: 303 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.228 Epsilon: 0.578\n",
      "Episode: 977 Duration: 0:00:03.336452 Num steps: 283 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.248 Epsilon: 0.578\n",
      "Episode: 978 Duration: 0:00:02.105317 Num steps: 179 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.248 Epsilon: 0.578\n",
      "Episode: 979 Duration: 0:00:03.814729 Num steps: 324 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.228 Epsilon: 0.577\n",
      "Episode: 980 Duration: 0:00:01.979339 Num steps: 168 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.198 Epsilon: 0.577\n",
      "Episode: 981 Duration: 0:00:02.066081 Num steps: 175 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.188 Epsilon: 0.576\n",
      "Episode: 982 Duration: 0:00:02.889122 Num steps: 243 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.198 Epsilon: 0.576\n",
      "Episode: 983 Duration: 0:00:04.013746 Num steps: 340 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.188 Epsilon: 0.575\n",
      "Episode: 984 Duration: 0:00:02.716042 Num steps: 231 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.168 Epsilon: 0.575\n",
      "Episode: 985 Duration: 0:00:02.148154 Num steps: 181 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.168 Epsilon: 0.575\n",
      "Episode: 986 Duration: 0:00:02.971826 Num steps: 253 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.149 Epsilon: 0.574\n",
      "Episode: 987 Duration: 0:00:03.436793 Num steps: 291 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.158 Epsilon: 0.574\n",
      "Episode: 988 Duration: 0:00:02.788876 Num steps: 237 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.168 Epsilon: 0.573\n",
      "Episode: 989 Duration: 0:00:02.814853 Num steps: 240 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.149 Epsilon: 0.573\n",
      "Episode: 990 Duration: 0:00:02.022273 Num steps: 171 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.139 Epsilon: 0.572\n",
      "Episode: 991 Duration: 0:00:03.665219 Num steps: 312 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.158 Epsilon: 0.572\n",
      "Episode: 992 Duration: 0:00:02.840806 Num steps: 242 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.149 Epsilon: 0.571\n",
      "Episode: 993 Duration: 0:00:02.023190 Num steps: 172 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.149 Epsilon: 0.571\n",
      "Episode: 994 Duration: 0:00:03.791155 Num steps: 323 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.168 Epsilon: 0.571\n",
      "Episode: 995 Duration: 0:00:03.237695 Num steps: 275 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.178 Epsilon: 0.570\n",
      "Episode: 996 Duration: 0:00:02.110302 Num steps: 179 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.168 Epsilon: 0.570\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 997 Duration: 0:00:02.113831 Num steps: 179 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.168 Epsilon: 0.569\n",
      "Episode: 998 Duration: 0:00:02.783709 Num steps: 236 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.158 Epsilon: 0.569\n",
      "Episode: 999 Duration: 0:00:03.998268 Num steps: 340 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.188 Epsilon: 0.568\n",
      "Copied model parameters to target network. total_t = 240000, period = 10000\n",
      "Episode: 1000 Duration: 0:00:03.727678 Num steps: 298 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.208 Epsilon: 0.568\n",
      "Episode: 1001 Duration: 0:00:02.057627 Num steps: 173 Reward: 0.0 Training time per step: 0.010 Avg Reward (Last 100): 1.188 Epsilon: 0.568\n",
      "Episode: 1002 Duration: 0:00:02.140413 Num steps: 180 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.168 Epsilon: 0.567\n",
      "Episode: 1003 Duration: 0:00:04.025168 Num steps: 338 Reward: 4.0 Training time per step: 0.010 Avg Reward (Last 100): 1.208 Epsilon: 0.567\n",
      "Episode: 1004 Duration: 0:00:03.949925 Num steps: 334 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.238 Epsilon: 0.566\n",
      "Episode: 1005 Duration: 0:00:02.330155 Num steps: 199 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.198 Epsilon: 0.566\n",
      "Episode: 1006 Duration: 0:00:02.883424 Num steps: 245 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.208 Epsilon: 0.565\n",
      "Episode: 1007 Duration: 0:00:03.516813 Num steps: 299 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.218 Epsilon: 0.565\n",
      "Episode: 1008 Duration: 0:00:02.112364 Num steps: 180 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.208 Epsilon: 0.564\n",
      "Episode: 1009 Duration: 0:00:02.057466 Num steps: 172 Reward: 0.0 Training time per step: 0.010 Avg Reward (Last 100): 1.208 Epsilon: 0.564\n",
      "Episode: 1010 Duration: 0:00:03.603069 Num steps: 307 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.208 Epsilon: 0.563\n",
      "Episode: 1011 Duration: 0:00:02.762615 Num steps: 236 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.208 Epsilon: 0.563\n",
      "Episode: 1012 Duration: 0:00:04.001491 Num steps: 339 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.238 Epsilon: 0.562\n",
      "Episode: 1013 Duration: 0:00:04.216519 Num steps: 361 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.257 Epsilon: 0.562\n",
      "Episode: 1014 Duration: 0:00:02.677812 Num steps: 227 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.248 Epsilon: 0.561\n",
      "Episode: 1015 Duration: 0:00:02.577091 Num steps: 219 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.257 Epsilon: 0.561\n",
      "Episode: 1016 Duration: 0:00:02.052564 Num steps: 174 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.238 Epsilon: 0.561\n",
      "Episode: 1017 Duration: 0:00:02.778002 Num steps: 236 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.228 Epsilon: 0.560\n",
      "Episode: 1018 Duration: 0:00:03.159597 Num steps: 267 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.238 Epsilon: 0.560\n",
      "Episode: 1019 Duration: 0:00:02.763351 Num steps: 233 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.248 Epsilon: 0.559\n",
      "Episode: 1020 Duration: 0:00:03.330958 Num steps: 283 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.267 Epsilon: 0.559\n",
      "Episode: 1021 Duration: 0:00:02.113523 Num steps: 178 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.267 Epsilon: 0.559\n",
      "Episode: 1022 Duration: 0:00:02.166254 Num steps: 183 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.257 Epsilon: 0.558\n",
      "Episode: 1023 Duration: 0:00:02.219980 Num steps: 188 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.248 Epsilon: 0.558\n",
      "Episode: 1024 Duration: 0:00:02.513587 Num steps: 213 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.228 Epsilon: 0.557\n",
      "Episode: 1025 Duration: 0:00:02.114921 Num steps: 178 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.218 Epsilon: 0.557\n",
      "Episode: 1026 Duration: 0:00:02.757972 Num steps: 234 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.218 Epsilon: 0.557\n",
      "Episode: 1027 Duration: 0:00:02.675856 Num steps: 227 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.218 Epsilon: 0.556\n",
      "Episode: 1028 Duration: 0:00:02.038502 Num steps: 172 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.208 Epsilon: 0.556\n",
      "Episode: 1029 Duration: 0:00:04.455042 Num steps: 379 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.228 Epsilon: 0.555\n",
      "Episode: 1030 Duration: 0:00:02.633274 Num steps: 222 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.218 Epsilon: 0.555\n",
      "Episode: 1031 Duration: 0:00:04.451660 Num steps: 379 Reward: 4.0 Training time per step: 0.009 Avg Reward (Last 100): 1.257 Epsilon: 0.554\n",
      "Episode: 1032 Duration: 0:00:03.029656 Num steps: 256 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.277 Epsilon: 0.554\n",
      "Episode: 1033 Duration: 0:00:02.938331 Num steps: 249 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.287 Epsilon: 0.553\n",
      "Episode: 1034 Duration: 0:00:02.564962 Num steps: 218 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.287 Epsilon: 0.553\n",
      "Episode: 1035 Duration: 0:00:04.027646 Num steps: 342 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.307 Epsilon: 0.552\n",
      "Episode: 1036 Duration: 0:00:01.933382 Num steps: 164 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.277 Epsilon: 0.552\n",
      "Episode: 1037 Duration: 0:00:02.481618 Num steps: 206 Reward: 1.0 Training time per step: 0.010 Avg Reward (Last 100): 1.238 Epsilon: 0.552\n",
      "Episode: 1038 Duration: 0:00:02.028471 Num steps: 173 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.238 Epsilon: 0.551\n",
      "Episode: 1039 Duration: 0:00:03.234385 Num steps: 274 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.238 Epsilon: 0.551\n",
      "Episode: 1040 Duration: 0:00:02.234648 Num steps: 190 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.208 Epsilon: 0.551\n",
      "Episode: 1041 Duration: 0:00:02.255830 Num steps: 190 Reward: 0.0 Training time per step: 0.010 Avg Reward (Last 100): 1.198 Epsilon: 0.550\n",
      "Copied model parameters to target network. total_t = 250000, period = 10000\n",
      "Episode: 1042 Duration: 0:00:03.372916 Num steps: 269 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.188 Epsilon: 0.550\n",
      "Episode: 1043 Duration: 0:00:04.034902 Num steps: 339 Reward: 3.0 Training time per step: 0.010 Avg Reward (Last 100): 1.218 Epsilon: 0.549\n",
      "Episode: 1044 Duration: 0:00:03.267081 Num steps: 276 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.228 Epsilon: 0.549\n",
      "Episode: 1045 Duration: 0:00:02.809599 Num steps: 239 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.228 Epsilon: 0.548\n",
      "Episode: 1046 Duration: 0:00:03.036471 Num steps: 259 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.218 Epsilon: 0.548\n",
      "Episode: 1047 Duration: 0:00:02.029855 Num steps: 172 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.218 Epsilon: 0.547\n",
      "Episode: 1048 Duration: 0:00:03.932197 Num steps: 332 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.218 Epsilon: 0.547\n",
      "Episode: 1049 Duration: 0:00:02.135484 Num steps: 180 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.218 Epsilon: 0.546\n",
      "Episode: 1050 Duration: 0:00:02.825575 Num steps: 240 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.218 Epsilon: 0.546\n",
      "Episode: 1051 Duration: 0:00:02.353411 Num steps: 199 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.208 Epsilon: 0.546\n",
      "Episode: 1052 Duration: 0:00:03.394925 Num steps: 287 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.218 Epsilon: 0.545\n",
      "Episode: 1053 Duration: 0:00:02.175237 Num steps: 184 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.208 Epsilon: 0.545\n",
      "Episode: 1054 Duration: 0:00:02.659914 Num steps: 224 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.208 Epsilon: 0.544\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1055 Duration: 0:00:02.179897 Num steps: 184 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.208 Epsilon: 0.544\n",
      "Episode: 1056 Duration: 0:00:02.824708 Num steps: 237 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.218 Epsilon: 0.544\n",
      "Episode: 1057 Duration: 0:00:02.053583 Num steps: 173 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.218 Epsilon: 0.543\n",
      "Episode: 1058 Duration: 0:00:02.112221 Num steps: 179 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.208 Epsilon: 0.543\n",
      "Episode: 1059 Duration: 0:00:04.806214 Num steps: 408 Reward: 4.0 Training time per step: 0.009 Avg Reward (Last 100): 1.248 Epsilon: 0.542\n",
      "Episode: 1060 Duration: 0:00:03.391484 Num steps: 288 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.248 Epsilon: 0.542\n",
      "Episode: 1061 Duration: 0:00:01.945577 Num steps: 165 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.218 Epsilon: 0.541\n",
      "Episode: 1062 Duration: 0:00:02.112215 Num steps: 179 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.198 Epsilon: 0.541\n",
      "Episode: 1063 Duration: 0:00:03.693899 Num steps: 316 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.208 Epsilon: 0.541\n",
      "Episode: 1064 Duration: 0:00:02.506914 Num steps: 213 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.198 Epsilon: 0.540\n",
      "Episode: 1065 Duration: 0:00:02.240366 Num steps: 187 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.178 Epsilon: 0.540\n",
      "Episode: 1066 Duration: 0:00:02.924170 Num steps: 248 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.188 Epsilon: 0.539\n",
      "Episode: 1067 Duration: 0:00:02.960778 Num steps: 251 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.198 Epsilon: 0.539\n",
      "Episode: 1068 Duration: 0:00:02.508022 Num steps: 215 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.208 Epsilon: 0.539\n",
      "Episode: 1069 Duration: 0:00:02.049605 Num steps: 174 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.198 Epsilon: 0.538\n",
      "Episode: 1070 Duration: 0:00:02.293493 Num steps: 194 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.168 Epsilon: 0.538\n",
      "Episode: 1071 Duration: 0:00:02.437704 Num steps: 206 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.149 Epsilon: 0.538\n",
      "Episode: 1072 Duration: 0:00:02.101208 Num steps: 179 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.149 Epsilon: 0.537\n",
      "Episode: 1073 Duration: 0:00:01.990270 Num steps: 169 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.139 Epsilon: 0.537\n",
      "Episode: 1074 Duration: 0:00:02.918593 Num steps: 247 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.139 Epsilon: 0.536\n",
      "Episode: 1075 Duration: 0:00:02.882756 Num steps: 243 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.129 Epsilon: 0.536\n",
      "Episode: 1076 Duration: 0:00:02.292236 Num steps: 193 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.109 Epsilon: 0.536\n",
      "Episode: 1077 Duration: 0:00:02.115139 Num steps: 179 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.089 Epsilon: 0.535\n",
      "Episode: 1078 Duration: 0:00:02.963989 Num steps: 252 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.079 Epsilon: 0.535\n",
      "Episode: 1079 Duration: 0:00:05.821432 Num steps: 494 Reward: 6.0 Training time per step: 0.009 Avg Reward (Last 100): 1.139 Epsilon: 0.534\n",
      "Episode: 1080 Duration: 0:00:02.175664 Num steps: 184 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.119 Epsilon: 0.534\n",
      "Episode: 1081 Duration: 0:00:03.918108 Num steps: 331 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.149 Epsilon: 0.533\n",
      "Episode: 1082 Duration: 0:00:03.908666 Num steps: 333 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.178 Epsilon: 0.533\n",
      "Episode: 1083 Duration: 0:00:02.730426 Num steps: 231 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.178 Epsilon: 0.532\n",
      "Copied model parameters to target network. total_t = 260000, period = 10000\n",
      "Episode: 1084 Duration: 0:00:03.249294 Num steps: 254 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.158 Epsilon: 0.532\n",
      "Episode: 1085 Duration: 0:00:02.669920 Num steps: 225 Reward: 1.0 Training time per step: 0.010 Avg Reward (Last 100): 1.158 Epsilon: 0.531\n",
      "Episode: 1086 Duration: 0:00:02.580090 Num steps: 217 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.168 Epsilon: 0.531\n",
      "Episode: 1087 Duration: 0:00:05.178364 Num steps: 438 Reward: 5.0 Training time per step: 0.009 Avg Reward (Last 100): 1.208 Epsilon: 0.530\n",
      "Episode: 1088 Duration: 0:00:03.219996 Num steps: 272 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.208 Epsilon: 0.530\n",
      "Episode: 1089 Duration: 0:00:02.949775 Num steps: 249 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.208 Epsilon: 0.529\n",
      "Episode: 1090 Duration: 0:00:02.455829 Num steps: 207 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.208 Epsilon: 0.529\n",
      "Episode: 1091 Duration: 0:00:02.132503 Num steps: 179 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.208 Epsilon: 0.528\n",
      "Episode: 1092 Duration: 0:00:02.239405 Num steps: 190 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.188 Epsilon: 0.528\n",
      "Episode: 1093 Duration: 0:00:02.333792 Num steps: 198 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.178 Epsilon: 0.528\n",
      "Episode: 1094 Duration: 0:00:01.990143 Num steps: 169 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.178 Epsilon: 0.527\n",
      "Episode: 1095 Duration: 0:00:02.289286 Num steps: 193 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.149 Epsilon: 0.527\n",
      "Episode: 1096 Duration: 0:00:02.138157 Num steps: 181 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.129 Epsilon: 0.527\n",
      "Episode: 1097 Duration: 0:00:03.256515 Num steps: 274 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.149 Epsilon: 0.526\n",
      "Episode: 1098 Duration: 0:00:03.429409 Num steps: 289 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.168 Epsilon: 0.526\n",
      "Episode: 1099 Duration: 0:00:02.306808 Num steps: 196 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.158 Epsilon: 0.525\n",
      "Episode: 1100 Duration: 0:00:03.442985 Num steps: 292 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.149 Epsilon: 0.525\n",
      "Episode: 1101 Duration: 0:00:01.985228 Num steps: 169 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.129 Epsilon: 0.525\n",
      "Episode: 1102 Duration: 0:00:02.095969 Num steps: 177 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.129 Epsilon: 0.524\n",
      "Episode: 1103 Duration: 0:00:03.360061 Num steps: 286 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.149 Epsilon: 0.524\n",
      "Episode: 1104 Duration: 0:00:03.901697 Num steps: 332 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.139 Epsilon: 0.523\n",
      "Episode: 1105 Duration: 0:00:03.966481 Num steps: 334 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.139 Epsilon: 0.523\n",
      "Episode: 1106 Duration: 0:00:02.133515 Num steps: 179 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.139 Epsilon: 0.522\n",
      "Episode: 1107 Duration: 0:00:03.084880 Num steps: 262 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.149 Epsilon: 0.522\n",
      "Episode: 1108 Duration: 0:00:02.060162 Num steps: 174 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.129 Epsilon: 0.521\n",
      "Episode: 1109 Duration: 0:00:02.611037 Num steps: 222 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.139 Epsilon: 0.521\n",
      "Episode: 1110 Duration: 0:00:04.805850 Num steps: 408 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.168 Epsilon: 0.520\n",
      "Episode: 1111 Duration: 0:00:02.234441 Num steps: 190 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.149 Epsilon: 0.520\n",
      "Episode: 1112 Duration: 0:00:02.918241 Num steps: 248 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.149 Epsilon: 0.519\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1113 Duration: 0:00:02.206259 Num steps: 186 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.119 Epsilon: 0.519\n",
      "Episode: 1114 Duration: 0:00:02.465732 Num steps: 209 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.089 Epsilon: 0.519\n",
      "Episode: 1115 Duration: 0:00:02.157773 Num steps: 180 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.079 Epsilon: 0.518\n",
      "Episode: 1116 Duration: 0:00:01.958522 Num steps: 164 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.069 Epsilon: 0.518\n",
      "Episode: 1117 Duration: 0:00:02.735680 Num steps: 231 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.079 Epsilon: 0.518\n",
      "Episode: 1118 Duration: 0:00:02.147765 Num steps: 181 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.069 Epsilon: 0.517\n",
      "Episode: 1119 Duration: 0:00:03.812755 Num steps: 323 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.069 Epsilon: 0.517\n",
      "Episode: 1120 Duration: 0:00:04.387382 Num steps: 371 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.089 Epsilon: 0.516\n",
      "Episode: 1121 Duration: 0:00:02.355794 Num steps: 199 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.069 Epsilon: 0.516\n",
      "Episode: 1122 Duration: 0:00:03.568965 Num steps: 300 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.099 Epsilon: 0.515\n",
      "Episode: 1123 Duration: 0:00:03.485347 Num steps: 293 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.119 Epsilon: 0.515\n",
      "Episode: 1124 Duration: 0:00:03.218384 Num steps: 275 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.139 Epsilon: 0.514\n",
      "Copied model parameters to target network. total_t = 270000, period = 10000\n",
      "Episode: 1125 Duration: 0:00:04.457762 Num steps: 355 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.168 Epsilon: 0.514\n",
      "Episode: 1126 Duration: 0:00:03.393706 Num steps: 287 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.188 Epsilon: 0.513\n",
      "Episode: 1127 Duration: 0:00:03.052425 Num steps: 255 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.198 Epsilon: 0.513\n",
      "Episode: 1128 Duration: 0:00:02.310237 Num steps: 193 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.188 Epsilon: 0.512\n",
      "Episode: 1129 Duration: 0:00:02.171333 Num steps: 184 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.188 Epsilon: 0.512\n",
      "Episode: 1130 Duration: 0:00:02.198204 Num steps: 186 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.158 Epsilon: 0.512\n",
      "Episode: 1131 Duration: 0:00:02.515017 Num steps: 212 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.158 Epsilon: 0.511\n",
      "Episode: 1132 Duration: 0:00:02.117179 Num steps: 179 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.119 Epsilon: 0.511\n",
      "Episode: 1133 Duration: 0:00:03.161248 Num steps: 268 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.119 Epsilon: 0.510\n",
      "Episode: 1134 Duration: 0:00:04.603021 Num steps: 392 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.139 Epsilon: 0.510\n",
      "Episode: 1135 Duration: 0:00:04.163953 Num steps: 353 Reward: 4.0 Training time per step: 0.009 Avg Reward (Last 100): 1.168 Epsilon: 0.509\n",
      "Episode: 1136 Duration: 0:00:02.120607 Num steps: 179 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.139 Epsilon: 0.509\n",
      "Episode: 1137 Duration: 0:00:02.882033 Num steps: 241 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.149 Epsilon: 0.508\n",
      "Episode: 1138 Duration: 0:00:03.040329 Num steps: 258 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.149 Epsilon: 0.508\n",
      "Episode: 1139 Duration: 0:00:04.358929 Num steps: 368 Reward: 4.0 Training time per step: 0.009 Avg Reward (Last 100): 1.188 Epsilon: 0.507\n",
      "Episode: 1140 Duration: 0:00:02.362416 Num steps: 199 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.168 Epsilon: 0.507\n",
      "Episode: 1141 Duration: 0:00:02.067060 Num steps: 171 Reward: 0.0 Training time per step: 0.010 Avg Reward (Last 100): 1.168 Epsilon: 0.507\n",
      "Episode: 1142 Duration: 0:00:03.845150 Num steps: 325 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.198 Epsilon: 0.506\n",
      "Episode: 1143 Duration: 0:00:02.114051 Num steps: 178 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.188 Epsilon: 0.506\n",
      "Episode: 1144 Duration: 0:00:02.277878 Num steps: 192 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.158 Epsilon: 0.505\n",
      "Episode: 1145 Duration: 0:00:03.192261 Num steps: 269 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.158 Epsilon: 0.505\n",
      "Episode: 1146 Duration: 0:00:03.508759 Num steps: 294 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.168 Epsilon: 0.504\n",
      "Episode: 1147 Duration: 0:00:03.172044 Num steps: 269 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.178 Epsilon: 0.504\n",
      "Episode: 1148 Duration: 0:00:02.093205 Num steps: 176 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.178 Epsilon: 0.503\n",
      "Episode: 1149 Duration: 0:00:02.042959 Num steps: 172 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.149 Epsilon: 0.503\n",
      "Episode: 1150 Duration: 0:00:04.563452 Num steps: 385 Reward: 4.0 Training time per step: 0.009 Avg Reward (Last 100): 1.188 Epsilon: 0.502\n",
      "Episode: 1151 Duration: 0:00:02.092578 Num steps: 176 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.178 Epsilon: 0.502\n",
      "Episode: 1152 Duration: 0:00:02.861129 Num steps: 242 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.178 Epsilon: 0.502\n",
      "Episode: 1153 Duration: 0:00:04.327227 Num steps: 364 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.188 Epsilon: 0.501\n",
      "Episode: 1154 Duration: 0:00:01.929578 Num steps: 162 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.188 Epsilon: 0.501\n",
      "Episode: 1155 Duration: 0:00:02.864606 Num steps: 243 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.198 Epsilon: 0.500\n",
      "Episode: 1156 Duration: 0:00:05.266202 Num steps: 445 Reward: 5.0 Training time per step: 0.009 Avg Reward (Last 100): 1.248 Epsilon: 0.500\n",
      "Episode: 1157 Duration: 0:00:02.419620 Num steps: 202 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.238 Epsilon: 0.499\n",
      "Episode: 1158 Duration: 0:00:02.642751 Num steps: 225 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.248 Epsilon: 0.499\n",
      "Episode: 1159 Duration: 0:00:03.854562 Num steps: 326 Reward: 4.0 Training time per step: 0.009 Avg Reward (Last 100): 1.287 Epsilon: 0.498\n",
      "Episode: 1160 Duration: 0:00:01.999851 Num steps: 169 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.248 Epsilon: 0.498\n",
      "Episode: 1161 Duration: 0:00:03.449335 Num steps: 291 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.248 Epsilon: 0.497\n",
      "Episode: 1162 Duration: 0:00:03.035531 Num steps: 257 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.267 Epsilon: 0.497\n",
      "Episode: 1163 Duration: 0:00:02.166597 Num steps: 183 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.267 Epsilon: 0.497\n",
      "Episode: 1164 Duration: 0:00:02.033017 Num steps: 172 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.238 Epsilon: 0.496\n",
      "Copied model parameters to target network. total_t = 280000, period = 10000\n",
      "Episode: 1165 Duration: 0:00:02.391563 Num steps: 180 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.228 Epsilon: 0.496\n",
      "Episode: 1166 Duration: 0:00:03.221115 Num steps: 270 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.248 Epsilon: 0.495\n",
      "Episode: 1167 Duration: 0:00:02.343133 Num steps: 197 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.228 Epsilon: 0.495\n",
      "Episode: 1168 Duration: 0:00:03.407151 Num steps: 285 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.228 Epsilon: 0.495\n",
      "Episode: 1169 Duration: 0:00:02.748953 Num steps: 231 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.228 Epsilon: 0.494\n",
      "Episode: 1170 Duration: 0:00:02.841412 Num steps: 240 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.238 Epsilon: 0.494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1171 Duration: 0:00:02.700528 Num steps: 228 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.248 Epsilon: 0.493\n",
      "Episode: 1172 Duration: 0:00:03.537892 Num steps: 301 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.257 Epsilon: 0.493\n",
      "Episode: 1173 Duration: 0:00:04.431333 Num steps: 375 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.287 Epsilon: 0.492\n",
      "Episode: 1174 Duration: 0:00:04.345451 Num steps: 367 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.317 Epsilon: 0.491\n",
      "Episode: 1175 Duration: 0:00:02.192604 Num steps: 182 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.307 Epsilon: 0.491\n",
      "Episode: 1176 Duration: 0:00:03.928819 Num steps: 334 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.327 Epsilon: 0.491\n",
      "Episode: 1177 Duration: 0:00:04.154521 Num steps: 351 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.356 Epsilon: 0.490\n",
      "Episode: 1178 Duration: 0:00:03.873184 Num steps: 327 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.386 Epsilon: 0.489\n",
      "Episode: 1179 Duration: 0:00:03.174782 Num steps: 267 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.396 Epsilon: 0.489\n",
      "Episode: 1180 Duration: 0:00:01.933668 Num steps: 163 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.337 Epsilon: 0.489\n",
      "Episode: 1181 Duration: 0:00:03.710464 Num steps: 311 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.356 Epsilon: 0.488\n",
      "Episode: 1182 Duration: 0:00:02.543842 Num steps: 214 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.337 Epsilon: 0.488\n",
      "Episode: 1183 Duration: 0:00:02.494762 Num steps: 210 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.317 Epsilon: 0.487\n",
      "Episode: 1184 Duration: 0:00:03.985419 Num steps: 337 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.337 Epsilon: 0.487\n",
      "Episode: 1185 Duration: 0:00:02.874863 Num steps: 239 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.337 Epsilon: 0.486\n",
      "Episode: 1186 Duration: 0:00:03.552619 Num steps: 301 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.347 Epsilon: 0.486\n",
      "Episode: 1187 Duration: 0:00:03.767870 Num steps: 318 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.366 Epsilon: 0.485\n",
      "Episode: 1188 Duration: 0:00:03.946471 Num steps: 330 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.347 Epsilon: 0.484\n",
      "Episode: 1189 Duration: 0:00:03.780266 Num steps: 318 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.356 Epsilon: 0.484\n",
      "Episode: 1190 Duration: 0:00:02.726176 Num steps: 228 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.356 Epsilon: 0.483\n",
      "Episode: 1191 Duration: 0:00:02.837435 Num steps: 239 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.356 Epsilon: 0.483\n",
      "Episode: 1192 Duration: 0:00:03.254855 Num steps: 274 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.376 Epsilon: 0.483\n",
      "Episode: 1193 Duration: 0:00:02.926900 Num steps: 247 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.396 Epsilon: 0.482\n",
      "Episode: 1194 Duration: 0:00:03.262524 Num steps: 276 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.416 Epsilon: 0.482\n",
      "Episode: 1195 Duration: 0:00:03.993740 Num steps: 336 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.446 Epsilon: 0.481\n",
      "Episode: 1196 Duration: 0:00:02.440739 Num steps: 206 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.455 Epsilon: 0.481\n",
      "Episode: 1197 Duration: 0:00:02.143253 Num steps: 179 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.455 Epsilon: 0.480\n",
      "Episode: 1198 Duration: 0:00:02.365218 Num steps: 200 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.436 Epsilon: 0.480\n",
      "Episode: 1199 Duration: 0:00:03.287934 Num steps: 277 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.436 Epsilon: 0.479\n",
      "Episode: 1200 Duration: 0:00:02.201676 Num steps: 185 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.436 Epsilon: 0.479\n",
      "Episode: 1201 Duration: 0:00:04.217117 Num steps: 355 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.446 Epsilon: 0.478\n",
      "Copied model parameters to target network. total_t = 290000, period = 10000\n",
      "Episode: 1202 Duration: 0:00:03.637925 Num steps: 288 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.465 Epsilon: 0.478\n",
      "Episode: 1203 Duration: 0:00:02.677655 Num steps: 226 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.475 Epsilon: 0.478\n",
      "Episode: 1204 Duration: 0:00:03.569624 Num steps: 299 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.475 Epsilon: 0.477\n",
      "Episode: 1205 Duration: 0:00:02.759997 Num steps: 231 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.455 Epsilon: 0.477\n",
      "Episode: 1206 Duration: 0:00:02.986893 Num steps: 251 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.436 Epsilon: 0.476\n",
      "Episode: 1207 Duration: 0:00:04.207861 Num steps: 357 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.465 Epsilon: 0.476\n",
      "Episode: 1208 Duration: 0:00:03.553528 Num steps: 299 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.465 Epsilon: 0.475\n",
      "Episode: 1209 Duration: 0:00:03.831808 Num steps: 323 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.485 Epsilon: 0.474\n",
      "Episode: 1210 Duration: 0:00:02.369309 Num steps: 199 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.475 Epsilon: 0.474\n",
      "Episode: 1211 Duration: 0:00:03.069826 Num steps: 258 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.455 Epsilon: 0.474\n",
      "Episode: 1212 Duration: 0:00:03.802489 Num steps: 320 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.485 Epsilon: 0.473\n",
      "Episode: 1213 Duration: 0:00:02.633141 Num steps: 221 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.485 Epsilon: 0.473\n",
      "Episode: 1214 Duration: 0:00:02.048031 Num steps: 174 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.485 Epsilon: 0.472\n",
      "Episode: 1215 Duration: 0:00:03.838724 Num steps: 326 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.515 Epsilon: 0.472\n",
      "Episode: 1216 Duration: 0:00:03.337266 Num steps: 281 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.535 Epsilon: 0.471\n",
      "Episode: 1217 Duration: 0:00:02.121281 Num steps: 178 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.535 Epsilon: 0.471\n",
      "Episode: 1218 Duration: 0:00:02.008206 Num steps: 169 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.525 Epsilon: 0.471\n",
      "Episode: 1219 Duration: 0:00:03.273472 Num steps: 275 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.545 Epsilon: 0.470\n",
      "Episode: 1220 Duration: 0:00:03.573657 Num steps: 303 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.545 Epsilon: 0.470\n",
      "Episode: 1221 Duration: 0:00:02.848473 Num steps: 241 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.525 Epsilon: 0.469\n",
      "Episode: 1222 Duration: 0:00:03.544865 Num steps: 298 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.554 Epsilon: 0.469\n",
      "Episode: 1223 Duration: 0:00:03.401395 Num steps: 286 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.545 Epsilon: 0.468\n",
      "Episode: 1224 Duration: 0:00:03.986786 Num steps: 337 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.545 Epsilon: 0.467\n",
      "Episode: 1225 Duration: 0:00:02.965799 Num steps: 249 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.535 Epsilon: 0.467\n",
      "Episode: 1226 Duration: 0:00:03.315475 Num steps: 280 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.525 Epsilon: 0.466\n",
      "Episode: 1227 Duration: 0:00:02.338002 Num steps: 195 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.505 Epsilon: 0.466\n",
      "Episode: 1228 Duration: 0:00:04.857040 Num steps: 410 Reward: 4.0 Training time per step: 0.009 Avg Reward (Last 100): 1.525 Epsilon: 0.465\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1229 Duration: 0:00:03.141794 Num steps: 264 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.535 Epsilon: 0.465\n",
      "Episode: 1230 Duration: 0:00:02.683370 Num steps: 228 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.545 Epsilon: 0.465\n",
      "Episode: 1231 Duration: 0:00:03.723914 Num steps: 314 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.564 Epsilon: 0.464\n",
      "Episode: 1232 Duration: 0:00:02.165160 Num steps: 183 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.554 Epsilon: 0.464\n",
      "Episode: 1233 Duration: 0:00:02.681764 Num steps: 228 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.564 Epsilon: 0.463\n",
      "Episode: 1234 Duration: 0:00:02.989374 Num steps: 252 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.564 Epsilon: 0.463\n",
      "Episode: 1235 Duration: 0:00:03.968873 Num steps: 335 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.564 Epsilon: 0.462\n",
      "Episode: 1236 Duration: 0:00:02.860834 Num steps: 240 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.535 Epsilon: 0.462\n",
      "Episode: 1237 Duration: 0:00:03.348974 Num steps: 283 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.554 Epsilon: 0.461\n",
      "Episode: 1238 Duration: 0:00:03.406853 Num steps: 288 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.564 Epsilon: 0.461\n",
      "Episode: 1239 Duration: 0:00:02.674460 Num steps: 226 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.564 Epsilon: 0.460\n",
      "Copied model parameters to target network. total_t = 300000, period = 10000\n",
      "Episode: 1240 Duration: 0:00:03.558296 Num steps: 280 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.535 Epsilon: 0.460\n",
      "Episode: 1241 Duration: 0:00:02.804672 Num steps: 235 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.545 Epsilon: 0.459\n",
      "Episode: 1242 Duration: 0:00:04.891347 Num steps: 409 Reward: 4.0 Training time per step: 0.009 Avg Reward (Last 100): 1.584 Epsilon: 0.459\n",
      "Episode: 1243 Duration: 0:00:04.281977 Num steps: 360 Reward: 4.0 Training time per step: 0.009 Avg Reward (Last 100): 1.594 Epsilon: 0.458\n",
      "Episode: 1244 Duration: 0:00:04.169904 Num steps: 350 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.624 Epsilon: 0.457\n",
      "Episode: 1245 Duration: 0:00:02.876763 Num steps: 241 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.634 Epsilon: 0.457\n",
      "Episode: 1246 Duration: 0:00:03.558240 Num steps: 301 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.634 Epsilon: 0.456\n",
      "Episode: 1247 Duration: 0:00:03.741303 Num steps: 313 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.634 Epsilon: 0.456\n",
      "Episode: 1248 Duration: 0:00:02.402688 Num steps: 203 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.624 Epsilon: 0.455\n",
      "Episode: 1249 Duration: 0:00:03.399011 Num steps: 287 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.644 Epsilon: 0.455\n",
      "Episode: 1250 Duration: 0:00:05.511421 Num steps: 467 Reward: 5.0 Training time per step: 0.009 Avg Reward (Last 100): 1.693 Epsilon: 0.454\n",
      "Episode: 1251 Duration: 0:00:05.016562 Num steps: 421 Reward: 4.0 Training time per step: 0.009 Avg Reward (Last 100): 1.693 Epsilon: 0.453\n",
      "Episode: 1252 Duration: 0:00:03.189147 Num steps: 268 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.713 Epsilon: 0.453\n",
      "Episode: 1253 Duration: 0:00:02.461534 Num steps: 208 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.713 Epsilon: 0.452\n",
      "Episode: 1254 Duration: 0:00:03.159119 Num steps: 265 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.693 Epsilon: 0.452\n",
      "Episode: 1255 Duration: 0:00:03.518866 Num steps: 297 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.713 Epsilon: 0.451\n",
      "Episode: 1256 Duration: 0:00:02.755014 Num steps: 230 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.703 Epsilon: 0.451\n",
      "Episode: 1257 Duration: 0:00:04.598658 Num steps: 387 Reward: 4.0 Training time per step: 0.009 Avg Reward (Last 100): 1.693 Epsilon: 0.450\n",
      "Episode: 1258 Duration: 0:00:03.475025 Num steps: 281 Reward: 2.0 Training time per step: 0.010 Avg Reward (Last 100): 1.713 Epsilon: 0.450\n",
      "Episode: 1259 Duration: 0:00:05.186734 Num steps: 358 Reward: 3.0 Training time per step: 0.012 Avg Reward (Last 100): 1.733 Epsilon: 0.449\n",
      "Episode: 1260 Duration: 0:00:06.366519 Num steps: 424 Reward: 4.0 Training time per step: 0.012 Avg Reward (Last 100): 1.733 Epsilon: 0.448\n",
      "Episode: 1261 Duration: 0:00:03.941648 Num steps: 329 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.752 Epsilon: 0.448\n",
      "Episode: 1262 Duration: 0:00:03.487346 Num steps: 290 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.752 Epsilon: 0.447\n",
      "Episode: 1263 Duration: 0:00:03.596023 Num steps: 302 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.762 Epsilon: 0.447\n",
      "Episode: 1264 Duration: 0:00:03.895331 Num steps: 324 Reward: 3.0 Training time per step: 0.010 Avg Reward (Last 100): 1.792 Epsilon: 0.446\n",
      "Episode: 1265 Duration: 0:00:04.422442 Num steps: 370 Reward: 4.0 Training time per step: 0.009 Avg Reward (Last 100): 1.832 Epsilon: 0.446\n",
      "Episode: 1266 Duration: 0:00:02.782842 Num steps: 229 Reward: 1.0 Training time per step: 0.010 Avg Reward (Last 100): 1.842 Epsilon: 0.445\n",
      "Episode: 1267 Duration: 0:00:03.120717 Num steps: 260 Reward: 2.0 Training time per step: 0.010 Avg Reward (Last 100): 1.842 Epsilon: 0.445\n",
      "Episode: 1268 Duration: 0:00:03.219160 Num steps: 266 Reward: 1.0 Training time per step: 0.010 Avg Reward (Last 100): 1.851 Epsilon: 0.444\n",
      "Episode: 1269 Duration: 0:00:02.647584 Num steps: 220 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.842 Epsilon: 0.444\n",
      "Episode: 1270 Duration: 0:00:02.643382 Num steps: 220 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.842 Epsilon: 0.443\n",
      "Episode: 1271 Duration: 0:00:02.279863 Num steps: 189 Reward: 0.0 Training time per step: 0.010 Avg Reward (Last 100): 1.832 Epsilon: 0.443\n",
      "Episode: 1272 Duration: 0:00:05.078467 Num steps: 426 Reward: 4.0 Training time per step: 0.009 Avg Reward (Last 100): 1.861 Epsilon: 0.442\n",
      "Copied model parameters to target network. total_t = 310000, period = 10000\n",
      "Episode: 1273 Duration: 0:00:02.463677 Num steps: 187 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.842 Epsilon: 0.442\n",
      "Episode: 1274 Duration: 0:00:02.490325 Num steps: 206 Reward: 1.0 Training time per step: 0.010 Avg Reward (Last 100): 1.822 Epsilon: 0.442\n",
      "Episode: 1275 Duration: 0:00:04.664047 Num steps: 389 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.822 Epsilon: 0.441\n",
      "Episode: 1276 Duration: 0:00:02.033290 Num steps: 169 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.822 Epsilon: 0.441\n",
      "Episode: 1277 Duration: 0:00:04.210963 Num steps: 354 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.822 Epsilon: 0.440\n",
      "Episode: 1278 Duration: 0:00:03.686041 Num steps: 307 Reward: 2.0 Training time per step: 0.010 Avg Reward (Last 100): 1.812 Epsilon: 0.439\n",
      "Episode: 1279 Duration: 0:00:03.407084 Num steps: 286 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.802 Epsilon: 0.439\n",
      "Episode: 1280 Duration: 0:00:02.394417 Num steps: 200 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.782 Epsilon: 0.438\n",
      "Episode: 1281 Duration: 0:00:02.973799 Num steps: 249 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.802 Epsilon: 0.438\n",
      "Episode: 1282 Duration: 0:00:02.321993 Num steps: 195 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.782 Epsilon: 0.438\n",
      "Episode: 1283 Duration: 0:00:02.545461 Num steps: 214 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.782 Epsilon: 0.437\n",
      "Episode: 1284 Duration: 0:00:02.930324 Num steps: 244 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.792 Epsilon: 0.437\n",
      "Episode: 1285 Duration: 0:00:03.692791 Num steps: 309 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.782 Epsilon: 0.436\n",
      "Episode: 1286 Duration: 0:00:03.693885 Num steps: 309 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.802 Epsilon: 0.436\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1287 Duration: 0:00:03.338918 Num steps: 279 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.802 Epsilon: 0.435\n",
      "Episode: 1288 Duration: 0:00:03.765606 Num steps: 313 Reward: 3.0 Training time per step: 0.010 Avg Reward (Last 100): 1.802 Epsilon: 0.435\n",
      "Episode: 1289 Duration: 0:00:03.593448 Num steps: 303 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.802 Epsilon: 0.434\n",
      "Episode: 1290 Duration: 0:00:02.116921 Num steps: 176 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.772 Epsilon: 0.434\n",
      "Episode: 1291 Duration: 0:00:02.837538 Num steps: 236 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.772 Epsilon: 0.433\n",
      "Episode: 1292 Duration: 0:00:04.494637 Num steps: 376 Reward: 4.0 Training time per step: 0.009 Avg Reward (Last 100): 1.802 Epsilon: 0.433\n",
      "Episode: 1293 Duration: 0:00:02.342877 Num steps: 194 Reward: 0.0 Training time per step: 0.010 Avg Reward (Last 100): 1.782 Epsilon: 0.432\n",
      "Episode: 1294 Duration: 0:00:02.951984 Num steps: 246 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.782 Epsilon: 0.432\n",
      "Episode: 1295 Duration: 0:00:05.463303 Num steps: 458 Reward: 5.0 Training time per step: 0.009 Avg Reward (Last 100): 1.812 Epsilon: 0.431\n",
      "Episode: 1296 Duration: 0:00:03.718015 Num steps: 310 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.802 Epsilon: 0.431\n",
      "Episode: 1297 Duration: 0:00:04.119559 Num steps: 343 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.822 Epsilon: 0.430\n",
      "Episode: 1298 Duration: 0:00:04.763121 Num steps: 398 Reward: 5.0 Training time per step: 0.009 Avg Reward (Last 100): 1.871 Epsilon: 0.429\n",
      "Episode: 1299 Duration: 0:00:05.559315 Num steps: 464 Reward: 6.0 Training time per step: 0.009 Avg Reward (Last 100): 1.931 Epsilon: 0.428\n",
      "Episode: 1300 Duration: 0:00:03.473865 Num steps: 290 Reward: 2.0 Training time per step: 0.010 Avg Reward (Last 100): 1.931 Epsilon: 0.428\n",
      "Episode: 1301 Duration: 0:00:04.985120 Num steps: 419 Reward: 5.0 Training time per step: 0.009 Avg Reward (Last 100): 1.980 Epsilon: 0.427\n",
      "Episode: 1302 Duration: 0:00:03.469659 Num steps: 290 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.970 Epsilon: 0.427\n",
      "Episode: 1303 Duration: 0:00:02.890881 Num steps: 242 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.960 Epsilon: 0.426\n",
      "Episode: 1304 Duration: 0:00:04.815201 Num steps: 405 Reward: 5.0 Training time per step: 0.009 Avg Reward (Last 100): 2.000 Epsilon: 0.425\n",
      "Episode: 1305 Duration: 0:00:02.898625 Num steps: 243 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 2.000 Epsilon: 0.425\n",
      "Episode: 1306 Duration: 0:00:02.849760 Num steps: 239 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 2.000 Epsilon: 0.425\n",
      "Episode: 1307 Duration: 0:00:03.000840 Num steps: 251 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 2.010 Epsilon: 0.424\n",
      "Copied model parameters to target network. total_t = 320000, period = 10000\n",
      "Episode: 1308 Duration: 0:00:03.940313 Num steps: 305 Reward: 3.0 Training time per step: 0.010 Avg Reward (Last 100): 2.010 Epsilon: 0.424\n",
      "Episode: 1309 Duration: 0:00:03.011803 Num steps: 250 Reward: 2.0 Training time per step: 0.010 Avg Reward (Last 100): 2.010 Epsilon: 0.423\n",
      "Episode: 1310 Duration: 0:00:02.114104 Num steps: 176 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.990 Epsilon: 0.423\n",
      "Episode: 1311 Duration: 0:00:02.678232 Num steps: 224 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 2.000 Epsilon: 0.422\n",
      "Episode: 1312 Duration: 0:00:03.430621 Num steps: 285 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 2.010 Epsilon: 0.422\n",
      "Episode: 1313 Duration: 0:00:02.982241 Num steps: 249 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.990 Epsilon: 0.421\n",
      "Episode: 1314 Duration: 0:00:02.436215 Num steps: 204 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.980 Epsilon: 0.421\n",
      "Episode: 1315 Duration: 0:00:03.079001 Num steps: 256 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 2.000 Epsilon: 0.421\n",
      "Episode: 1316 Duration: 0:00:03.453066 Num steps: 289 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.990 Epsilon: 0.420\n",
      "Episode: 1317 Duration: 0:00:04.314242 Num steps: 361 Reward: 4.0 Training time per step: 0.009 Avg Reward (Last 100): 2.010 Epsilon: 0.419\n",
      "Episode: 1318 Duration: 0:00:03.507630 Num steps: 293 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 2.040 Epsilon: 0.419\n",
      "Episode: 1319 Duration: 0:00:02.046273 Num steps: 172 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 2.040 Epsilon: 0.419\n",
      "Episode: 1320 Duration: 0:00:02.377463 Num steps: 199 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 2.020 Epsilon: 0.418\n",
      "Episode: 1321 Duration: 0:00:02.961872 Num steps: 248 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 2.020 Epsilon: 0.418\n",
      "Episode: 1322 Duration: 0:00:02.849405 Num steps: 237 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 2.020 Epsilon: 0.417\n",
      "Episode: 1323 Duration: 0:00:03.251539 Num steps: 272 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 2.010 Epsilon: 0.417\n",
      "Episode: 1324 Duration: 0:00:02.667154 Num steps: 221 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 2.000 Epsilon: 0.416\n",
      "Episode: 1325 Duration: 0:00:02.131988 Num steps: 177 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.980 Epsilon: 0.416\n",
      "Episode: 1326 Duration: 0:00:02.958134 Num steps: 246 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.990 Epsilon: 0.416\n",
      "Episode: 1327 Duration: 0:00:03.039752 Num steps: 254 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.990 Epsilon: 0.415\n",
      "Episode: 1328 Duration: 0:00:02.662906 Num steps: 224 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 2.000 Epsilon: 0.415\n",
      "Episode: 1329 Duration: 0:00:02.496110 Num steps: 209 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.960 Epsilon: 0.414\n",
      "Episode: 1330 Duration: 0:00:02.708046 Num steps: 223 Reward: 1.0 Training time per step: 0.010 Avg Reward (Last 100): 1.960 Epsilon: 0.414\n",
      "Episode: 1331 Duration: 0:00:03.455216 Num steps: 287 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.970 Epsilon: 0.414\n",
      "Episode: 1332 Duration: 0:00:02.938272 Num steps: 245 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.960 Epsilon: 0.413\n",
      "Episode: 1333 Duration: 0:00:04.292381 Num steps: 360 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.990 Epsilon: 0.412\n",
      "Episode: 1334 Duration: 0:00:03.311019 Num steps: 275 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 2.010 Epsilon: 0.412\n",
      "Episode: 1335 Duration: 0:00:02.691361 Num steps: 224 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 2.000 Epsilon: 0.412\n",
      "Episode: 1336 Duration: 0:00:03.201921 Num steps: 266 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.990 Epsilon: 0.411\n",
      "Episode: 1337 Duration: 0:00:02.897271 Num steps: 242 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.990 Epsilon: 0.411\n",
      "Episode: 1338 Duration: 0:00:04.862071 Num steps: 404 Reward: 4.0 Training time per step: 0.009 Avg Reward (Last 100): 2.010 Epsilon: 0.410\n",
      "Episode: 1339 Duration: 0:00:02.706128 Num steps: 226 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 2.000 Epsilon: 0.410\n",
      "Episode: 1340 Duration: 0:00:05.067693 Num steps: 423 Reward: 4.0 Training time per step: 0.009 Avg Reward (Last 100): 2.030 Epsilon: 0.409\n",
      "Episode: 1341 Duration: 0:00:02.424384 Num steps: 202 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 2.020 Epsilon: 0.408\n",
      "Episode: 1342 Duration: 0:00:03.820238 Num steps: 319 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 2.040 Epsilon: 0.408\n",
      "Episode: 1343 Duration: 0:00:05.268714 Num steps: 439 Reward: 5.0 Training time per step: 0.009 Avg Reward (Last 100): 2.050 Epsilon: 0.407\n",
      "Episode: 1344 Duration: 0:00:02.558286 Num steps: 212 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 2.020 Epsilon: 0.407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied model parameters to target network. total_t = 330000, period = 10000\n",
      "Episode: 1345 Duration: 0:00:04.593217 Num steps: 361 Reward: 4.0 Training time per step: 0.009 Avg Reward (Last 100): 2.030 Epsilon: 0.406\n",
      "Episode: 1346 Duration: 0:00:03.071338 Num steps: 254 Reward: 2.0 Training time per step: 0.010 Avg Reward (Last 100): 2.040 Epsilon: 0.406\n",
      "Episode: 1347 Duration: 0:00:03.231109 Num steps: 269 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 2.040 Epsilon: 0.405\n",
      "Episode: 1348 Duration: 0:00:03.710577 Num steps: 308 Reward: 2.0 Training time per step: 0.010 Avg Reward (Last 100): 2.040 Epsilon: 0.404\n",
      "Episode: 1349 Duration: 0:00:02.125647 Num steps: 175 Reward: 0.0 Training time per step: 0.010 Avg Reward (Last 100): 2.030 Epsilon: 0.404\n",
      "Episode: 1350 Duration: 0:00:02.544227 Num steps: 212 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 2.020 Epsilon: 0.404\n",
      "Episode: 1351 Duration: 0:00:03.355941 Num steps: 276 Reward: 2.0 Training time per step: 0.010 Avg Reward (Last 100): 1.990 Epsilon: 0.403\n",
      "Episode: 1352 Duration: 0:00:06.410528 Num steps: 535 Reward: 6.0 Training time per step: 0.009 Avg Reward (Last 100): 2.010 Epsilon: 0.402\n",
      "Episode: 1353 Duration: 0:00:02.927229 Num steps: 244 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 2.010 Epsilon: 0.402\n",
      "Episode: 1354 Duration: 0:00:02.614059 Num steps: 218 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 2.010 Epsilon: 0.401\n",
      "Episode: 1355 Duration: 0:00:03.089478 Num steps: 257 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 2.020 Epsilon: 0.401\n",
      "Episode: 1356 Duration: 0:00:03.269722 Num steps: 273 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 2.020 Epsilon: 0.401\n",
      "Episode: 1357 Duration: 0:00:02.378686 Num steps: 199 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 2.010 Epsilon: 0.400\n",
      "Episode: 1358 Duration: 0:00:03.313564 Num steps: 276 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.990 Epsilon: 0.400\n",
      "Episode: 1359 Duration: 0:00:04.482612 Num steps: 375 Reward: 4.0 Training time per step: 0.009 Avg Reward (Last 100): 2.010 Epsilon: 0.399\n",
      "Episode: 1360 Duration: 0:00:03.216482 Num steps: 268 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.990 Epsilon: 0.399\n",
      "Episode: 1361 Duration: 0:00:03.385588 Num steps: 284 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 1.970 Epsilon: 0.398\n",
      "Episode: 1362 Duration: 0:00:03.735507 Num steps: 312 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.980 Epsilon: 0.397\n",
      "Episode: 1363 Duration: 0:00:04.692967 Num steps: 391 Reward: 4.0 Training time per step: 0.009 Avg Reward (Last 100): 2.000 Epsilon: 0.397\n",
      "Episode: 1364 Duration: 0:00:03.978408 Num steps: 332 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 2.000 Epsilon: 0.396\n",
      "Episode: 1365 Duration: 0:00:03.945397 Num steps: 327 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 2.000 Epsilon: 0.396\n",
      "Episode: 1366 Duration: 0:00:03.036108 Num steps: 253 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.970 Epsilon: 0.395\n",
      "Episode: 1367 Duration: 0:00:03.901391 Num steps: 325 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 1.990 Epsilon: 0.395\n",
      "Episode: 1368 Duration: 0:00:02.123041 Num steps: 176 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.970 Epsilon: 0.394\n",
      "Episode: 1369 Duration: 0:00:02.829371 Num steps: 234 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.970 Epsilon: 0.394\n",
      "Episode: 1370 Duration: 0:00:02.251130 Num steps: 186 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 1.960 Epsilon: 0.393\n",
      "Episode: 1371 Duration: 0:00:02.962906 Num steps: 248 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 1.960 Epsilon: 0.393\n",
      "Episode: 1372 Duration: 0:00:04.383925 Num steps: 367 Reward: 4.0 Training time per step: 0.009 Avg Reward (Last 100): 2.000 Epsilon: 0.392\n",
      "Episode: 1373 Duration: 0:00:04.467961 Num steps: 371 Reward: 4.0 Training time per step: 0.009 Avg Reward (Last 100): 2.000 Epsilon: 0.392\n",
      "Episode: 1374 Duration: 0:00:03.239430 Num steps: 271 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 2.020 Epsilon: 0.391\n",
      "Episode: 1375 Duration: 0:00:05.666047 Num steps: 473 Reward: 5.0 Training time per step: 0.009 Avg Reward (Last 100): 2.059 Epsilon: 0.390\n",
      "Episode: 1376 Duration: 0:00:03.569223 Num steps: 296 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 2.050 Epsilon: 0.390\n",
      "Episode: 1377 Duration: 0:00:04.200325 Num steps: 350 Reward: 4.0 Training time per step: 0.009 Avg Reward (Last 100): 2.089 Epsilon: 0.389\n",
      "Episode: 1378 Duration: 0:00:03.900078 Num steps: 328 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 2.089 Epsilon: 0.389\n",
      "Episode: 1379 Duration: 0:00:02.163143 Num steps: 180 Reward: 0.0 Training time per step: 0.009 Avg Reward (Last 100): 2.069 Epsilon: 0.388\n",
      "Copied model parameters to target network. total_t = 340000, period = 10000\n",
      "Episode: 1380 Duration: 0:00:03.020507 Num steps: 229 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 2.059 Epsilon: 0.388\n",
      "Episode: 1381 Duration: 0:00:05.981468 Num steps: 496 Reward: 6.0 Training time per step: 0.010 Avg Reward (Last 100): 2.119 Epsilon: 0.387\n",
      "Episode: 1382 Duration: 0:00:04.908592 Num steps: 406 Reward: 5.0 Training time per step: 0.010 Avg Reward (Last 100): 2.149 Epsilon: 0.386\n",
      "Episode: 1383 Duration: 0:00:04.553089 Num steps: 383 Reward: 4.0 Training time per step: 0.009 Avg Reward (Last 100): 2.188 Epsilon: 0.386\n",
      "Episode: 1384 Duration: 0:00:04.398217 Num steps: 367 Reward: 4.0 Training time per step: 0.009 Avg Reward (Last 100): 2.218 Epsilon: 0.385\n",
      "Episode: 1385 Duration: 0:00:03.406061 Num steps: 283 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 2.218 Epsilon: 0.384\n",
      "Episode: 1386 Duration: 0:00:03.980297 Num steps: 331 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 2.228 Epsilon: 0.384\n",
      "Episode: 1387 Duration: 0:00:02.425126 Num steps: 202 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 2.208 Epsilon: 0.383\n",
      "Episode: 1388 Duration: 0:00:04.093945 Num steps: 340 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 2.218 Epsilon: 0.383\n",
      "Episode: 1389 Duration: 0:00:03.334932 Num steps: 277 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 2.198 Epsilon: 0.382\n",
      "Episode: 1390 Duration: 0:00:04.609451 Num steps: 384 Reward: 4.0 Training time per step: 0.009 Avg Reward (Last 100): 2.208 Epsilon: 0.382\n",
      "Episode: 1391 Duration: 0:00:03.802121 Num steps: 315 Reward: 3.0 Training time per step: 0.010 Avg Reward (Last 100): 2.238 Epsilon: 0.381\n",
      "Episode: 1392 Duration: 0:00:02.407272 Num steps: 199 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 2.238 Epsilon: 0.381\n",
      "Episode: 1393 Duration: 0:00:04.263879 Num steps: 355 Reward: 4.0 Training time per step: 0.009 Avg Reward (Last 100): 2.238 Epsilon: 0.380\n",
      "Episode: 1394 Duration: 0:00:03.745339 Num steps: 313 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 2.267 Epsilon: 0.379\n",
      "Episode: 1395 Duration: 0:00:03.320132 Num steps: 275 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 2.267 Epsilon: 0.379\n",
      "Episode: 1396 Duration: 0:00:04.915220 Num steps: 410 Reward: 4.0 Training time per step: 0.009 Avg Reward (Last 100): 2.257 Epsilon: 0.378\n",
      "Episode: 1397 Duration: 0:00:04.574034 Num steps: 380 Reward: 4.0 Training time per step: 0.009 Avg Reward (Last 100): 2.277 Epsilon: 0.378\n",
      "Episode: 1398 Duration: 0:00:02.876289 Num steps: 239 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 2.257 Epsilon: 0.377\n",
      "Episode: 1399 Duration: 0:00:04.535019 Num steps: 375 Reward: 4.0 Training time per step: 0.009 Avg Reward (Last 100): 2.248 Epsilon: 0.376\n",
      "Episode: 1400 Duration: 0:00:02.818100 Num steps: 233 Reward: 1.0 Training time per step: 0.010 Avg Reward (Last 100): 2.198 Epsilon: 0.376\n",
      "Episode: 1401 Duration: 0:00:03.042843 Num steps: 255 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 2.188 Epsilon: 0.376\n",
      "Episode: 1402 Duration: 0:00:04.680094 Num steps: 390 Reward: 4.0 Training time per step: 0.009 Avg Reward (Last 100): 2.178 Epsilon: 0.375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1403 Duration: 0:00:02.860829 Num steps: 238 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 2.168 Epsilon: 0.374\n",
      "Episode: 1404 Duration: 0:00:04.239456 Num steps: 352 Reward: 4.0 Training time per step: 0.009 Avg Reward (Last 100): 2.198 Epsilon: 0.374\n",
      "Episode: 1405 Duration: 0:00:04.527679 Num steps: 378 Reward: 4.0 Training time per step: 0.009 Avg Reward (Last 100): 2.188 Epsilon: 0.373\n",
      "Episode: 1406 Duration: 0:00:02.606462 Num steps: 216 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 2.178 Epsilon: 0.373\n",
      "Episode: 1407 Duration: 0:00:03.293416 Num steps: 273 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 2.188 Epsilon: 0.372\n",
      "Episode: 1408 Duration: 0:00:03.489371 Num steps: 291 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 2.188 Epsilon: 0.372\n",
      "Episode: 1409 Duration: 0:00:03.860146 Num steps: 322 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 2.188 Epsilon: 0.371\n",
      "Episode: 1410 Duration: 0:00:02.977181 Num steps: 247 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 2.178 Epsilon: 0.371\n",
      "Episode: 1411 Duration: 0:00:02.989750 Num steps: 250 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 2.198 Epsilon: 0.370\n",
      "Copied model parameters to target network. total_t = 350000, period = 10000\n",
      "Episode: 1412 Duration: 0:00:03.376242 Num steps: 257 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 2.208 Epsilon: 0.370\n",
      "Episode: 1413 Duration: 0:00:03.676718 Num steps: 305 Reward: 2.0 Training time per step: 0.010 Avg Reward (Last 100): 2.208 Epsilon: 0.369\n",
      "Episode: 1414 Duration: 0:00:03.560352 Num steps: 295 Reward: 3.0 Training time per step: 0.010 Avg Reward (Last 100): 2.228 Epsilon: 0.369\n",
      "Episode: 1415 Duration: 0:00:04.044354 Num steps: 335 Reward: 2.0 Training time per step: 0.010 Avg Reward (Last 100): 2.248 Epsilon: 0.368\n",
      "Episode: 1416 Duration: 0:00:03.317037 Num steps: 274 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 2.248 Epsilon: 0.368\n",
      "Episode: 1417 Duration: 0:00:06.208189 Num steps: 521 Reward: 6.0 Training time per step: 0.009 Avg Reward (Last 100): 2.287 Epsilon: 0.367\n",
      "Episode: 1418 Duration: 0:00:03.841665 Num steps: 319 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 2.277 Epsilon: 0.366\n",
      "Episode: 1419 Duration: 0:00:04.165485 Num steps: 346 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 2.277 Epsilon: 0.365\n",
      "Episode: 1420 Duration: 0:00:03.600052 Num steps: 298 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 2.297 Epsilon: 0.365\n",
      "Episode: 1421 Duration: 0:00:06.724244 Num steps: 559 Reward: 8.0 Training time per step: 0.009 Avg Reward (Last 100): 2.376 Epsilon: 0.364\n",
      "Episode: 1422 Duration: 0:00:05.219338 Num steps: 433 Reward: 4.0 Training time per step: 0.009 Avg Reward (Last 100): 2.396 Epsilon: 0.363\n",
      "Episode: 1423 Duration: 0:00:04.557671 Num steps: 380 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 2.416 Epsilon: 0.362\n",
      "Episode: 1424 Duration: 0:00:03.409770 Num steps: 285 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 2.416 Epsilon: 0.362\n",
      "Episode: 1425 Duration: 0:00:04.105850 Num steps: 341 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 2.436 Epsilon: 0.361\n",
      "Episode: 1426 Duration: 0:00:03.260185 Num steps: 272 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 2.455 Epsilon: 0.361\n",
      "Episode: 1427 Duration: 0:00:04.691299 Num steps: 392 Reward: 4.0 Training time per step: 0.009 Avg Reward (Last 100): 2.475 Epsilon: 0.360\n",
      "Episode: 1428 Duration: 0:00:05.150120 Num steps: 428 Reward: 5.0 Training time per step: 0.009 Avg Reward (Last 100): 2.505 Epsilon: 0.359\n",
      "Episode: 1429 Duration: 0:00:03.845716 Num steps: 320 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 2.525 Epsilon: 0.359\n",
      "Episode: 1430 Duration: 0:00:05.314659 Num steps: 441 Reward: 5.0 Training time per step: 0.009 Avg Reward (Last 100): 2.574 Epsilon: 0.358\n",
      "Episode: 1431 Duration: 0:00:06.651855 Num steps: 555 Reward: 9.0 Training time per step: 0.009 Avg Reward (Last 100): 2.653 Epsilon: 0.357\n",
      "Episode: 1432 Duration: 0:00:05.488394 Num steps: 455 Reward: 5.0 Training time per step: 0.009 Avg Reward (Last 100): 2.683 Epsilon: 0.356\n",
      "Episode: 1433 Duration: 0:00:06.256365 Num steps: 521 Reward: 6.0 Training time per step: 0.009 Avg Reward (Last 100): 2.733 Epsilon: 0.355\n",
      "Episode: 1434 Duration: 0:00:04.974867 Num steps: 412 Reward: 4.0 Training time per step: 0.009 Avg Reward (Last 100): 2.743 Epsilon: 0.355\n",
      "Episode: 1435 Duration: 0:00:04.607997 Num steps: 381 Reward: 4.0 Training time per step: 0.009 Avg Reward (Last 100): 2.752 Epsilon: 0.354\n",
      "Episode: 1436 Duration: 0:00:03.630837 Num steps: 299 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 2.772 Epsilon: 0.353\n",
      "Episode: 1437 Duration: 0:00:03.037908 Num steps: 254 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 2.762 Epsilon: 0.353\n",
      "Episode: 1438 Duration: 0:00:04.179076 Num steps: 349 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 2.782 Epsilon: 0.352\n",
      "Copied model parameters to target network. total_t = 360000, period = 10000\n",
      "Episode: 1439 Duration: 0:00:03.334127 Num steps: 256 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 2.762 Epsilon: 0.352\n",
      "Episode: 1440 Duration: 0:00:03.220962 Num steps: 265 Reward: 2.0 Training time per step: 0.010 Avg Reward (Last 100): 2.772 Epsilon: 0.351\n",
      "Episode: 1441 Duration: 0:00:04.673417 Num steps: 384 Reward: 4.0 Training time per step: 0.010 Avg Reward (Last 100): 2.772 Epsilon: 0.351\n",
      "Episode: 1442 Duration: 0:00:03.450876 Num steps: 284 Reward: 2.0 Training time per step: 0.010 Avg Reward (Last 100): 2.792 Epsilon: 0.350\n",
      "Episode: 1443 Duration: 0:00:05.315681 Num steps: 441 Reward: 5.0 Training time per step: 0.009 Avg Reward (Last 100): 2.812 Epsilon: 0.349\n",
      "Episode: 1444 Duration: 0:00:05.026125 Num steps: 420 Reward: 5.0 Training time per step: 0.009 Avg Reward (Last 100): 2.812 Epsilon: 0.349\n",
      "Episode: 1445 Duration: 0:00:04.089442 Num steps: 340 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 2.832 Epsilon: 0.348\n",
      "Episode: 1446 Duration: 0:00:06.748408 Num steps: 560 Reward: 7.0 Training time per step: 0.009 Avg Reward (Last 100): 2.861 Epsilon: 0.347\n",
      "Episode: 1447 Duration: 0:00:04.634063 Num steps: 387 Reward: 4.0 Training time per step: 0.009 Avg Reward (Last 100): 2.881 Epsilon: 0.346\n",
      "Episode: 1448 Duration: 0:00:03.841723 Num steps: 318 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 2.891 Epsilon: 0.346\n",
      "Episode: 1449 Duration: 0:00:03.734553 Num steps: 311 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 2.901 Epsilon: 0.345\n",
      "Episode: 1450 Duration: 0:00:04.919361 Num steps: 409 Reward: 5.0 Training time per step: 0.009 Avg Reward (Last 100): 2.950 Epsilon: 0.344\n",
      "Episode: 1451 Duration: 0:00:05.489421 Num steps: 457 Reward: 5.0 Training time per step: 0.009 Avg Reward (Last 100): 2.990 Epsilon: 0.344\n",
      "Episode: 1452 Duration: 0:00:04.652278 Num steps: 385 Reward: 4.0 Training time per step: 0.009 Avg Reward (Last 100): 3.010 Epsilon: 0.343\n",
      "Episode: 1453 Duration: 0:00:05.095719 Num steps: 424 Reward: 4.0 Training time per step: 0.009 Avg Reward (Last 100): 2.990 Epsilon: 0.342\n",
      "Episode: 1454 Duration: 0:00:07.619113 Num steps: 632 Reward: 8.0 Training time per step: 0.009 Avg Reward (Last 100): 3.050 Epsilon: 0.341\n",
      "Episode: 1455 Duration: 0:00:05.433232 Num steps: 452 Reward: 5.0 Training time per step: 0.009 Avg Reward (Last 100): 3.089 Epsilon: 0.340\n",
      "Episode: 1456 Duration: 0:00:03.017296 Num steps: 251 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 3.089 Epsilon: 0.340\n",
      "Episode: 1457 Duration: 0:00:05.435434 Num steps: 452 Reward: 5.0 Training time per step: 0.009 Avg Reward (Last 100): 3.119 Epsilon: 0.339\n",
      "Episode: 1458 Duration: 0:00:07.126887 Num steps: 593 Reward: 8.0 Training time per step: 0.009 Avg Reward (Last 100): 3.198 Epsilon: 0.338\n",
      "Episode: 1459 Duration: 0:00:04.128310 Num steps: 344 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 3.208 Epsilon: 0.337\n",
      "Episode: 1460 Duration: 0:00:03.411513 Num steps: 283 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 3.188 Epsilon: 0.337\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1461 Duration: 0:00:05.701211 Num steps: 476 Reward: 5.0 Training time per step: 0.009 Avg Reward (Last 100): 3.228 Epsilon: 0.336\n",
      "Episode: 1462 Duration: 0:00:03.415074 Num steps: 283 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 3.228 Epsilon: 0.335\n",
      "Episode: 1463 Duration: 0:00:02.988034 Num steps: 248 Reward: 1.0 Training time per step: 0.009 Avg Reward (Last 100): 3.208 Epsilon: 0.335\n",
      "Episode: 1464 Duration: 0:00:03.539639 Num steps: 295 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 3.198 Epsilon: 0.334\n",
      "Copied model parameters to target network. total_t = 370000, period = 10000\n",
      "Episode: 1465 Duration: 0:00:07.078279 Num steps: 564 Reward: 6.0 Training time per step: 0.009 Avg Reward (Last 100): 3.228 Epsilon: 0.333\n",
      "Episode: 1466 Duration: 0:00:04.627002 Num steps: 383 Reward: 4.0 Training time per step: 0.009 Avg Reward (Last 100): 3.238 Epsilon: 0.333\n",
      "Episode: 1467 Duration: 0:00:03.879365 Num steps: 323 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 3.257 Epsilon: 0.332\n",
      "Episode: 1468 Duration: 0:00:05.136216 Num steps: 426 Reward: 4.0 Training time per step: 0.009 Avg Reward (Last 100): 3.267 Epsilon: 0.331\n",
      "Episode: 1469 Duration: 0:00:07.910453 Num steps: 660 Reward: 8.0 Training time per step: 0.009 Avg Reward (Last 100): 3.347 Epsilon: 0.330\n",
      "Episode: 1470 Duration: 0:00:04.742348 Num steps: 393 Reward: 4.0 Training time per step: 0.009 Avg Reward (Last 100): 3.376 Epsilon: 0.329\n",
      "Episode: 1471 Duration: 0:00:06.546015 Num steps: 544 Reward: 6.0 Training time per step: 0.009 Avg Reward (Last 100): 3.436 Epsilon: 0.328\n",
      "Episode: 1472 Duration: 0:00:03.311246 Num steps: 274 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 3.446 Epsilon: 0.328\n",
      "Episode: 1473 Duration: 0:00:03.961612 Num steps: 329 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 3.436 Epsilon: 0.327\n",
      "Episode: 1474 Duration: 0:00:05.026493 Num steps: 418 Reward: 5.0 Training time per step: 0.009 Avg Reward (Last 100): 3.446 Epsilon: 0.327\n",
      "Episode: 1475 Duration: 0:00:05.731807 Num steps: 478 Reward: 5.0 Training time per step: 0.009 Avg Reward (Last 100): 3.475 Epsilon: 0.326\n",
      "Episode: 1476 Duration: 0:00:04.289428 Num steps: 357 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 3.455 Epsilon: 0.325\n",
      "Episode: 1477 Duration: 0:00:08.372027 Num steps: 696 Reward: 10.0 Training time per step: 0.009 Avg Reward (Last 100): 3.535 Epsilon: 0.324\n",
      "Episode: 1478 Duration: 0:00:04.051092 Num steps: 338 Reward: 3.0 Training time per step: 0.009 Avg Reward (Last 100): 3.525 Epsilon: 0.323\n",
      "Episode: 1479 Duration: 0:00:06.050347 Num steps: 504 Reward: 6.0 Training time per step: 0.009 Avg Reward (Last 100): 3.554 Epsilon: 0.322\n",
      "Episode: 1480 Duration: 0:00:04.950685 Num steps: 411 Reward: 5.0 Training time per step: 0.009 Avg Reward (Last 100): 3.604 Epsilon: 0.322\n",
      "Episode: 1481 Duration: 0:00:06.374961 Num steps: 531 Reward: 7.0 Training time per step: 0.009 Avg Reward (Last 100): 3.663 Epsilon: 0.321\n",
      "Episode: 1482 Duration: 0:00:05.747097 Num steps: 479 Reward: 5.0 Training time per step: 0.009 Avg Reward (Last 100): 3.653 Epsilon: 0.320\n",
      "Episode: 1483 Duration: 0:00:07.490948 Num steps: 620 Reward: 8.0 Training time per step: 0.009 Avg Reward (Last 100): 3.683 Epsilon: 0.319\n",
      "Episode: 1484 Duration: 0:00:03.801154 Num steps: 314 Reward: 2.0 Training time per step: 0.009 Avg Reward (Last 100): 3.663 Epsilon: 0.318\n",
      "Episode: 1485 Duration: 0:00:06.872068 Num steps: 573 Reward: 7.0 Training time per step: 0.009 Avg Reward (Last 100): 3.693 Epsilon: 0.317\n",
      "Copied model parameters to target network. total_t = 380000, period = 10000\n",
      "Episode: 1486 Duration: 0:00:06.948731 Num steps: 558 Reward: 7.0 Training time per step: 0.009 Avg Reward (Last 100): 3.743 Epsilon: 0.316\n",
      "Episode: 1487 Duration: 0:00:08.085850 Num steps: 668 Reward: 10.0 Training time per step: 0.009 Avg Reward (Last 100): 3.812 Epsilon: 0.315\n",
      "Episode: 1488 Duration: 0:00:04.806725 Num steps: 396 Reward: 3.0 Training time per step: 0.010 Avg Reward (Last 100): 3.832 Epsilon: 0.314\n",
      "Episode: 1489 Duration: 0:00:09.133017 Num steps: 760 Reward: 9.0 Training time per step: 0.009 Avg Reward (Last 100): 3.891 Epsilon: 0.313\n",
      "Episode: 1490 Duration: 0:00:07.347130 Num steps: 612 Reward: 8.0 Training time per step: 0.009 Avg Reward (Last 100): 3.960 Epsilon: 0.312\n",
      "Episode: 1491 Duration: 0:00:05.076343 Num steps: 421 Reward: 4.0 Training time per step: 0.009 Avg Reward (Last 100): 3.960 Epsilon: 0.311\n",
      "Episode: 1492 Duration: 0:00:06.812689 Num steps: 563 Reward: 11.0 Training time per step: 0.009 Avg Reward (Last 100): 4.040 Epsilon: 0.310\n",
      "Episode: 1493 Duration: 0:00:06.333249 Num steps: 524 Reward: 6.0 Training time per step: 0.009 Avg Reward (Last 100): 4.089 Epsilon: 0.309\n",
      "Episode: 1494 Duration: 0:00:06.675329 Num steps: 551 Reward: 7.0 Training time per step: 0.009 Avg Reward (Last 100): 4.119 Epsilon: 0.308\n",
      "Episode: 1495 Duration: 0:00:05.604328 Num steps: 463 Reward: 5.0 Training time per step: 0.009 Avg Reward (Last 100): 4.139 Epsilon: 0.307\n",
      "Episode: 1496 Duration: 0:00:06.936041 Num steps: 575 Reward: 7.0 Training time per step: 0.009 Avg Reward (Last 100): 4.188 Epsilon: 0.306\n",
      "Episode: 1497 Duration: 0:00:05.683264 Num steps: 472 Reward: 5.0 Training time per step: 0.009 Avg Reward (Last 100): 4.198 Epsilon: 0.305\n",
      "Episode: 1498 Duration: 0:00:08.501678 Num steps: 707 Reward: 9.0 Training time per step: 0.009 Avg Reward (Last 100): 4.248 Epsilon: 0.304\n",
      "Episode: 1499 Duration: 0:00:08.525964 Num steps: 708 Reward: 11.0 Training time per step: 0.009 Avg Reward (Last 100): 4.347 Epsilon: 0.303\n",
      "Episode: 1500 Duration: 0:00:05.373677 Num steps: 447 Reward: 5.0 Training time per step: 0.009 Avg Reward (Last 100): 4.356 Epsilon: 0.302\n",
      "Episode: 1501 Duration: 0:00:07.105020 Num steps: 589 Reward: 7.0 Training time per step: 0.009 Avg Reward (Last 100): 4.416 Epsilon: 0.301\n",
      "Episode: 1502 Duration: 0:00:08.224883 Num steps: 682 Reward: 9.0 Training time per step: 0.009 Avg Reward (Last 100): 4.495 Epsilon: 0.300\n",
      "Episode: 1503 Duration: 0:00:05.689825 Num steps: 471 Reward: 6.0 Training time per step: 0.009 Avg Reward (Last 100): 4.515 Epsilon: 0.299\n",
      "Copied model parameters to target network. total_t = 390000, period = 10000\n",
      "Episode: 1504 Duration: 0:00:05.731386 Num steps: 452 Reward: 5.0 Training time per step: 0.009 Avg Reward (Last 100): 4.554 Epsilon: 0.298\n",
      "Episode: 1505 Duration: 0:00:03.950690 Num steps: 325 Reward: 3.0 Training time per step: 0.010 Avg Reward (Last 100): 4.545 Epsilon: 0.297\n",
      "Episode: 1506 Duration: 0:00:09.434618 Num steps: 778 Reward: 11.0 Training time per step: 0.009 Avg Reward (Last 100): 4.614 Epsilon: 0.296\n",
      "Episode: 1507 Duration: 0:00:06.156406 Num steps: 508 Reward: 7.0 Training time per step: 0.009 Avg Reward (Last 100): 4.673 Epsilon: 0.295\n",
      "Episode: 1508 Duration: 0:00:08.833278 Num steps: 735 Reward: 12.0 Training time per step: 0.009 Avg Reward (Last 100): 4.772 Epsilon: 0.294\n",
      "Episode: 1509 Duration: 0:00:06.140069 Num steps: 507 Reward: 6.0 Training time per step: 0.009 Avg Reward (Last 100): 4.812 Epsilon: 0.293\n",
      "Episode: 1510 Duration: 0:00:07.553732 Num steps: 626 Reward: 8.0 Training time per step: 0.009 Avg Reward (Last 100): 4.861 Epsilon: 0.292\n",
      "Episode: 1511 Duration: 0:00:06.144256 Num steps: 507 Reward: 6.0 Training time per step: 0.009 Avg Reward (Last 100): 4.911 Epsilon: 0.291\n",
      "Episode: 1512 Duration: 0:00:04.308728 Num steps: 356 Reward: 4.0 Training time per step: 0.009 Avg Reward (Last 100): 4.931 Epsilon: 0.290\n",
      "Episode: 1513 Duration: 0:00:09.098723 Num steps: 753 Reward: 10.0 Training time per step: 0.009 Avg Reward (Last 100): 5.010 Epsilon: 0.289\n",
      "Episode: 1514 Duration: 0:00:06.379710 Num steps: 528 Reward: 6.0 Training time per step: 0.009 Avg Reward (Last 100): 5.050 Epsilon: 0.288\n",
      "Episode: 1515 Duration: 0:00:08.518213 Num steps: 703 Reward: 10.0 Training time per step: 0.009 Avg Reward (Last 100): 5.119 Epsilon: 0.286\n",
      "Episode: 1516 Duration: 0:00:06.204688 Num steps: 513 Reward: 6.0 Training time per step: 0.009 Avg Reward (Last 100): 5.158 Epsilon: 0.286\n",
      "Episode: 1517 Duration: 0:00:07.349174 Num steps: 611 Reward: 9.0 Training time per step: 0.009 Avg Reward (Last 100): 5.228 Epsilon: 0.284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1518 Duration: 0:00:09.955875 Num steps: 825 Reward: 14.0 Training time per step: 0.009 Avg Reward (Last 100): 5.307 Epsilon: 0.283\n",
      "Episode: 1519 Duration: 0:00:04.595154 Num steps: 380 Reward: 4.0 Training time per step: 0.009 Avg Reward (Last 100): 5.317 Epsilon: 0.282\n",
      "Episode: 1520 Duration: 0:00:08.087282 Num steps: 671 Reward: 8.0 Training time per step: 0.009 Avg Reward (Last 100): 5.366 Epsilon: 0.281\n",
      "Episode: 1521 Duration: 0:00:04.560122 Num steps: 380 Reward: 4.0 Training time per step: 0.009 Avg Reward (Last 100): 5.386 Epsilon: 0.280\n",
      "Copied model parameters to target network. total_t = 400000, period = 10000\n",
      "Episode: 1522 Duration: 0:00:08.721176 Num steps: 699 Reward: 10.0 Training time per step: 0.009 Avg Reward (Last 100): 5.406 Epsilon: 0.279\n",
      "Episode: 1523 Duration: 0:00:09.745440 Num steps: 804 Reward: 15.0 Training time per step: 0.009 Avg Reward (Last 100): 5.515 Epsilon: 0.278\n",
      "Episode: 1524 Duration: 0:00:09.540498 Num steps: 788 Reward: 15.0 Training time per step: 0.009 Avg Reward (Last 100): 5.634 Epsilon: 0.276\n",
      "Episode: 1525 Duration: 0:00:10.401778 Num steps: 861 Reward: 12.0 Training time per step: 0.009 Avg Reward (Last 100): 5.733 Epsilon: 0.275\n",
      "Episode: 1526 Duration: 0:00:10.564920 Num steps: 874 Reward: 13.0 Training time per step: 0.009 Avg Reward (Last 100): 5.832 Epsilon: 0.273\n",
      "Episode: 1527 Duration: 0:00:07.578118 Num steps: 629 Reward: 10.0 Training time per step: 0.009 Avg Reward (Last 100): 5.911 Epsilon: 0.272\n",
      "Episode: 1528 Duration: 0:00:06.540410 Num steps: 543 Reward: 6.0 Training time per step: 0.009 Avg Reward (Last 100): 5.931 Epsilon: 0.271\n",
      "Episode: 1529 Duration: 0:00:10.291930 Num steps: 849 Reward: 17.0 Training time per step: 0.009 Avg Reward (Last 100): 6.050 Epsilon: 0.270\n",
      "Episode: 1530 Duration: 0:00:07.932769 Num steps: 655 Reward: 9.0 Training time per step: 0.009 Avg Reward (Last 100): 6.109 Epsilon: 0.268\n",
      "Episode: 1531 Duration: 0:00:10.088542 Num steps: 835 Reward: 18.0 Training time per step: 0.009 Avg Reward (Last 100): 6.238 Epsilon: 0.267\n",
      "Episode: 1532 Duration: 0:00:06.664688 Num steps: 549 Reward: 8.0 Training time per step: 0.009 Avg Reward (Last 100): 6.228 Epsilon: 0.266\n",
      "Episode: 1533 Duration: 0:00:05.579520 Num steps: 460 Reward: 5.0 Training time per step: 0.009 Avg Reward (Last 100): 6.228 Epsilon: 0.265\n",
      "Episode: 1534 Duration: 0:00:09.848993 Num steps: 815 Reward: 11.0 Training time per step: 0.009 Avg Reward (Last 100): 6.277 Epsilon: 0.264\n",
      "Episode: 1535 Duration: 0:00:04.815657 Num steps: 400 Reward: 4.0 Training time per step: 0.009 Avg Reward (Last 100): 6.277 Epsilon: 0.263\n",
      "Copied model parameters to target network. total_t = 410000, period = 10000\n",
      "Episode: 1536 Duration: 0:00:07.029085 Num steps: 556 Reward: 8.0 Training time per step: 0.009 Avg Reward (Last 100): 6.317 Epsilon: 0.262\n",
      "Episode: 1537 Duration: 0:00:08.893542 Num steps: 730 Reward: 10.0 Training time per step: 0.009 Avg Reward (Last 100): 6.386 Epsilon: 0.261\n",
      "Episode: 1538 Duration: 0:00:08.462639 Num steps: 697 Reward: 11.0 Training time per step: 0.009 Avg Reward (Last 100): 6.485 Epsilon: 0.259\n",
      "Episode: 1539 Duration: 0:00:05.942328 Num steps: 491 Reward: 5.0 Training time per step: 0.009 Avg Reward (Last 100): 6.505 Epsilon: 0.258\n",
      "Episode: 1540 Duration: 0:00:09.500162 Num steps: 787 Reward: 16.0 Training time per step: 0.009 Avg Reward (Last 100): 6.644 Epsilon: 0.257\n",
      "Episode: 1541 Duration: 0:00:11.797700 Num steps: 977 Reward: 19.0 Training time per step: 0.009 Avg Reward (Last 100): 6.812 Epsilon: 0.255\n",
      "Episode: 1542 Duration: 0:00:05.608635 Num steps: 463 Reward: 5.0 Training time per step: 0.009 Avg Reward (Last 100): 6.822 Epsilon: 0.254\n",
      "Episode: 1543 Duration: 0:00:07.586871 Num steps: 624 Reward: 10.0 Training time per step: 0.009 Avg Reward (Last 100): 6.901 Epsilon: 0.253\n",
      "Episode: 1544 Duration: 0:00:06.060891 Num steps: 502 Reward: 7.0 Training time per step: 0.009 Avg Reward (Last 100): 6.921 Epsilon: 0.252\n",
      "Episode: 1545 Duration: 0:00:09.998004 Num steps: 826 Reward: 13.0 Training time per step: 0.009 Avg Reward (Last 100): 7.000 Epsilon: 0.251\n",
      "Episode: 1546 Duration: 0:00:08.381995 Num steps: 697 Reward: 10.0 Training time per step: 0.009 Avg Reward (Last 100): 7.069 Epsilon: 0.250\n",
      "Episode: 1547 Duration: 0:00:09.039276 Num steps: 746 Reward: 12.0 Training time per step: 0.009 Avg Reward (Last 100): 7.119 Epsilon: 0.248\n",
      "Episode: 1548 Duration: 0:00:08.820305 Num steps: 727 Reward: 11.0 Training time per step: 0.009 Avg Reward (Last 100): 7.188 Epsilon: 0.247\n",
      "Episode: 1549 Duration: 0:00:09.862342 Num steps: 816 Reward: 17.0 Training time per step: 0.009 Avg Reward (Last 100): 7.327 Epsilon: 0.245\n",
      "Episode: 1550 Duration: 0:00:09.382546 Num steps: 775 Reward: 11.0 Training time per step: 0.009 Avg Reward (Last 100): 7.406 Epsilon: 0.244\n",
      "Copied model parameters to target network. total_t = 420000, period = 10000\n",
      "Episode: 1551 Duration: 0:00:09.727011 Num steps: 779 Reward: 11.0 Training time per step: 0.009 Avg Reward (Last 100): 7.465 Epsilon: 0.243\n",
      "Episode: 1552 Duration: 0:00:08.529986 Num steps: 704 Reward: 9.0 Training time per step: 0.009 Avg Reward (Last 100): 7.505 Epsilon: 0.241\n",
      "Episode: 1553 Duration: 0:00:05.729160 Num steps: 473 Reward: 4.0 Training time per step: 0.009 Avg Reward (Last 100): 7.505 Epsilon: 0.241\n",
      "Episode: 1554 Duration: 0:00:10.985142 Num steps: 910 Reward: 20.0 Training time per step: 0.009 Avg Reward (Last 100): 7.663 Epsilon: 0.239\n",
      "Episode: 1555 Duration: 0:00:11.949032 Num steps: 991 Reward: 23.0 Training time per step: 0.009 Avg Reward (Last 100): 7.812 Epsilon: 0.237\n",
      "Episode: 1556 Duration: 0:00:07.361980 Num steps: 607 Reward: 8.0 Training time per step: 0.009 Avg Reward (Last 100): 7.842 Epsilon: 0.236\n",
      "Episode: 1557 Duration: 0:00:10.100723 Num steps: 835 Reward: 21.0 Training time per step: 0.009 Avg Reward (Last 100): 8.030 Epsilon: 0.235\n",
      "Episode: 1558 Duration: 0:00:09.273469 Num steps: 766 Reward: 11.0 Training time per step: 0.009 Avg Reward (Last 100): 8.089 Epsilon: 0.233\n",
      "Episode: 1559 Duration: 0:00:06.135504 Num steps: 505 Reward: 5.0 Training time per step: 0.009 Avg Reward (Last 100): 8.059 Epsilon: 0.232\n",
      "Episode: 1560 Duration: 0:00:11.014890 Num steps: 912 Reward: 12.0 Training time per step: 0.009 Avg Reward (Last 100): 8.149 Epsilon: 0.231\n",
      "Episode: 1561 Duration: 0:00:08.594924 Num steps: 706 Reward: 11.0 Training time per step: 0.009 Avg Reward (Last 100): 8.238 Epsilon: 0.229\n",
      "Episode: 1562 Duration: 0:00:10.006469 Num steps: 825 Reward: 16.0 Training time per step: 0.009 Avg Reward (Last 100): 8.347 Epsilon: 0.228\n",
      "Episode: 1563 Duration: 0:00:04.984747 Num steps: 412 Reward: 4.0 Training time per step: 0.009 Avg Reward (Last 100): 8.366 Epsilon: 0.227\n",
      "Copied model parameters to target network. total_t = 430000, period = 10000\n",
      "Episode: 1564 Duration: 0:00:09.296259 Num steps: 743 Reward: 11.0 Training time per step: 0.009 Avg Reward (Last 100): 8.465 Epsilon: 0.226\n",
      "Episode: 1565 Duration: 0:00:10.773359 Num steps: 887 Reward: 14.0 Training time per step: 0.009 Avg Reward (Last 100): 8.574 Epsilon: 0.224\n",
      "Episode: 1566 Duration: 0:00:10.641999 Num steps: 879 Reward: 14.0 Training time per step: 0.009 Avg Reward (Last 100): 8.653 Epsilon: 0.223\n",
      "Episode: 1567 Duration: 0:00:09.876378 Num steps: 813 Reward: 13.0 Training time per step: 0.009 Avg Reward (Last 100): 8.743 Epsilon: 0.221\n",
      "Episode: 1568 Duration: 0:00:09.759133 Num steps: 808 Reward: 12.0 Training time per step: 0.009 Avg Reward (Last 100): 8.832 Epsilon: 0.220\n",
      "Episode: 1569 Duration: 0:00:08.700910 Num steps: 716 Reward: 11.0 Training time per step: 0.009 Avg Reward (Last 100): 8.901 Epsilon: 0.218\n",
      "Episode: 1570 Duration: 0:00:08.863773 Num steps: 730 Reward: 11.0 Training time per step: 0.009 Avg Reward (Last 100): 8.931 Epsilon: 0.217\n",
      "Episode: 1571 Duration: 0:00:12.193203 Num steps: 1009 Reward: 15.0 Training time per step: 0.009 Avg Reward (Last 100): 9.040 Epsilon: 0.215\n",
      "Episode: 1572 Duration: 0:00:08.074725 Num steps: 666 Reward: 9.0 Training time per step: 0.009 Avg Reward (Last 100): 9.069 Epsilon: 0.214\n",
      "Episode: 1573 Duration: 0:00:06.428300 Num steps: 530 Reward: 7.0 Training time per step: 0.009 Avg Reward (Last 100): 9.119 Epsilon: 0.213\n",
      "Episode: 1574 Duration: 0:00:06.324190 Num steps: 521 Reward: 6.0 Training time per step: 0.009 Avg Reward (Last 100): 9.149 Epsilon: 0.212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1575 Duration: 0:00:11.036787 Num steps: 910 Reward: 18.0 Training time per step: 0.009 Avg Reward (Last 100): 9.277 Epsilon: 0.211\n",
      "Episode: 1576 Duration: 0:00:05.611275 Num steps: 465 Reward: 8.0 Training time per step: 0.009 Avg Reward (Last 100): 9.307 Epsilon: 0.210\n",
      "Episode: 1577 Duration: 0:00:07.420247 Num steps: 610 Reward: 8.0 Training time per step: 0.009 Avg Reward (Last 100): 9.356 Epsilon: 0.209\n",
      "Copied model parameters to target network. total_t = 440000, period = 10000\n",
      "Episode: 1578 Duration: 0:00:10.694501 Num steps: 855 Reward: 16.0 Training time per step: 0.009 Avg Reward (Last 100): 9.416 Epsilon: 0.207\n",
      "Episode: 1579 Duration: 0:00:10.310938 Num steps: 846 Reward: 12.0 Training time per step: 0.009 Avg Reward (Last 100): 9.505 Epsilon: 0.206\n",
      "Episode: 1580 Duration: 0:00:08.830168 Num steps: 727 Reward: 10.0 Training time per step: 0.009 Avg Reward (Last 100): 9.545 Epsilon: 0.204\n",
      "Episode: 1581 Duration: 0:00:07.119698 Num steps: 585 Reward: 9.0 Training time per step: 0.009 Avg Reward (Last 100): 9.584 Epsilon: 0.203\n",
      "Episode: 1582 Duration: 0:00:11.019224 Num steps: 908 Reward: 13.0 Training time per step: 0.009 Avg Reward (Last 100): 9.644 Epsilon: 0.202\n",
      "Episode: 1583 Duration: 0:00:08.765285 Num steps: 722 Reward: 11.0 Training time per step: 0.009 Avg Reward (Last 100): 9.703 Epsilon: 0.200\n",
      "Episode: 1584 Duration: 0:00:11.603032 Num steps: 960 Reward: 16.0 Training time per step: 0.009 Avg Reward (Last 100): 9.782 Epsilon: 0.199\n",
      "Episode: 1585 Duration: 0:00:06.614764 Num steps: 544 Reward: 9.0 Training time per step: 0.009 Avg Reward (Last 100): 9.851 Epsilon: 0.198\n",
      "Episode: 1586 Duration: 0:00:10.165167 Num steps: 838 Reward: 13.0 Training time per step: 0.009 Avg Reward (Last 100): 9.911 Epsilon: 0.196\n",
      "Episode: 1587 Duration: 0:00:08.847942 Num steps: 728 Reward: 11.0 Training time per step: 0.009 Avg Reward (Last 100): 9.950 Epsilon: 0.195\n",
      "Episode: 1588 Duration: 0:00:13.482833 Num steps: 1107 Reward: 24.0 Training time per step: 0.009 Avg Reward (Last 100): 10.089 Epsilon: 0.193\n",
      "Episode: 1589 Duration: 0:00:08.173229 Num steps: 673 Reward: 10.0 Training time per step: 0.009 Avg Reward (Last 100): 10.158 Epsilon: 0.192\n",
      "Copied model parameters to target network. total_t = 450000, period = 10000\n",
      "Episode: 1590 Duration: 0:00:11.201935 Num steps: 892 Reward: 18.0 Training time per step: 0.009 Avg Reward (Last 100): 10.248 Epsilon: 0.190\n",
      "Episode: 1591 Duration: 0:00:08.713377 Num steps: 689 Reward: 10.0 Training time per step: 0.009 Avg Reward (Last 100): 10.267 Epsilon: 0.189\n",
      "Episode: 1592 Duration: 0:00:08.839755 Num steps: 698 Reward: 9.0 Training time per step: 0.010 Avg Reward (Last 100): 10.317 Epsilon: 0.187\n",
      "Episode: 1593 Duration: 0:00:10.599535 Num steps: 836 Reward: 13.0 Training time per step: 0.010 Avg Reward (Last 100): 10.337 Epsilon: 0.186\n",
      "Episode: 1594 Duration: 0:00:09.048431 Num steps: 710 Reward: 14.0 Training time per step: 0.010 Avg Reward (Last 100): 10.416 Epsilon: 0.185\n",
      "Episode: 1595 Duration: 0:00:11.871105 Num steps: 933 Reward: 25.0 Training time per step: 0.010 Avg Reward (Last 100): 10.594 Epsilon: 0.183\n",
      "Episode: 1596 Duration: 0:00:08.476973 Num steps: 666 Reward: 9.0 Training time per step: 0.010 Avg Reward (Last 100): 10.634 Epsilon: 0.182\n",
      "Episode: 1597 Duration: 0:00:08.610690 Num steps: 677 Reward: 10.0 Training time per step: 0.010 Avg Reward (Last 100): 10.663 Epsilon: 0.181\n",
      "Episode: 1598 Duration: 0:00:07.140148 Num steps: 558 Reward: 8.0 Training time per step: 0.010 Avg Reward (Last 100): 10.693 Epsilon: 0.180\n",
      "Episode: 1599 Duration: 0:00:12.502150 Num steps: 984 Reward: 16.0 Training time per step: 0.010 Avg Reward (Last 100): 10.762 Epsilon: 0.178\n",
      "Episode: 1600 Duration: 0:00:14.030381 Num steps: 1103 Reward: 22.0 Training time per step: 0.010 Avg Reward (Last 100): 10.871 Epsilon: 0.176\n",
      "Episode: 1601 Duration: 0:00:08.957360 Num steps: 704 Reward: 14.0 Training time per step: 0.010 Avg Reward (Last 100): 10.960 Epsilon: 0.175\n",
      "Episode: 1602 Duration: 0:00:09.329467 Num steps: 732 Reward: 11.0 Training time per step: 0.010 Avg Reward (Last 100): 11.000 Epsilon: 0.173\n",
      "Copied model parameters to target network. total_t = 460000, period = 10000\n",
      "Episode: 1603 Duration: 0:00:10.686054 Num steps: 816 Reward: 12.0 Training time per step: 0.010 Avg Reward (Last 100): 11.030 Epsilon: 0.172\n",
      "Episode: 1604 Duration: 0:00:14.173101 Num steps: 1110 Reward: 26.0 Training time per step: 0.010 Avg Reward (Last 100): 11.228 Epsilon: 0.170\n",
      "Episode: 1605 Duration: 0:00:08.485158 Num steps: 664 Reward: 14.0 Training time per step: 0.010 Avg Reward (Last 100): 11.317 Epsilon: 0.169\n",
      "Episode: 1606 Duration: 0:00:10.316050 Num steps: 807 Reward: 20.0 Training time per step: 0.010 Avg Reward (Last 100): 11.485 Epsilon: 0.167\n",
      "Episode: 1607 Duration: 0:00:08.878590 Num steps: 692 Reward: 14.0 Training time per step: 0.010 Avg Reward (Last 100): 11.515 Epsilon: 0.166\n",
      "Episode: 1608 Duration: 0:00:10.925947 Num steps: 854 Reward: 16.0 Training time per step: 0.010 Avg Reward (Last 100): 11.604 Epsilon: 0.164\n",
      "Episode: 1609 Duration: 0:00:06.535460 Num steps: 511 Reward: 7.0 Training time per step: 0.010 Avg Reward (Last 100): 11.554 Epsilon: 0.163\n",
      "Episode: 1610 Duration: 0:00:13.440971 Num steps: 1050 Reward: 20.0 Training time per step: 0.010 Avg Reward (Last 100): 11.693 Epsilon: 0.161\n",
      "Episode: 1611 Duration: 0:00:10.807469 Num steps: 844 Reward: 18.0 Training time per step: 0.010 Avg Reward (Last 100): 11.792 Epsilon: 0.160\n",
      "Episode: 1612 Duration: 0:00:12.185475 Num steps: 951 Reward: 15.0 Training time per step: 0.010 Avg Reward (Last 100): 11.881 Epsilon: 0.158\n",
      "Episode: 1613 Duration: 0:00:11.052495 Num steps: 863 Reward: 21.0 Training time per step: 0.010 Avg Reward (Last 100): 12.050 Epsilon: 0.157\n",
      "Episode: 1614 Duration: 0:00:15.367311 Num steps: 1196 Reward: 28.0 Training time per step: 0.010 Avg Reward (Last 100): 12.228 Epsilon: 0.155\n",
      "Copied model parameters to target network. total_t = 470000, period = 10000\n",
      "Episode: 1615 Duration: 0:00:07.338117 Num steps: 547 Reward: 11.0 Training time per step: 0.010 Avg Reward (Last 100): 12.277 Epsilon: 0.154\n",
      "Episode: 1616 Duration: 0:00:10.149491 Num steps: 791 Reward: 16.0 Training time per step: 0.010 Avg Reward (Last 100): 12.337 Epsilon: 0.152\n",
      "Episode: 1617 Duration: 0:00:09.403754 Num steps: 735 Reward: 11.0 Training time per step: 0.010 Avg Reward (Last 100): 12.386 Epsilon: 0.151\n",
      "Episode: 1618 Duration: 0:00:12.359948 Num steps: 964 Reward: 17.0 Training time per step: 0.010 Avg Reward (Last 100): 12.465 Epsilon: 0.149\n",
      "Episode: 1619 Duration: 0:00:07.507115 Num steps: 586 Reward: 9.0 Training time per step: 0.010 Avg Reward (Last 100): 12.416 Epsilon: 0.148\n",
      "Episode: 1620 Duration: 0:00:12.072244 Num steps: 942 Reward: 15.0 Training time per step: 0.010 Avg Reward (Last 100): 12.525 Epsilon: 0.146\n",
      "Episode: 1621 Duration: 0:00:05.290093 Num steps: 413 Reward: 5.0 Training time per step: 0.010 Avg Reward (Last 100): 12.495 Epsilon: 0.146\n",
      "Episode: 1622 Duration: 0:00:10.816704 Num steps: 844 Reward: 21.0 Training time per step: 0.010 Avg Reward (Last 100): 12.663 Epsilon: 0.144\n",
      "Episode: 1623 Duration: 0:00:17.158695 Num steps: 1335 Reward: 25.0 Training time per step: 0.010 Avg Reward (Last 100): 12.812 Epsilon: 0.142\n",
      "Episode: 1624 Duration: 0:00:11.629649 Num steps: 909 Reward: 23.0 Training time per step: 0.010 Avg Reward (Last 100): 12.891 Epsilon: 0.140\n",
      "Episode: 1625 Duration: 0:00:11.268404 Num steps: 878 Reward: 13.0 Training time per step: 0.010 Avg Reward (Last 100): 12.871 Epsilon: 0.138\n",
      "Episode: 1626 Duration: 0:00:12.116996 Num steps: 945 Reward: 15.0 Training time per step: 0.010 Avg Reward (Last 100): 12.901 Epsilon: 0.137\n",
      "Copied model parameters to target network. total_t = 480000, period = 10000\n",
      "Episode: 1627 Duration: 0:00:09.657032 Num steps: 729 Reward: 18.0 Training time per step: 0.010 Avg Reward (Last 100): 12.950 Epsilon: 0.135\n",
      "Episode: 1628 Duration: 0:00:11.178160 Num steps: 868 Reward: 19.0 Training time per step: 0.010 Avg Reward (Last 100): 13.040 Epsilon: 0.134\n",
      "Episode: 1629 Duration: 0:00:10.844940 Num steps: 847 Reward: 20.0 Training time per step: 0.010 Avg Reward (Last 100): 13.178 Epsilon: 0.132\n",
      "Episode: 1630 Duration: 0:00:06.013174 Num steps: 469 Reward: 7.0 Training time per step: 0.010 Avg Reward (Last 100): 13.079 Epsilon: 0.132\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1631 Duration: 0:00:12.520629 Num steps: 975 Reward: 15.0 Training time per step: 0.010 Avg Reward (Last 100): 13.139 Epsilon: 0.130\n",
      "Episode: 1632 Duration: 0:00:11.241743 Num steps: 879 Reward: 13.0 Training time per step: 0.010 Avg Reward (Last 100): 13.089 Epsilon: 0.128\n",
      "Episode: 1633 Duration: 0:00:14.555755 Num steps: 1134 Reward: 25.0 Training time per step: 0.010 Avg Reward (Last 100): 13.257 Epsilon: 0.126\n",
      "Episode: 1634 Duration: 0:00:09.860064 Num steps: 767 Reward: 12.0 Training time per step: 0.010 Avg Reward (Last 100): 13.327 Epsilon: 0.125\n",
      "Episode: 1635 Duration: 0:00:13.533554 Num steps: 1051 Reward: 25.0 Training time per step: 0.010 Avg Reward (Last 100): 13.465 Epsilon: 0.123\n",
      "Episode: 1636 Duration: 0:00:11.879553 Num steps: 927 Reward: 16.0 Training time per step: 0.010 Avg Reward (Last 100): 13.584 Epsilon: 0.121\n",
      "Episode: 1637 Duration: 0:00:09.482582 Num steps: 739 Reward: 12.0 Training time per step: 0.010 Avg Reward (Last 100): 13.624 Epsilon: 0.120\n",
      "Episode: 1638 Duration: 0:00:08.865241 Num steps: 690 Reward: 11.0 Training time per step: 0.010 Avg Reward (Last 100): 13.634 Epsilon: 0.119\n",
      "Copied model parameters to target network. total_t = 490000, period = 10000\n",
      "Episode: 1639 Duration: 0:00:14.722681 Num steps: 1121 Reward: 30.0 Training time per step: 0.010 Avg Reward (Last 100): 13.822 Epsilon: 0.117\n",
      "Episode: 1640 Duration: 0:00:10.024450 Num steps: 782 Reward: 14.0 Training time per step: 0.010 Avg Reward (Last 100): 13.911 Epsilon: 0.115\n",
      "Episode: 1641 Duration: 0:00:12.553548 Num steps: 981 Reward: 21.0 Training time per step: 0.010 Avg Reward (Last 100): 13.960 Epsilon: 0.113\n",
      "Episode: 1642 Duration: 0:00:12.108361 Num steps: 941 Reward: 15.0 Training time per step: 0.010 Avg Reward (Last 100): 13.921 Epsilon: 0.112\n",
      "Episode: 1643 Duration: 0:00:09.559098 Num steps: 742 Reward: 12.0 Training time per step: 0.010 Avg Reward (Last 100): 13.990 Epsilon: 0.110\n",
      "Episode: 1644 Duration: 0:00:08.324945 Num steps: 646 Reward: 11.0 Training time per step: 0.010 Avg Reward (Last 100): 14.000 Epsilon: 0.109\n",
      "Episode: 1645 Duration: 0:00:12.493408 Num steps: 972 Reward: 20.0 Training time per step: 0.010 Avg Reward (Last 100): 14.129 Epsilon: 0.107\n",
      "Episode: 1646 Duration: 0:00:10.441460 Num steps: 812 Reward: 13.0 Training time per step: 0.010 Avg Reward (Last 100): 14.129 Epsilon: 0.106\n",
      "Episode: 1647 Duration: 0:00:11.118531 Num steps: 865 Reward: 14.0 Training time per step: 0.010 Avg Reward (Last 100): 14.168 Epsilon: 0.104\n",
      "Episode: 1648 Duration: 0:00:14.373406 Num steps: 1114 Reward: 19.0 Training time per step: 0.010 Avg Reward (Last 100): 14.238 Epsilon: 0.102\n",
      "Episode: 1649 Duration: 0:00:10.259780 Num steps: 797 Reward: 12.0 Training time per step: 0.010 Avg Reward (Last 100): 14.248 Epsilon: 0.101\n",
      "Copied model parameters to target network. total_t = 500000, period = 10000\n",
      "Episode: 1650 Duration: 0:00:10.483209 Num steps: 786 Reward: 14.0 Training time per step: 0.010 Avg Reward (Last 100): 14.218 Epsilon: 0.100\n",
      "Episode: 1651 Duration: 0:00:12.799685 Num steps: 995 Reward: 23.0 Training time per step: 0.010 Avg Reward (Last 100): 14.337 Epsilon: 0.100\n",
      "Episode: 1652 Duration: 0:00:11.873769 Num steps: 925 Reward: 15.0 Training time per step: 0.010 Avg Reward (Last 100): 14.376 Epsilon: 0.100\n",
      "Episode: 1653 Duration: 0:00:11.796851 Num steps: 917 Reward: 19.0 Training time per step: 0.010 Avg Reward (Last 100): 14.475 Epsilon: 0.100\n",
      "Episode: 1654 Duration: 0:00:12.328667 Num steps: 960 Reward: 17.0 Training time per step: 0.010 Avg Reward (Last 100): 14.604 Epsilon: 0.100\n",
      "Episode: 1655 Duration: 0:00:12.426978 Num steps: 967 Reward: 20.0 Training time per step: 0.010 Avg Reward (Last 100): 14.604 Epsilon: 0.100\n",
      "Episode: 1656 Duration: 0:00:11.603746 Num steps: 906 Reward: 23.0 Training time per step: 0.010 Avg Reward (Last 100): 14.604 Epsilon: 0.100\n",
      "Episode: 1657 Duration: 0:00:13.003160 Num steps: 1013 Reward: 22.0 Training time per step: 0.010 Avg Reward (Last 100): 14.743 Epsilon: 0.100\n",
      "Episode: 1658 Duration: 0:00:11.129483 Num steps: 867 Reward: 21.0 Training time per step: 0.010 Avg Reward (Last 100): 14.743 Epsilon: 0.100\n",
      "Episode: 1659 Duration: 0:00:14.759782 Num steps: 1150 Reward: 25.0 Training time per step: 0.010 Avg Reward (Last 100): 14.881 Epsilon: 0.100\n",
      "Episode: 1660 Duration: 0:00:13.078173 Num steps: 1019 Reward: 26.0 Training time per step: 0.010 Avg Reward (Last 100): 15.089 Epsilon: 0.100\n",
      "Copied model parameters to target network. total_t = 510000, period = 10000\n",
      "Episode: 1661 Duration: 0:00:09.470230 Num steps: 715 Reward: 11.0 Training time per step: 0.010 Avg Reward (Last 100): 15.079 Epsilon: 0.100\n",
      "Episode: 1662 Duration: 0:00:10.056721 Num steps: 785 Reward: 12.0 Training time per step: 0.010 Avg Reward (Last 100): 15.089 Epsilon: 0.100\n",
      "Episode: 1663 Duration: 0:00:17.002081 Num steps: 1319 Reward: 36.0 Training time per step: 0.010 Avg Reward (Last 100): 15.287 Epsilon: 0.100\n",
      "Episode: 1664 Duration: 0:00:15.461136 Num steps: 1202 Reward: 24.0 Training time per step: 0.010 Avg Reward (Last 100): 15.485 Epsilon: 0.100\n",
      "Episode: 1665 Duration: 0:00:15.698077 Num steps: 1223 Reward: 28.0 Training time per step: 0.010 Avg Reward (Last 100): 15.653 Epsilon: 0.100\n",
      "Episode: 1666 Duration: 0:00:12.335013 Num steps: 958 Reward: 23.0 Training time per step: 0.010 Avg Reward (Last 100): 15.743 Epsilon: 0.100\n",
      "Episode: 1667 Duration: 0:00:10.743177 Num steps: 835 Reward: 18.0 Training time per step: 0.010 Avg Reward (Last 100): 15.782 Epsilon: 0.100\n",
      "Episode: 1668 Duration: 0:00:13.521661 Num steps: 1050 Reward: 17.0 Training time per step: 0.010 Avg Reward (Last 100): 15.822 Epsilon: 0.100\n",
      "Episode: 1669 Duration: 0:00:10.833342 Num steps: 846 Reward: 22.0 Training time per step: 0.010 Avg Reward (Last 100): 15.921 Epsilon: 0.100\n",
      "Episode: 1670 Duration: 0:00:11.553038 Num steps: 904 Reward: 19.0 Training time per step: 0.010 Avg Reward (Last 100): 16.000 Epsilon: 0.100\n",
      "Copied model parameters to target network. total_t = 520000, period = 10000\n",
      "Episode: 1671 Duration: 0:00:11.400142 Num steps: 863 Reward: 13.0 Training time per step: 0.010 Avg Reward (Last 100): 16.020 Epsilon: 0.100\n",
      "Episode: 1672 Duration: 0:00:11.720861 Num steps: 915 Reward: 16.0 Training time per step: 0.010 Avg Reward (Last 100): 16.030 Epsilon: 0.100\n",
      "Episode: 1673 Duration: 0:00:09.786512 Num steps: 762 Reward: 12.0 Training time per step: 0.010 Avg Reward (Last 100): 16.059 Epsilon: 0.100\n",
      "Episode: 1674 Duration: 0:00:15.813819 Num steps: 1229 Reward: 54.0 Training time per step: 0.010 Avg Reward (Last 100): 16.525 Epsilon: 0.100\n",
      "Episode: 1675 Duration: 0:00:08.730002 Num steps: 682 Reward: 10.0 Training time per step: 0.010 Avg Reward (Last 100): 16.564 Epsilon: 0.100\n",
      "Episode: 1676 Duration: 0:00:12.259268 Num steps: 957 Reward: 24.0 Training time per step: 0.010 Avg Reward (Last 100): 16.624 Epsilon: 0.100\n",
      "Episode: 1677 Duration: 0:00:06.092685 Num steps: 475 Reward: 6.0 Training time per step: 0.010 Avg Reward (Last 100): 16.604 Epsilon: 0.100\n",
      "Episode: 1678 Duration: 0:00:15.316473 Num steps: 1193 Reward: 25.0 Training time per step: 0.010 Avg Reward (Last 100): 16.772 Epsilon: 0.100\n",
      "Episode: 1679 Duration: 0:00:13.129176 Num steps: 1024 Reward: 21.0 Training time per step: 0.010 Avg Reward (Last 100): 16.822 Epsilon: 0.100\n",
      "Episode: 1680 Duration: 0:00:11.640060 Num steps: 912 Reward: 18.0 Training time per step: 0.010 Avg Reward (Last 100): 16.881 Epsilon: 0.100\n",
      "Episode: 1681 Duration: 0:00:09.885415 Num steps: 771 Reward: 12.0 Training time per step: 0.010 Avg Reward (Last 100): 16.901 Epsilon: 0.100\n",
      "Copied model parameters to target network. total_t = 530000, period = 10000\n",
      "Episode: 1682 Duration: 0:00:17.854996 Num steps: 1368 Reward: 29.0 Training time per step: 0.010 Avg Reward (Last 100): 17.099 Epsilon: 0.100\n",
      "Episode: 1683 Duration: 0:00:10.431106 Num steps: 814 Reward: 17.0 Training time per step: 0.010 Avg Reward (Last 100): 17.139 Epsilon: 0.100\n",
      "Episode: 1684 Duration: 0:00:07.858204 Num steps: 612 Reward: 10.0 Training time per step: 0.010 Avg Reward (Last 100): 17.129 Epsilon: 0.100\n",
      "Episode: 1685 Duration: 0:00:10.646096 Num steps: 829 Reward: 12.0 Training time per step: 0.010 Avg Reward (Last 100): 17.089 Epsilon: 0.100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1686 Duration: 0:00:11.678905 Num steps: 908 Reward: 16.0 Training time per step: 0.010 Avg Reward (Last 100): 17.158 Epsilon: 0.100\n",
      "Episode: 1687 Duration: 0:00:07.387404 Num steps: 573 Reward: 19.0 Training time per step: 0.010 Avg Reward (Last 100): 17.218 Epsilon: 0.100\n",
      "Episode: 1688 Duration: 0:00:08.747535 Num steps: 680 Reward: 13.0 Training time per step: 0.010 Avg Reward (Last 100): 17.238 Epsilon: 0.100\n",
      "Episode: 1689 Duration: 0:00:11.716698 Num steps: 908 Reward: 22.0 Training time per step: 0.010 Avg Reward (Last 100): 17.218 Epsilon: 0.100\n",
      "Episode: 1690 Duration: 0:00:13.655273 Num steps: 1062 Reward: 26.0 Training time per step: 0.010 Avg Reward (Last 100): 17.376 Epsilon: 0.100\n",
      "Episode: 1691 Duration: 0:00:09.022153 Num steps: 698 Reward: 12.0 Training time per step: 0.010 Avg Reward (Last 100): 17.317 Epsilon: 0.100\n",
      "Episode: 1692 Duration: 0:00:12.976838 Num steps: 1011 Reward: 18.0 Training time per step: 0.010 Avg Reward (Last 100): 17.396 Epsilon: 0.100\n",
      "Copied model parameters to target network. total_t = 540000, period = 10000\n",
      "Episode: 1693 Duration: 0:00:13.545468 Num steps: 1022 Reward: 24.0 Training time per step: 0.010 Avg Reward (Last 100): 17.545 Epsilon: 0.100\n",
      "Episode: 1694 Duration: 0:00:10.744561 Num steps: 835 Reward: 20.0 Training time per step: 0.010 Avg Reward (Last 100): 17.614 Epsilon: 0.100\n",
      "Episode: 1695 Duration: 0:00:13.589038 Num steps: 1054 Reward: 20.0 Training time per step: 0.010 Avg Reward (Last 100): 17.673 Epsilon: 0.100\n",
      "Episode: 1696 Duration: 0:00:13.589373 Num steps: 1061 Reward: 21.0 Training time per step: 0.010 Avg Reward (Last 100): 17.634 Epsilon: 0.100\n",
      "Episode: 1697 Duration: 0:00:12.784426 Num steps: 995 Reward: 20.0 Training time per step: 0.010 Avg Reward (Last 100): 17.743 Epsilon: 0.100\n",
      "Episode: 1698 Duration: 0:00:11.682781 Num steps: 909 Reward: 17.0 Training time per step: 0.010 Avg Reward (Last 100): 17.812 Epsilon: 0.100\n",
      "Episode: 1699 Duration: 0:00:10.131935 Num steps: 787 Reward: 16.0 Training time per step: 0.010 Avg Reward (Last 100): 17.891 Epsilon: 0.100\n",
      "Episode: 1700 Duration: 0:00:08.704600 Num steps: 678 Reward: 11.0 Training time per step: 0.010 Avg Reward (Last 100): 17.842 Epsilon: 0.100\n",
      "Episode: 1701 Duration: 0:00:08.244304 Num steps: 642 Reward: 10.0 Training time per step: 0.010 Avg Reward (Last 100): 17.723 Epsilon: 0.100\n",
      "Episode: 1702 Duration: 0:00:10.050411 Num steps: 777 Reward: 13.0 Training time per step: 0.010 Avg Reward (Last 100): 17.713 Epsilon: 0.100\n",
      "Episode: 1703 Duration: 0:00:13.307909 Num steps: 1037 Reward: 25.0 Training time per step: 0.010 Avg Reward (Last 100): 17.851 Epsilon: 0.100\n",
      "Episode: 1704 Duration: 0:00:07.803177 Num steps: 607 Reward: 10.0 Training time per step: 0.010 Avg Reward (Last 100): 17.832 Epsilon: 0.100\n",
      "Copied model parameters to target network. total_t = 550000, period = 10000\n",
      "Episode: 1705 Duration: 0:00:12.283484 Num steps: 873 Reward: 15.0 Training time per step: 0.010 Avg Reward (Last 100): 17.723 Epsilon: 0.100\n",
      "Episode: 1706 Duration: 0:00:14.827856 Num steps: 978 Reward: 20.0 Training time per step: 0.011 Avg Reward (Last 100): 17.782 Epsilon: 0.100\n",
      "Episode: 1707 Duration: 0:00:22.004164 Num steps: 1639 Reward: 32.0 Training time per step: 0.010 Avg Reward (Last 100): 17.901 Epsilon: 0.100\n",
      "Episode: 1708 Duration: 0:00:15.257864 Num steps: 1107 Reward: 26.0 Training time per step: 0.010 Avg Reward (Last 100): 18.020 Epsilon: 0.100\n",
      "Episode: 1709 Duration: 0:00:09.483569 Num steps: 681 Reward: 12.0 Training time per step: 0.010 Avg Reward (Last 100): 17.980 Epsilon: 0.100\n",
      "Episode: 1710 Duration: 0:00:13.586936 Num steps: 1009 Reward: 20.0 Training time per step: 0.010 Avg Reward (Last 100): 18.109 Epsilon: 0.100\n",
      "Episode: 1711 Duration: 0:00:10.650341 Num steps: 792 Reward: 13.0 Training time per step: 0.010 Avg Reward (Last 100): 18.040 Epsilon: 0.100\n",
      "Episode: 1712 Duration: 0:00:10.829335 Num steps: 801 Reward: 12.0 Training time per step: 0.010 Avg Reward (Last 100): 17.980 Epsilon: 0.100\n",
      "Episode: 1713 Duration: 0:00:12.684077 Num steps: 826 Reward: 13.0 Training time per step: 0.012 Avg Reward (Last 100): 17.960 Epsilon: 0.100\n",
      "Episode: 1714 Duration: 0:00:17.473914 Num steps: 1023 Reward: 24.0 Training time per step: 0.013 Avg Reward (Last 100): 17.990 Epsilon: 0.100\n",
      "Copied model parameters to target network. total_t = 560000, period = 10000\n",
      "Episode: 1715 Duration: 0:00:13.993426 Num steps: 862 Reward: 17.0 Training time per step: 0.012 Avg Reward (Last 100): 17.881 Epsilon: 0.100\n",
      "Episode: 1716 Duration: 0:00:20.898795 Num steps: 1242 Reward: 40.0 Training time per step: 0.013 Avg Reward (Last 100): 18.168 Epsilon: 0.100\n",
      "Episode: 1717 Duration: 0:00:16.216180 Num steps: 1227 Reward: 25.0 Training time per step: 0.010 Avg Reward (Last 100): 18.257 Epsilon: 0.100\n",
      "Episode: 1718 Duration: 0:00:16.018893 Num steps: 1042 Reward: 21.0 Training time per step: 0.012 Avg Reward (Last 100): 18.356 Epsilon: 0.100\n",
      "Episode: 1719 Duration: 0:00:15.561654 Num steps: 931 Reward: 19.0 Training time per step: 0.013 Avg Reward (Last 100): 18.376 Epsilon: 0.100\n",
      "Episode: 1720 Duration: 0:00:16.036596 Num steps: 933 Reward: 14.0 Training time per step: 0.013 Avg Reward (Last 100): 18.426 Epsilon: 0.100\n",
      "Episode: 1721 Duration: 0:00:16.155522 Num steps: 951 Reward: 16.0 Training time per step: 0.013 Avg Reward (Last 100): 18.436 Epsilon: 0.100\n",
      "Episode: 1722 Duration: 0:00:12.538665 Num steps: 759 Reward: 16.0 Training time per step: 0.012 Avg Reward (Last 100): 18.545 Epsilon: 0.100\n",
      "Episode: 1723 Duration: 0:00:12.879492 Num steps: 807 Reward: 17.0 Training time per step: 0.012 Avg Reward (Last 100): 18.505 Epsilon: 0.100\n",
      "Episode: 1724 Duration: 0:00:14.494049 Num steps: 898 Reward: 18.0 Training time per step: 0.012 Avg Reward (Last 100): 18.436 Epsilon: 0.100\n",
      "Episode: 1725 Duration: 0:00:16.037304 Num steps: 982 Reward: 21.0 Training time per step: 0.012 Avg Reward (Last 100): 18.416 Epsilon: 0.100\n",
      "Copied model parameters to target network. total_t = 570000, period = 10000\n",
      "Episode: 1726 Duration: 0:00:14.841396 Num steps: 875 Reward: 14.0 Training time per step: 0.012 Avg Reward (Last 100): 18.426 Epsilon: 0.100\n",
      "Episode: 1727 Duration: 0:00:17.708750 Num steps: 1088 Reward: 23.0 Training time per step: 0.012 Avg Reward (Last 100): 18.505 Epsilon: 0.100\n",
      "Episode: 1728 Duration: 0:00:12.286424 Num steps: 749 Reward: 14.0 Training time per step: 0.012 Avg Reward (Last 100): 18.465 Epsilon: 0.100\n",
      "Episode: 1729 Duration: 0:00:14.148500 Num steps: 845 Reward: 18.0 Training time per step: 0.013 Avg Reward (Last 100): 18.455 Epsilon: 0.100\n",
      "Episode: 1730 Duration: 0:00:16.244327 Num steps: 1064 Reward: 20.0 Training time per step: 0.011 Avg Reward (Last 100): 18.455 Epsilon: 0.100\n",
      "Episode: 1731 Duration: 0:00:12.132280 Num steps: 849 Reward: 12.0 Training time per step: 0.011 Avg Reward (Last 100): 18.505 Epsilon: 0.100\n",
      "Episode: 1732 Duration: 0:00:14.812472 Num steps: 824 Reward: 24.0 Training time per step: 0.014 Avg Reward (Last 100): 18.594 Epsilon: 0.100\n",
      "Episode: 1733 Duration: 0:00:15.243886 Num steps: 876 Reward: 15.0 Training time per step: 0.013 Avg Reward (Last 100): 18.614 Epsilon: 0.100\n",
      "Episode: 1734 Duration: 0:00:12.756625 Num steps: 808 Reward: 13.0 Training time per step: 0.012 Avg Reward (Last 100): 18.495 Epsilon: 0.100\n",
      "Episode: 1735 Duration: 0:00:12.956437 Num steps: 854 Reward: 17.0 Training time per step: 0.011 Avg Reward (Last 100): 18.545 Epsilon: 0.100\n",
      "Episode: 1736 Duration: 0:00:15.327063 Num steps: 1015 Reward: 24.0 Training time per step: 0.011 Avg Reward (Last 100): 18.535 Epsilon: 0.100\n",
      "Copied model parameters to target network. total_t = 580000, period = 10000\n",
      "Episode: 1737 Duration: 0:00:10.556737 Num steps: 676 Reward: 11.0 Training time per step: 0.011 Avg Reward (Last 100): 18.485 Epsilon: 0.100\n",
      "Episode: 1738 Duration: 0:00:14.572122 Num steps: 969 Reward: 31.0 Training time per step: 0.011 Avg Reward (Last 100): 18.673 Epsilon: 0.100\n",
      "Episode: 1739 Duration: 0:00:13.432496 Num steps: 899 Reward: 16.0 Training time per step: 0.011 Avg Reward (Last 100): 18.723 Epsilon: 0.100\n",
      "Episode: 1740 Duration: 0:00:17.299013 Num steps: 1249 Reward: 29.0 Training time per step: 0.010 Avg Reward (Last 100): 18.713 Epsilon: 0.100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1741 Duration: 0:00:08.103181 Num steps: 633 Reward: 9.0 Training time per step: 0.010 Avg Reward (Last 100): 18.663 Epsilon: 0.100\n",
      "Episode: 1742 Duration: 0:00:13.535260 Num steps: 1063 Reward: 19.0 Training time per step: 0.010 Avg Reward (Last 100): 18.644 Epsilon: 0.100\n",
      "Episode: 1743 Duration: 0:00:14.280057 Num steps: 1121 Reward: 35.0 Training time per step: 0.010 Avg Reward (Last 100): 18.842 Epsilon: 0.100\n",
      "Episode: 1744 Duration: 0:00:11.598044 Num steps: 909 Reward: 29.0 Training time per step: 0.010 Avg Reward (Last 100): 19.010 Epsilon: 0.100\n",
      "Episode: 1745 Duration: 0:00:18.481978 Num steps: 1448 Reward: 43.0 Training time per step: 0.010 Avg Reward (Last 100): 19.327 Epsilon: 0.100\n",
      "Episode: 1746 Duration: 0:00:17.156181 Num steps: 1346 Reward: 30.0 Training time per step: 0.010 Avg Reward (Last 100): 19.426 Epsilon: 0.100\n",
      "Copied model parameters to target network. total_t = 590000, period = 10000\n",
      "Episode: 1747 Duration: 0:00:14.003249 Num steps: 1063 Reward: 23.0 Training time per step: 0.010 Avg Reward (Last 100): 19.525 Epsilon: 0.100\n",
      "Episode: 1748 Duration: 0:00:20.057747 Num steps: 1572 Reward: 40.0 Training time per step: 0.010 Avg Reward (Last 100): 19.782 Epsilon: 0.100\n",
      "Episode: 1749 Duration: 0:00:15.078680 Num steps: 1185 Reward: 24.0 Training time per step: 0.010 Avg Reward (Last 100): 19.832 Epsilon: 0.100\n",
      "Episode: 1750 Duration: 0:00:12.324847 Num steps: 967 Reward: 17.0 Training time per step: 0.010 Avg Reward (Last 100): 19.881 Epsilon: 0.100\n",
      "Episode: 1751 Duration: 0:00:14.797415 Num steps: 1163 Reward: 29.0 Training time per step: 0.010 Avg Reward (Last 100): 20.030 Epsilon: 0.100\n",
      "Episode: 1752 Duration: 0:00:14.624199 Num steps: 1147 Reward: 36.0 Training time per step: 0.010 Avg Reward (Last 100): 20.158 Epsilon: 0.100\n",
      "Episode: 1753 Duration: 0:00:14.926160 Num steps: 1168 Reward: 29.0 Training time per step: 0.010 Avg Reward (Last 100): 20.297 Epsilon: 0.100\n",
      "Episode: 1754 Duration: 0:00:10.395953 Num steps: 815 Reward: 24.0 Training time per step: 0.010 Avg Reward (Last 100): 20.347 Epsilon: 0.100\n",
      "Episode: 1755 Duration: 0:00:12.054952 Num steps: 942 Reward: 18.0 Training time per step: 0.010 Avg Reward (Last 100): 20.356 Epsilon: 0.100\n",
      "Copied model parameters to target network. total_t = 600000, period = 10000\n",
      "Episode: 1756 Duration: 0:00:17.000058 Num steps: 1308 Reward: 30.0 Training time per step: 0.010 Avg Reward (Last 100): 20.455 Epsilon: 0.100\n",
      "Episode: 1757 Duration: 0:00:11.178018 Num steps: 876 Reward: 14.0 Training time per step: 0.010 Avg Reward (Last 100): 20.366 Epsilon: 0.100\n",
      "Episode: 1758 Duration: 0:00:12.165306 Num steps: 952 Reward: 17.0 Training time per step: 0.010 Avg Reward (Last 100): 20.317 Epsilon: 0.100\n",
      "Episode: 1759 Duration: 0:00:13.074376 Num steps: 1023 Reward: 20.0 Training time per step: 0.010 Avg Reward (Last 100): 20.307 Epsilon: 0.100\n",
      "Episode: 1760 Duration: 0:00:11.170760 Num steps: 874 Reward: 22.0 Training time per step: 0.010 Avg Reward (Last 100): 20.277 Epsilon: 0.100\n",
      "Episode: 1761 Duration: 0:00:16.029105 Num steps: 1255 Reward: 30.0 Training time per step: 0.010 Avg Reward (Last 100): 20.317 Epsilon: 0.100\n",
      "Episode: 1762 Duration: 0:00:13.777538 Num steps: 1080 Reward: 24.0 Training time per step: 0.010 Avg Reward (Last 100): 20.446 Epsilon: 0.100\n",
      "Episode: 1763 Duration: 0:00:12.405303 Num steps: 974 Reward: 19.0 Training time per step: 0.010 Avg Reward (Last 100): 20.515 Epsilon: 0.100\n",
      "Episode: 1764 Duration: 0:00:15.308491 Num steps: 1199 Reward: 31.0 Training time per step: 0.010 Avg Reward (Last 100): 20.465 Epsilon: 0.100\n",
      "Copied model parameters to target network. total_t = 610000, period = 10000\n",
      "Episode: 1765 Duration: 0:00:11.036769 Num steps: 834 Reward: 14.0 Training time per step: 0.010 Avg Reward (Last 100): 20.366 Epsilon: 0.100\n",
      "Episode: 1766 Duration: 0:00:09.700448 Num steps: 760 Reward: 13.0 Training time per step: 0.010 Avg Reward (Last 100): 20.218 Epsilon: 0.100\n",
      "Episode: 1767 Duration: 0:00:19.319031 Num steps: 1517 Reward: 34.0 Training time per step: 0.010 Avg Reward (Last 100): 20.327 Epsilon: 0.100\n",
      "Episode: 1768 Duration: 0:00:11.492739 Num steps: 900 Reward: 15.0 Training time per step: 0.010 Avg Reward (Last 100): 20.297 Epsilon: 0.100\n",
      "Episode: 1769 Duration: 0:00:13.236514 Num steps: 1040 Reward: 28.0 Training time per step: 0.010 Avg Reward (Last 100): 20.406 Epsilon: 0.100\n",
      "Episode: 1770 Duration: 0:00:14.612582 Num steps: 1146 Reward: 24.0 Training time per step: 0.010 Avg Reward (Last 100): 20.426 Epsilon: 0.100\n",
      "Episode: 1771 Duration: 0:00:13.252467 Num steps: 1038 Reward: 33.0 Training time per step: 0.010 Avg Reward (Last 100): 20.564 Epsilon: 0.100\n",
      "Episode: 1772 Duration: 0:00:13.939908 Num steps: 1093 Reward: 32.0 Training time per step: 0.010 Avg Reward (Last 100): 20.752 Epsilon: 0.100\n",
      "Episode: 1773 Duration: 0:00:12.497246 Num steps: 978 Reward: 21.0 Training time per step: 0.010 Avg Reward (Last 100): 20.802 Epsilon: 0.100\n",
      "Episode: 1774 Duration: 0:00:12.148311 Num steps: 952 Reward: 20.0 Training time per step: 0.010 Avg Reward (Last 100): 20.881 Epsilon: 0.100\n",
      "Copied model parameters to target network. total_t = 620000, period = 10000\n",
      "Episode: 1775 Duration: 0:00:12.495995 Num steps: 944 Reward: 21.0 Training time per step: 0.010 Avg Reward (Last 100): 20.554 Epsilon: 0.100\n",
      "Episode: 1776 Duration: 0:00:14.832792 Num steps: 1123 Reward: 40.0 Training time per step: 0.010 Avg Reward (Last 100): 20.851 Epsilon: 0.100\n",
      "Episode: 1777 Duration: 0:00:12.207251 Num steps: 946 Reward: 20.0 Training time per step: 0.010 Avg Reward (Last 100): 20.812 Epsilon: 0.100\n",
      "Episode: 1778 Duration: 0:00:16.511621 Num steps: 1282 Reward: 29.0 Training time per step: 0.010 Avg Reward (Last 100): 21.040 Epsilon: 0.100\n",
      "Episode: 1779 Duration: 0:00:16.167958 Num steps: 1261 Reward: 34.0 Training time per step: 0.010 Avg Reward (Last 100): 21.129 Epsilon: 0.100\n",
      "Episode: 1780 Duration: 0:00:17.294019 Num steps: 1359 Reward: 34.0 Training time per step: 0.010 Avg Reward (Last 100): 21.257 Epsilon: 0.100\n",
      "Episode: 1781 Duration: 0:00:10.791445 Num steps: 847 Reward: 15.0 Training time per step: 0.010 Avg Reward (Last 100): 21.228 Epsilon: 0.100\n",
      "Episode: 1782 Duration: 0:00:19.491615 Num steps: 1530 Reward: 54.0 Training time per step: 0.010 Avg Reward (Last 100): 21.644 Epsilon: 0.100\n",
      "Copied model parameters to target network. total_t = 630000, period = 10000\n",
      "Episode: 1783 Duration: 0:00:14.201562 Num steps: 1081 Reward: 18.0 Training time per step: 0.010 Avg Reward (Last 100): 21.535 Epsilon: 0.100\n",
      "Episode: 1784 Duration: 0:00:09.914424 Num steps: 777 Reward: 15.0 Training time per step: 0.010 Avg Reward (Last 100): 21.515 Epsilon: 0.100\n",
      "Episode: 1785 Duration: 0:00:26.837207 Num steps: 2108 Reward: 55.0 Training time per step: 0.010 Avg Reward (Last 100): 21.960 Epsilon: 0.100\n",
      "Episode: 1786 Duration: 0:00:11.811342 Num steps: 923 Reward: 20.0 Training time per step: 0.010 Avg Reward (Last 100): 22.040 Epsilon: 0.100\n",
      "Episode: 1787 Duration: 0:00:12.729856 Num steps: 994 Reward: 21.0 Training time per step: 0.010 Avg Reward (Last 100): 22.089 Epsilon: 0.100\n",
      "Episode: 1788 Duration: 0:00:08.325380 Num steps: 654 Reward: 11.0 Training time per step: 0.010 Avg Reward (Last 100): 22.010 Epsilon: 0.100\n",
      "Episode: 1789 Duration: 0:00:18.331082 Num steps: 1442 Reward: 37.0 Training time per step: 0.010 Avg Reward (Last 100): 22.248 Epsilon: 0.100\n",
      "Episode: 1790 Duration: 0:00:15.984725 Num steps: 1258 Reward: 25.0 Training time per step: 0.009 Avg Reward (Last 100): 22.277 Epsilon: 0.100\n",
      "Episode: 1791 Duration: 0:00:17.523061 Num steps: 1375 Reward: 27.0 Training time per step: 0.010 Avg Reward (Last 100): 22.287 Epsilon: 0.100\n",
      "Copied model parameters to target network. total_t = 640000, period = 10000\n",
      "Episode: 1792 Duration: 0:00:12.245636 Num steps: 934 Reward: 24.0 Training time per step: 0.010 Avg Reward (Last 100): 22.406 Epsilon: 0.100\n",
      "Episode: 1793 Duration: 0:00:12.676316 Num steps: 995 Reward: 17.0 Training time per step: 0.010 Avg Reward (Last 100): 22.396 Epsilon: 0.100\n",
      "Episode: 1794 Duration: 0:00:19.579979 Num steps: 1540 Reward: 41.0 Training time per step: 0.010 Avg Reward (Last 100): 22.564 Epsilon: 0.100\n",
      "Episode: 1795 Duration: 0:00:15.500225 Num steps: 1209 Reward: 22.0 Training time per step: 0.010 Avg Reward (Last 100): 22.584 Epsilon: 0.100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1796 Duration: 0:00:16.392447 Num steps: 1284 Reward: 33.0 Training time per step: 0.010 Avg Reward (Last 100): 22.713 Epsilon: 0.100\n",
      "Episode: 1797 Duration: 0:00:09.402128 Num steps: 737 Reward: 18.0 Training time per step: 0.010 Avg Reward (Last 100): 22.683 Epsilon: 0.100\n",
      "Episode: 1798 Duration: 0:00:12.829391 Num steps: 1003 Reward: 18.0 Training time per step: 0.010 Avg Reward (Last 100): 22.663 Epsilon: 0.100\n",
      "Episode: 1799 Duration: 0:00:10.416493 Num steps: 819 Reward: 14.0 Training time per step: 0.009 Avg Reward (Last 100): 22.634 Epsilon: 0.100\n",
      "Episode: 1800 Duration: 0:00:13.347652 Num steps: 1042 Reward: 19.0 Training time per step: 0.010 Avg Reward (Last 100): 22.663 Epsilon: 0.100\n",
      "Copied model parameters to target network. total_t = 650000, period = 10000\n",
      "Episode: 1801 Duration: 0:00:13.966042 Num steps: 1064 Reward: 25.0 Training time per step: 0.010 Avg Reward (Last 100): 22.802 Epsilon: 0.100\n",
      "Episode: 1802 Duration: 0:00:16.048248 Num steps: 1260 Reward: 25.0 Training time per step: 0.010 Avg Reward (Last 100): 22.950 Epsilon: 0.100\n",
      "Episode: 1803 Duration: 0:00:11.214132 Num steps: 882 Reward: 16.0 Training time per step: 0.009 Avg Reward (Last 100): 22.980 Epsilon: 0.100\n",
      "Episode: 1804 Duration: 0:00:13.619775 Num steps: 1060 Reward: 21.0 Training time per step: 0.010 Avg Reward (Last 100): 22.941 Epsilon: 0.100\n",
      "Episode: 1805 Duration: 0:00:11.089918 Num steps: 869 Reward: 18.0 Training time per step: 0.010 Avg Reward (Last 100): 23.020 Epsilon: 0.100\n",
      "Episode: 1806 Duration: 0:00:17.810409 Num steps: 1403 Reward: 32.0 Training time per step: 0.009 Avg Reward (Last 100): 23.188 Epsilon: 0.100\n",
      "Episode: 1807 Duration: 0:00:12.838397 Num steps: 1008 Reward: 24.0 Training time per step: 0.010 Avg Reward (Last 100): 23.228 Epsilon: 0.100\n",
      "Episode: 1808 Duration: 0:00:18.652384 Num steps: 1464 Reward: 34.0 Training time per step: 0.010 Avg Reward (Last 100): 23.248 Epsilon: 0.100\n",
      "Episode: 1809 Duration: 0:00:15.253274 Num steps: 1195 Reward: 27.0 Training time per step: 0.010 Avg Reward (Last 100): 23.257 Epsilon: 0.100\n",
      "Copied model parameters to target network. total_t = 660000, period = 10000\n",
      "Episode: 1810 Duration: 0:00:11.058391 Num steps: 837 Reward: 24.0 Training time per step: 0.010 Avg Reward (Last 100): 23.376 Epsilon: 0.100\n",
      "Episode: 1811 Duration: 0:00:14.643987 Num steps: 1151 Reward: 27.0 Training time per step: 0.010 Avg Reward (Last 100): 23.446 Epsilon: 0.100\n",
      "Episode: 1812 Duration: 0:00:13.418828 Num steps: 1049 Reward: 25.0 Training time per step: 0.010 Avg Reward (Last 100): 23.564 Epsilon: 0.100\n",
      "Episode: 1813 Duration: 0:00:10.158890 Num steps: 796 Reward: 12.0 Training time per step: 0.010 Avg Reward (Last 100): 23.564 Epsilon: 0.100\n",
      "Episode: 1814 Duration: 0:00:11.375658 Num steps: 893 Reward: 18.0 Training time per step: 0.010 Avg Reward (Last 100): 23.614 Epsilon: 0.100\n",
      "Episode: 1815 Duration: 0:00:11.050895 Num steps: 867 Reward: 29.0 Training time per step: 0.010 Avg Reward (Last 100): 23.663 Epsilon: 0.100\n",
      "Episode: 1816 Duration: 0:00:12.250019 Num steps: 962 Reward: 21.0 Training time per step: 0.010 Avg Reward (Last 100): 23.703 Epsilon: 0.100\n",
      "Episode: 1817 Duration: 0:00:17.384432 Num steps: 1362 Reward: 31.0 Training time per step: 0.010 Avg Reward (Last 100): 23.614 Epsilon: 0.100\n",
      "Episode: 1818 Duration: 0:00:11.241951 Num steps: 882 Reward: 18.0 Training time per step: 0.010 Avg Reward (Last 100): 23.545 Epsilon: 0.100\n",
      "Episode: 1819 Duration: 0:00:12.510582 Num steps: 978 Reward: 24.0 Training time per step: 0.010 Avg Reward (Last 100): 23.574 Epsilon: 0.100\n",
      "Copied model parameters to target network. total_t = 670000, period = 10000\n",
      "Episode: 1820 Duration: 0:00:11.373883 Num steps: 858 Reward: 15.0 Training time per step: 0.010 Avg Reward (Last 100): 23.535 Epsilon: 0.100\n",
      "Episode: 1821 Duration: 0:00:12.735891 Num steps: 996 Reward: 21.0 Training time per step: 0.010 Avg Reward (Last 100): 23.604 Epsilon: 0.100\n",
      "Episode: 1822 Duration: 0:00:12.191664 Num steps: 951 Reward: 21.0 Training time per step: 0.010 Avg Reward (Last 100): 23.653 Epsilon: 0.100\n",
      "Episode: 1823 Duration: 0:00:12.864294 Num steps: 1009 Reward: 20.0 Training time per step: 0.010 Avg Reward (Last 100): 23.693 Epsilon: 0.100\n",
      "Episode: 1824 Duration: 0:00:15.614332 Num steps: 1226 Reward: 22.0 Training time per step: 0.010 Avg Reward (Last 100): 23.743 Epsilon: 0.100\n",
      "Episode: 1825 Duration: 0:00:09.205488 Num steps: 722 Reward: 11.0 Training time per step: 0.010 Avg Reward (Last 100): 23.673 Epsilon: 0.100\n",
      "Episode: 1826 Duration: 0:00:13.656434 Num steps: 1067 Reward: 23.0 Training time per step: 0.010 Avg Reward (Last 100): 23.693 Epsilon: 0.100\n",
      "Episode: 1827 Duration: 0:00:17.323431 Num steps: 1356 Reward: 29.0 Training time per step: 0.010 Avg Reward (Last 100): 23.842 Epsilon: 0.100\n",
      "Episode: 1828 Duration: 0:00:14.167524 Num steps: 1109 Reward: 20.0 Training time per step: 0.010 Avg Reward (Last 100): 23.812 Epsilon: 0.100\n",
      "Episode: 1829 Duration: 0:00:18.076345 Num steps: 1411 Reward: 38.0 Training time per step: 0.010 Avg Reward (Last 100): 24.050 Epsilon: 0.100\n",
      "Copied model parameters to target network. total_t = 680000, period = 10000\n",
      "Episode: 1830 Duration: 0:00:19.850170 Num steps: 1519 Reward: 37.0 Training time per step: 0.010 Avg Reward (Last 100): 24.238 Epsilon: 0.100\n",
      "Episode: 1831 Duration: 0:00:11.896525 Num steps: 931 Reward: 19.0 Training time per step: 0.010 Avg Reward (Last 100): 24.228 Epsilon: 0.100\n",
      "Episode: 1832 Duration: 0:00:13.994193 Num steps: 1099 Reward: 27.0 Training time per step: 0.010 Avg Reward (Last 100): 24.376 Epsilon: 0.100\n",
      "Episode: 1833 Duration: 0:00:11.522327 Num steps: 899 Reward: 15.0 Training time per step: 0.010 Avg Reward (Last 100): 24.287 Epsilon: 0.100\n",
      "Episode: 1834 Duration: 0:00:18.229211 Num steps: 1430 Reward: 34.0 Training time per step: 0.010 Avg Reward (Last 100): 24.475 Epsilon: 0.100\n",
      "Episode: 1835 Duration: 0:00:12.362891 Num steps: 969 Reward: 27.0 Training time per step: 0.010 Avg Reward (Last 100): 24.614 Epsilon: 0.100\n",
      "Episode: 1836 Duration: 0:00:13.341021 Num steps: 1042 Reward: 20.0 Training time per step: 0.010 Avg Reward (Last 100): 24.644 Epsilon: 0.100\n",
      "Episode: 1837 Duration: 0:00:13.753780 Num steps: 1079 Reward: 23.0 Training time per step: 0.010 Avg Reward (Last 100): 24.634 Epsilon: 0.100\n",
      "Episode: 1838 Duration: 0:00:10.425878 Num steps: 819 Reward: 21.0 Training time per step: 0.010 Avg Reward (Last 100): 24.733 Epsilon: 0.100\n",
      "Copied model parameters to target network. total_t = 690000, period = 10000\n",
      "Episode: 1839 Duration: 0:00:11.880148 Num steps: 900 Reward: 18.0 Training time per step: 0.010 Avg Reward (Last 100): 24.604 Epsilon: 0.100\n",
      "Episode: 1840 Duration: 0:00:13.771036 Num steps: 1080 Reward: 22.0 Training time per step: 0.010 Avg Reward (Last 100): 24.663 Epsilon: 0.100\n",
      "Episode: 1841 Duration: 0:00:11.270353 Num steps: 882 Reward: 22.0 Training time per step: 0.010 Avg Reward (Last 100): 24.594 Epsilon: 0.100\n",
      "Episode: 1842 Duration: 0:00:16.880826 Num steps: 1323 Reward: 40.0 Training time per step: 0.010 Avg Reward (Last 100): 24.901 Epsilon: 0.100\n",
      "Episode: 1843 Duration: 0:00:08.042668 Num steps: 630 Reward: 11.0 Training time per step: 0.010 Avg Reward (Last 100): 24.822 Epsilon: 0.100\n",
      "Episode: 1844 Duration: 0:00:08.488872 Num steps: 666 Reward: 10.0 Training time per step: 0.010 Avg Reward (Last 100): 24.574 Epsilon: 0.100\n",
      "Episode: 1845 Duration: 0:00:09.971966 Num steps: 781 Reward: 17.0 Training time per step: 0.010 Avg Reward (Last 100): 24.455 Epsilon: 0.100\n",
      "Episode: 1846 Duration: 0:00:17.120651 Num steps: 1342 Reward: 31.0 Training time per step: 0.010 Avg Reward (Last 100): 24.337 Epsilon: 0.100\n",
      "Episode: 1847 Duration: 0:00:15.115212 Num steps: 1187 Reward: 26.0 Training time per step: 0.010 Avg Reward (Last 100): 24.297 Epsilon: 0.100\n",
      "Episode: 1848 Duration: 0:00:11.749949 Num steps: 921 Reward: 21.0 Training time per step: 0.010 Avg Reward (Last 100): 24.277 Epsilon: 0.100\n",
      "Episode: 1849 Duration: 0:00:07.124703 Num steps: 556 Reward: 8.0 Training time per step: 0.010 Avg Reward (Last 100): 23.960 Epsilon: 0.100\n",
      "Copied model parameters to target network. total_t = 700000, period = 10000\n",
      "Episode: 1850 Duration: 0:00:07.367169 Num steps: 545 Reward: 8.0 Training time per step: 0.010 Avg Reward (Last 100): 23.802 Epsilon: 0.100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1851 Duration: 0:00:17.220846 Num steps: 1351 Reward: 35.0 Training time per step: 0.010 Avg Reward (Last 100): 23.980 Epsilon: 0.100\n",
      "Episode: 1852 Duration: 0:00:17.825846 Num steps: 1394 Reward: 42.0 Training time per step: 0.010 Avg Reward (Last 100): 24.109 Epsilon: 0.100\n",
      "Episode: 1853 Duration: 0:00:15.972649 Num steps: 1249 Reward: 34.0 Training time per step: 0.010 Avg Reward (Last 100): 24.089 Epsilon: 0.100\n",
      "Episode: 1854 Duration: 0:00:09.175234 Num steps: 719 Reward: 15.0 Training time per step: 0.010 Avg Reward (Last 100): 23.950 Epsilon: 0.100\n",
      "Episode: 1855 Duration: 0:00:13.729367 Num steps: 1078 Reward: 26.0 Training time per step: 0.010 Avg Reward (Last 100): 23.970 Epsilon: 0.100\n",
      "Episode: 1856 Duration: 0:00:12.731541 Num steps: 1000 Reward: 21.0 Training time per step: 0.010 Avg Reward (Last 100): 24.000 Epsilon: 0.100\n",
      "Episode: 1857 Duration: 0:00:11.156630 Num steps: 878 Reward: 16.0 Training time per step: 0.009 Avg Reward (Last 100): 23.861 Epsilon: 0.100\n",
      "Episode: 1858 Duration: 0:00:09.480292 Num steps: 743 Reward: 12.0 Training time per step: 0.010 Avg Reward (Last 100): 23.842 Epsilon: 0.100\n",
      "Copied model parameters to target network. total_t = 710000, period = 10000\n",
      "Episode: 1859 Duration: 0:00:17.476840 Num steps: 1330 Reward: 31.0 Training time per step: 0.010 Avg Reward (Last 100): 23.980 Epsilon: 0.100\n",
      "Episode: 1860 Duration: 0:00:09.907415 Num steps: 779 Reward: 12.0 Training time per step: 0.010 Avg Reward (Last 100): 23.901 Epsilon: 0.100\n",
      "Episode: 1861 Duration: 0:00:13.062510 Num steps: 1027 Reward: 27.0 Training time per step: 0.010 Avg Reward (Last 100): 23.950 Epsilon: 0.100\n",
      "Episode: 1862 Duration: 0:00:12.164842 Num steps: 955 Reward: 17.0 Training time per step: 0.010 Avg Reward (Last 100): 23.822 Epsilon: 0.100\n",
      "Episode: 1863 Duration: 0:00:10.292948 Num steps: 808 Reward: 12.0 Training time per step: 0.010 Avg Reward (Last 100): 23.703 Epsilon: 0.100\n",
      "Episode: 1864 Duration: 0:00:13.381885 Num steps: 1045 Reward: 25.0 Training time per step: 0.010 Avg Reward (Last 100): 23.762 Epsilon: 0.100\n",
      "Episode: 1865 Duration: 0:00:13.181160 Num steps: 1033 Reward: 19.0 Training time per step: 0.010 Avg Reward (Last 100): 23.644 Epsilon: 0.100\n",
      "Episode: 1866 Duration: 0:00:17.132593 Num steps: 1344 Reward: 30.0 Training time per step: 0.010 Avg Reward (Last 100): 23.802 Epsilon: 0.100\n",
      "Episode: 1867 Duration: 0:00:13.002323 Num steps: 1020 Reward: 23.0 Training time per step: 0.010 Avg Reward (Last 100): 23.901 Epsilon: 0.100\n",
      "Episode: 1868 Duration: 0:00:11.912056 Num steps: 925 Reward: 14.0 Training time per step: 0.010 Avg Reward (Last 100): 23.703 Epsilon: 0.100\n",
      "Copied model parameters to target network. total_t = 720000, period = 10000\n",
      "Episode: 1869 Duration: 0:00:13.177659 Num steps: 997 Reward: 21.0 Training time per step: 0.010 Avg Reward (Last 100): 23.762 Epsilon: 0.100\n",
      "Episode: 1870 Duration: 0:00:20.858575 Num steps: 1637 Reward: 42.0 Training time per step: 0.010 Avg Reward (Last 100): 23.901 Epsilon: 0.100\n",
      "Episode: 1871 Duration: 0:00:13.530964 Num steps: 1062 Reward: 23.0 Training time per step: 0.010 Avg Reward (Last 100): 23.891 Epsilon: 0.100\n",
      "Episode: 1872 Duration: 0:00:10.632976 Num steps: 831 Reward: 17.0 Training time per step: 0.010 Avg Reward (Last 100): 23.733 Epsilon: 0.100\n",
      "Episode: 1873 Duration: 0:00:12.408717 Num steps: 970 Reward: 16.0 Training time per step: 0.010 Avg Reward (Last 100): 23.574 Epsilon: 0.100\n",
      "Episode: 1874 Duration: 0:00:12.413577 Num steps: 971 Reward: 18.0 Training time per step: 0.010 Avg Reward (Last 100): 23.545 Epsilon: 0.100\n",
      "Episode: 1875 Duration: 0:00:07.312313 Num steps: 574 Reward: 9.0 Training time per step: 0.010 Avg Reward (Last 100): 23.436 Epsilon: 0.100\n",
      "Episode: 1876 Duration: 0:00:12.181071 Num steps: 952 Reward: 19.0 Training time per step: 0.010 Avg Reward (Last 100): 23.416 Epsilon: 0.100\n",
      "Episode: 1877 Duration: 0:00:09.329369 Num steps: 730 Reward: 16.0 Training time per step: 0.010 Avg Reward (Last 100): 23.178 Epsilon: 0.100\n",
      "Episode: 1878 Duration: 0:00:12.555636 Num steps: 978 Reward: 15.0 Training time per step: 0.010 Avg Reward (Last 100): 23.129 Epsilon: 0.100\n",
      "Episode: 1879 Duration: 0:00:13.420582 Num steps: 1050 Reward: 23.0 Training time per step: 0.010 Avg Reward (Last 100): 23.069 Epsilon: 0.100\n",
      "Copied model parameters to target network. total_t = 730000, period = 10000\n",
      "Episode: 1880 Duration: 0:00:17.185400 Num steps: 1311 Reward: 26.0 Training time per step: 0.010 Avg Reward (Last 100): 22.990 Epsilon: 0.100\n",
      "Episode: 1881 Duration: 0:00:10.452435 Num steps: 817 Reward: 13.0 Training time per step: 0.010 Avg Reward (Last 100): 22.782 Epsilon: 0.100\n",
      "Episode: 1882 Duration: 0:00:16.174915 Num steps: 1267 Reward: 27.0 Training time per step: 0.010 Avg Reward (Last 100): 22.901 Epsilon: 0.100\n",
      "Episode: 1883 Duration: 0:00:09.947371 Num steps: 778 Reward: 17.0 Training time per step: 0.010 Avg Reward (Last 100): 22.535 Epsilon: 0.100\n",
      "Episode: 1884 Duration: 0:00:14.490010 Num steps: 1134 Reward: 24.0 Training time per step: 0.010 Avg Reward (Last 100): 22.594 Epsilon: 0.100\n",
      "Episode: 1885 Duration: 0:00:11.759030 Num steps: 923 Reward: 25.0 Training time per step: 0.010 Avg Reward (Last 100): 22.693 Epsilon: 0.100\n",
      "Episode: 1886 Duration: 0:00:14.690388 Num steps: 1145 Reward: 22.0 Training time per step: 0.010 Avg Reward (Last 100): 22.366 Epsilon: 0.100\n",
      "Episode: 1887 Duration: 0:00:14.031744 Num steps: 1092 Reward: 22.0 Training time per step: 0.010 Avg Reward (Last 100): 22.386 Epsilon: 0.100\n",
      "Episode: 1888 Duration: 0:00:13.197564 Num steps: 1037 Reward: 17.0 Training time per step: 0.010 Avg Reward (Last 100): 22.347 Epsilon: 0.100\n",
      "Copied model parameters to target network. total_t = 740000, period = 10000\n",
      "Episode: 1889 Duration: 0:00:09.961528 Num steps: 746 Reward: 14.0 Training time per step: 0.010 Avg Reward (Last 100): 22.376 Epsilon: 0.100\n",
      "Episode: 1890 Duration: 0:00:12.564447 Num steps: 983 Reward: 22.0 Training time per step: 0.010 Avg Reward (Last 100): 22.228 Epsilon: 0.100\n",
      "Episode: 1891 Duration: 0:00:12.155433 Num steps: 951 Reward: 20.0 Training time per step: 0.010 Avg Reward (Last 100): 22.178 Epsilon: 0.100\n",
      "Episode: 1892 Duration: 0:00:11.288462 Num steps: 886 Reward: 20.0 Training time per step: 0.010 Avg Reward (Last 100): 22.109 Epsilon: 0.100\n",
      "Episode: 1893 Duration: 0:00:08.434295 Num steps: 660 Reward: 10.0 Training time per step: 0.010 Avg Reward (Last 100): 21.970 Epsilon: 0.100\n",
      "Episode: 1894 Duration: 0:00:09.714715 Num steps: 759 Reward: 13.0 Training time per step: 0.010 Avg Reward (Last 100): 21.931 Epsilon: 0.100\n",
      "Episode: 1895 Duration: 0:00:18.763911 Num steps: 1468 Reward: 28.0 Training time per step: 0.010 Avg Reward (Last 100): 21.802 Epsilon: 0.100\n",
      "Episode: 1896 Duration: 0:00:12.961970 Num steps: 1011 Reward: 17.0 Training time per step: 0.010 Avg Reward (Last 100): 21.752 Epsilon: 0.100\n",
      "Episode: 1897 Duration: 0:00:13.959598 Num steps: 1089 Reward: 27.0 Training time per step: 0.010 Avg Reward (Last 100): 21.693 Epsilon: 0.100\n",
      "Episode: 1898 Duration: 0:00:10.932255 Num steps: 856 Reward: 19.0 Training time per step: 0.010 Avg Reward (Last 100): 21.703 Epsilon: 0.100\n",
      "Copied model parameters to target network. total_t = 750000, period = 10000\n",
      "Episode: 1899 Duration: 0:00:25.144212 Num steps: 1931 Reward: 51.0 Training time per step: 0.010 Avg Reward (Last 100): 22.030 Epsilon: 0.100\n",
      "Episode: 1900 Duration: 0:00:17.133651 Num steps: 1346 Reward: 30.0 Training time per step: 0.010 Avg Reward (Last 100): 22.188 Epsilon: 0.100\n",
      "Episode: 1901 Duration: 0:00:09.441214 Num steps: 740 Reward: 20.0 Training time per step: 0.010 Avg Reward (Last 100): 22.198 Epsilon: 0.100\n",
      "Episode: 1902 Duration: 0:00:10.882091 Num steps: 852 Reward: 13.0 Training time per step: 0.010 Avg Reward (Last 100): 22.079 Epsilon: 0.100\n",
      "Episode: 1903 Duration: 0:00:15.647089 Num steps: 1221 Reward: 26.0 Training time per step: 0.010 Avg Reward (Last 100): 22.089 Epsilon: 0.100\n",
      "Episode: 1904 Duration: 0:00:15.990589 Num steps: 1249 Reward: 24.0 Training time per step: 0.010 Avg Reward (Last 100): 22.168 Epsilon: 0.100\n",
      "Episode: 1905 Duration: 0:00:19.691515 Num steps: 1541 Reward: 39.0 Training time per step: 0.010 Avg Reward (Last 100): 22.347 Epsilon: 0.100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1906 Duration: 0:00:12.588806 Num steps: 984 Reward: 34.0 Training time per step: 0.010 Avg Reward (Last 100): 22.505 Epsilon: 0.100\n",
      "Episode: 1907 Duration: 0:00:08.955004 Num steps: 703 Reward: 11.0 Training time per step: 0.010 Avg Reward (Last 100): 22.297 Epsilon: 0.100\n",
      "Copied model parameters to target network. total_t = 760000, period = 10000\n",
      "Episode: 1908 Duration: 0:00:12.219150 Num steps: 925 Reward: 19.0 Training time per step: 0.010 Avg Reward (Last 100): 22.248 Epsilon: 0.100\n",
      "Episode: 1909 Duration: 0:00:15.979255 Num steps: 1246 Reward: 32.0 Training time per step: 0.010 Avg Reward (Last 100): 22.228 Epsilon: 0.100\n",
      "Episode: 1910 Duration: 0:00:18.331834 Num steps: 1432 Reward: 37.0 Training time per step: 0.010 Avg Reward (Last 100): 22.327 Epsilon: 0.100\n",
      "Episode: 1911 Duration: 0:00:10.551604 Num steps: 824 Reward: 13.0 Training time per step: 0.010 Avg Reward (Last 100): 22.218 Epsilon: 0.100\n",
      "Episode: 1912 Duration: 0:00:10.209470 Num steps: 802 Reward: 16.0 Training time per step: 0.010 Avg Reward (Last 100): 22.109 Epsilon: 0.100\n",
      "Episode: 1913 Duration: 0:00:12.877193 Num steps: 837 Reward: 14.0 Training time per step: 0.012 Avg Reward (Last 100): 22.000 Epsilon: 0.100\n",
      "Episode: 1914 Duration: 0:00:12.005811 Num steps: 929 Reward: 17.0 Training time per step: 0.010 Avg Reward (Last 100): 22.050 Epsilon: 0.100\n",
      "Episode: 1915 Duration: 0:00:09.353732 Num steps: 728 Reward: 12.0 Training time per step: 0.010 Avg Reward (Last 100): 21.990 Epsilon: 0.100\n",
      "Episode: 1916 Duration: 0:00:18.338006 Num steps: 1423 Reward: 39.0 Training time per step: 0.010 Avg Reward (Last 100): 22.089 Epsilon: 0.100\n",
      "Episode: 1917 Duration: 0:00:17.030593 Num steps: 1324 Reward: 21.0 Training time per step: 0.010 Avg Reward (Last 100): 22.089 Epsilon: 0.100\n",
      "Copied model parameters to target network. total_t = 770000, period = 10000\n",
      "Episode: 1918 Duration: 0:00:11.667372 Num steps: 872 Reward: 13.0 Training time per step: 0.010 Avg Reward (Last 100): 21.911 Epsilon: 0.100\n",
      "Episode: 1919 Duration: 0:00:15.473011 Num steps: 1205 Reward: 36.0 Training time per step: 0.010 Avg Reward (Last 100): 22.089 Epsilon: 0.100\n",
      "Episode: 1920 Duration: 0:00:16.845452 Num steps: 1312 Reward: 27.0 Training time per step: 0.010 Avg Reward (Last 100): 22.119 Epsilon: 0.100\n",
      "Episode: 1921 Duration: 0:00:14.999819 Num steps: 1166 Reward: 23.0 Training time per step: 0.010 Avg Reward (Last 100): 22.198 Epsilon: 0.100\n",
      "Episode: 1922 Duration: 0:00:12.157056 Num steps: 942 Reward: 23.0 Training time per step: 0.010 Avg Reward (Last 100): 22.218 Epsilon: 0.100\n",
      "Episode: 1923 Duration: 0:00:18.198940 Num steps: 1413 Reward: 43.0 Training time per step: 0.010 Avg Reward (Last 100): 22.436 Epsilon: 0.100\n",
      "Episode: 1924 Duration: 0:00:23.814640 Num steps: 1848 Reward: 50.0 Training time per step: 0.010 Avg Reward (Last 100): 22.733 Epsilon: 0.100\n",
      "Episode: 1925 Duration: 0:00:13.538682 Num steps: 1045 Reward: 21.0 Training time per step: 0.010 Avg Reward (Last 100): 22.723 Epsilon: 0.100\n",
      "Copied model parameters to target network. total_t = 780000, period = 10000\n",
      "Episode: 1926 Duration: 0:00:14.096663 Num steps: 1055 Reward: 19.0 Training time per step: 0.010 Avg Reward (Last 100): 22.802 Epsilon: 0.100\n",
      "Episode: 1927 Duration: 0:00:12.371639 Num steps: 960 Reward: 23.0 Training time per step: 0.010 Avg Reward (Last 100): 22.802 Epsilon: 0.100\n",
      "Episode: 1928 Duration: 0:00:12.486424 Num steps: 973 Reward: 22.0 Training time per step: 0.010 Avg Reward (Last 100): 22.733 Epsilon: 0.100\n",
      "Episode: 1929 Duration: 0:00:13.842866 Num steps: 1077 Reward: 25.0 Training time per step: 0.010 Avg Reward (Last 100): 22.782 Epsilon: 0.100\n",
      "Episode: 1930 Duration: 0:00:12.638122 Num steps: 980 Reward: 23.0 Training time per step: 0.010 Avg Reward (Last 100): 22.634 Epsilon: 0.100\n",
      "Episode: 1931 Duration: 0:00:20.488378 Num steps: 1593 Reward: 37.0 Training time per step: 0.010 Avg Reward (Last 100): 22.634 Epsilon: 0.100\n",
      "Episode: 1932 Duration: 0:00:14.766866 Num steps: 1149 Reward: 27.0 Training time per step: 0.010 Avg Reward (Last 100): 22.713 Epsilon: 0.100\n",
      "Episode: 1933 Duration: 0:00:19.885652 Num steps: 1550 Reward: 31.0 Training time per step: 0.010 Avg Reward (Last 100): 22.752 Epsilon: 0.100\n",
      "Copied model parameters to target network. total_t = 790000, period = 10000\n",
      "Episode: 1934 Duration: 0:00:21.165655 Num steps: 1606 Reward: 41.0 Training time per step: 0.010 Avg Reward (Last 100): 23.010 Epsilon: 0.100\n",
      "Episode: 1935 Duration: 0:00:09.797039 Num steps: 761 Reward: 18.0 Training time per step: 0.010 Avg Reward (Last 100): 22.851 Epsilon: 0.100\n",
      "Episode: 1936 Duration: 0:00:21.403751 Num steps: 1667 Reward: 44.0 Training time per step: 0.010 Avg Reward (Last 100): 23.020 Epsilon: 0.100\n",
      "Episode: 1937 Duration: 0:00:11.636626 Num steps: 903 Reward: 15.0 Training time per step: 0.010 Avg Reward (Last 100): 22.970 Epsilon: 0.100\n",
      "Episode: 1938 Duration: 0:00:11.179475 Num steps: 869 Reward: 26.0 Training time per step: 0.010 Avg Reward (Last 100): 23.000 Epsilon: 0.100\n",
      "Episode: 1939 Duration: 0:00:11.159144 Num steps: 865 Reward: 15.0 Training time per step: 0.010 Avg Reward (Last 100): 22.941 Epsilon: 0.100\n",
      "Episode: 1940 Duration: 0:00:09.594615 Num steps: 741 Reward: 13.0 Training time per step: 0.010 Avg Reward (Last 100): 22.891 Epsilon: 0.100\n",
      "Episode: 1941 Duration: 0:00:09.513192 Num steps: 739 Reward: 15.0 Training time per step: 0.010 Avg Reward (Last 100): 22.822 Epsilon: 0.100\n",
      "Episode: 1942 Duration: 0:00:21.729228 Num steps: 1688 Reward: 45.0 Training time per step: 0.010 Avg Reward (Last 100): 23.050 Epsilon: 0.100\n",
      "Copied model parameters to target network. total_t = 800000, period = 10000\n",
      "Episode: 1943 Duration: 0:00:17.901920 Num steps: 1352 Reward: 27.0 Training time per step: 0.010 Avg Reward (Last 100): 22.921 Epsilon: 0.100\n",
      "Episode: 1944 Duration: 0:00:10.747576 Num steps: 833 Reward: 14.0 Training time per step: 0.010 Avg Reward (Last 100): 22.950 Epsilon: 0.100\n",
      "Episode: 1945 Duration: 0:00:12.390653 Num steps: 964 Reward: 17.0 Training time per step: 0.010 Avg Reward (Last 100): 23.020 Epsilon: 0.100\n",
      "Episode: 1946 Duration: 0:00:14.385693 Num steps: 1121 Reward: 24.0 Training time per step: 0.010 Avg Reward (Last 100): 23.089 Epsilon: 0.100\n",
      "Episode: 1947 Duration: 0:00:08.210218 Num steps: 637 Reward: 17.0 Training time per step: 0.010 Avg Reward (Last 100): 22.950 Epsilon: 0.100\n",
      "Episode: 1948 Duration: 0:00:10.768430 Num steps: 837 Reward: 15.0 Training time per step: 0.010 Avg Reward (Last 100): 22.842 Epsilon: 0.100\n",
      "Episode: 1949 Duration: 0:00:18.543611 Num steps: 1444 Reward: 39.0 Training time per step: 0.010 Avg Reward (Last 100): 23.020 Epsilon: 0.100\n",
      "Episode: 1950 Duration: 0:00:10.268196 Num steps: 800 Reward: 20.0 Training time per step: 0.010 Avg Reward (Last 100): 23.139 Epsilon: 0.100\n",
      "Episode: 1951 Duration: 0:00:12.478104 Num steps: 970 Reward: 23.0 Training time per step: 0.010 Avg Reward (Last 100): 23.287 Epsilon: 0.100\n",
      "Episode: 1952 Duration: 0:00:11.186233 Num steps: 869 Reward: 30.0 Training time per step: 0.010 Avg Reward (Last 100): 23.238 Epsilon: 0.100\n",
      "Episode: 1953 Duration: 0:00:09.959277 Num steps: 772 Reward: 19.0 Training time per step: 0.010 Avg Reward (Last 100): 23.010 Epsilon: 0.100\n",
      "Copied model parameters to target network. total_t = 810000, period = 10000\n",
      "Episode: 1954 Duration: 0:00:20.056355 Num steps: 1520 Reward: 37.0 Training time per step: 0.010 Avg Reward (Last 100): 23.040 Epsilon: 0.100\n",
      "Episode: 1955 Duration: 0:00:13.288674 Num steps: 1035 Reward: 20.0 Training time per step: 0.010 Avg Reward (Last 100): 23.089 Epsilon: 0.100\n",
      "Episode: 1956 Duration: 0:00:14.497815 Num steps: 1126 Reward: 19.0 Training time per step: 0.010 Avg Reward (Last 100): 23.020 Epsilon: 0.100\n",
      "Episode: 1957 Duration: 0:00:13.495941 Num steps: 1050 Reward: 19.0 Training time per step: 0.010 Avg Reward (Last 100): 23.000 Epsilon: 0.100\n",
      "Episode: 1958 Duration: 0:00:14.643588 Num steps: 1139 Reward: 26.0 Training time per step: 0.010 Avg Reward (Last 100): 23.099 Epsilon: 0.100\n",
      "Episode: 1959 Duration: 0:00:13.453278 Num steps: 1046 Reward: 27.0 Training time per step: 0.010 Avg Reward (Last 100): 23.248 Epsilon: 0.100\n",
      "Episode: 1960 Duration: 0:00:11.514120 Num steps: 895 Reward: 19.0 Training time per step: 0.010 Avg Reward (Last 100): 23.129 Epsilon: 0.100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1961 Duration: 0:00:13.688556 Num steps: 1061 Reward: 27.0 Training time per step: 0.010 Avg Reward (Last 100): 23.277 Epsilon: 0.100\n",
      "Episode: 1962 Duration: 0:00:09.722973 Num steps: 757 Reward: 11.0 Training time per step: 0.010 Avg Reward (Last 100): 23.119 Epsilon: 0.100\n",
      "Copied model parameters to target network. total_t = 820000, period = 10000\n",
      "Episode: 1963 Duration: 0:00:14.344877 Num steps: 1083 Reward: 21.0 Training time per step: 0.010 Avg Reward (Last 100): 23.158 Epsilon: 0.100\n",
      "Episode: 1964 Duration: 0:00:18.074968 Num steps: 1404 Reward: 39.0 Training time per step: 0.010 Avg Reward (Last 100): 23.426 Epsilon: 0.100\n",
      "Episode: 1965 Duration: 0:00:14.003575 Num steps: 1087 Reward: 26.0 Training time per step: 0.010 Avg Reward (Last 100): 23.436 Epsilon: 0.100\n",
      "Episode: 1966 Duration: 0:00:15.149287 Num steps: 1177 Reward: 28.0 Training time per step: 0.010 Avg Reward (Last 100): 23.525 Epsilon: 0.100\n",
      "Episode: 1967 Duration: 0:00:09.085554 Num steps: 705 Reward: 12.0 Training time per step: 0.010 Avg Reward (Last 100): 23.347 Epsilon: 0.100\n",
      "Episode: 1968 Duration: 0:00:13.361033 Num steps: 1040 Reward: 26.0 Training time per step: 0.010 Avg Reward (Last 100): 23.376 Epsilon: 0.100\n",
      "Episode: 1969 Duration: 0:00:13.583521 Num steps: 1056 Reward: 29.0 Training time per step: 0.010 Avg Reward (Last 100): 23.525 Epsilon: 0.100\n",
      "Episode: 1970 Duration: 0:00:17.396866 Num steps: 1348 Reward: 30.0 Training time per step: 0.010 Avg Reward (Last 100): 23.614 Epsilon: 0.100\n",
      "Episode: 1971 Duration: 0:00:19.501220 Num steps: 1514 Reward: 49.0 Training time per step: 0.010 Avg Reward (Last 100): 23.683 Epsilon: 0.100\n",
      "Copied model parameters to target network. total_t = 830000, period = 10000\n",
      "Episode: 1972 Duration: 0:00:18.403561 Num steps: 1396 Reward: 40.0 Training time per step: 0.010 Avg Reward (Last 100): 23.851 Epsilon: 0.100\n",
      "Episode: 1973 Duration: 0:00:12.973404 Num steps: 1010 Reward: 17.0 Training time per step: 0.010 Avg Reward (Last 100): 23.851 Epsilon: 0.100\n",
      "Episode: 1974 Duration: 0:00:13.678721 Num steps: 1062 Reward: 20.0 Training time per step: 0.010 Avg Reward (Last 100): 23.891 Epsilon: 0.100\n",
      "Episode: 1975 Duration: 0:00:10.971868 Num steps: 853 Reward: 13.0 Training time per step: 0.010 Avg Reward (Last 100): 23.842 Epsilon: 0.100\n",
      "Episode: 1976 Duration: 0:00:12.317395 Num steps: 958 Reward: 21.0 Training time per step: 0.010 Avg Reward (Last 100): 23.960 Epsilon: 0.100\n",
      "Episode: 1977 Duration: 0:00:14.592934 Num steps: 1134 Reward: 27.0 Training time per step: 0.010 Avg Reward (Last 100): 24.040 Epsilon: 0.100\n",
      "Episode: 1978 Duration: 0:00:14.841085 Num steps: 1153 Reward: 24.0 Training time per step: 0.010 Avg Reward (Last 100): 24.119 Epsilon: 0.100\n",
      "Episode: 1979 Duration: 0:00:13.879519 Num steps: 1079 Reward: 23.0 Training time per step: 0.010 Avg Reward (Last 100): 24.198 Epsilon: 0.100\n",
      "Episode: 1980 Duration: 0:00:20.968447 Num steps: 1631 Reward: 40.0 Training time per step: 0.010 Avg Reward (Last 100): 24.366 Epsilon: 0.100\n",
      "Copied model parameters to target network. total_t = 840000, period = 10000\n",
      "Episode: 1981 Duration: 0:00:13.213199 Num steps: 994 Reward: 17.0 Training time per step: 0.010 Avg Reward (Last 100): 24.277 Epsilon: 0.100\n",
      "Episode: 1982 Duration: 0:00:11.417507 Num steps: 888 Reward: 16.0 Training time per step: 0.010 Avg Reward (Last 100): 24.307 Epsilon: 0.100\n",
      "Episode: 1983 Duration: 0:00:23.576544 Num steps: 1833 Reward: 48.0 Training time per step: 0.010 Avg Reward (Last 100): 24.515 Epsilon: 0.100\n",
      "Episode: 1984 Duration: 0:00:14.673067 Num steps: 1140 Reward: 27.0 Training time per step: 0.010 Avg Reward (Last 100): 24.614 Epsilon: 0.100\n",
      "Episode: 1985 Duration: 0:00:16.417560 Num steps: 1275 Reward: 32.0 Training time per step: 0.010 Avg Reward (Last 100): 24.693 Epsilon: 0.100\n",
      "Episode: 1986 Duration: 0:00:21.246600 Num steps: 1647 Reward: 41.0 Training time per step: 0.010 Avg Reward (Last 100): 24.851 Epsilon: 0.100\n",
      "Episode: 1987 Duration: 0:00:10.926638 Num steps: 848 Reward: 20.0 Training time per step: 0.010 Avg Reward (Last 100): 24.832 Epsilon: 0.100\n",
      "Episode: 1988 Duration: 0:00:09.151565 Num steps: 713 Reward: 16.0 Training time per step: 0.010 Avg Reward (Last 100): 24.772 Epsilon: 0.100\n",
      "Copied model parameters to target network. total_t = 850000, period = 10000\n",
      "Episode: 1989 Duration: 0:00:15.573919 Num steps: 1178 Reward: 24.0 Training time per step: 0.010 Avg Reward (Last 100): 24.842 Epsilon: 0.100\n",
      "Episode: 1990 Duration: 0:00:17.056078 Num steps: 1326 Reward: 42.0 Training time per step: 0.010 Avg Reward (Last 100): 25.119 Epsilon: 0.100\n",
      "Episode: 1991 Duration: 0:00:20.256163 Num steps: 1575 Reward: 39.0 Training time per step: 0.010 Avg Reward (Last 100): 25.287 Epsilon: 0.100\n",
      "Episode: 1992 Duration: 0:00:13.176021 Num steps: 1024 Reward: 32.0 Training time per step: 0.010 Avg Reward (Last 100): 25.406 Epsilon: 0.100\n",
      "Episode: 1993 Duration: 0:00:12.312740 Num steps: 958 Reward: 18.0 Training time per step: 0.010 Avg Reward (Last 100): 25.386 Epsilon: 0.100\n",
      "Episode: 1994 Duration: 0:00:15.107393 Num steps: 1173 Reward: 23.0 Training time per step: 0.010 Avg Reward (Last 100): 25.515 Epsilon: 0.100\n",
      "Episode: 1995 Duration: 0:00:17.828017 Num steps: 1387 Reward: 37.0 Training time per step: 0.010 Avg Reward (Last 100): 25.752 Epsilon: 0.100\n",
      "Episode: 1996 Duration: 0:00:11.588113 Num steps: 900 Reward: 16.0 Training time per step: 0.010 Avg Reward (Last 100): 25.634 Epsilon: 0.100\n",
      "Copied model parameters to target network. total_t = 860000, period = 10000\n",
      "Episode: 1997 Duration: 0:00:23.819250 Num steps: 1818 Reward: 45.0 Training time per step: 0.010 Avg Reward (Last 100): 25.911 Epsilon: 0.100\n",
      "Episode: 1998 Duration: 0:00:13.805090 Num steps: 1070 Reward: 20.0 Training time per step: 0.010 Avg Reward (Last 100): 25.842 Epsilon: 0.100\n",
      "Episode: 1999 Duration: 0:00:10.627045 Num steps: 828 Reward: 17.0 Training time per step: 0.010 Avg Reward (Last 100): 25.822 Epsilon: 0.100\n",
      "Episode: 2000 Duration: 0:00:13.526034 Num steps: 1049 Reward: 22.0 Training time per step: 0.010 Avg Reward (Last 100): 25.535 Epsilon: 0.100\n",
      "Episode: 2001 Duration: 0:00:13.238287 Num steps: 1030 Reward: 16.0 Training time per step: 0.010 Avg Reward (Last 100): 25.396 Epsilon: 0.100\n",
      "Episode: 2002 Duration: 0:00:11.420880 Num steps: 884 Reward: 21.0 Training time per step: 0.010 Avg Reward (Last 100): 25.406 Epsilon: 0.100\n",
      "Episode: 2003 Duration: 0:00:14.035312 Num steps: 1093 Reward: 32.0 Training time per step: 0.010 Avg Reward (Last 100): 25.594 Epsilon: 0.100\n",
      "Episode: 2004 Duration: 0:00:14.690519 Num steps: 1141 Reward: 25.0 Training time per step: 0.010 Avg Reward (Last 100): 25.584 Epsilon: 0.100\n",
      "Episode: 2005 Duration: 0:00:10.902530 Num steps: 845 Reward: 14.0 Training time per step: 0.010 Avg Reward (Last 100): 25.485 Epsilon: 0.100\n",
      "Copied model parameters to target network. total_t = 870000, period = 10000\n",
      "Episode: 2006 Duration: 0:00:25.258943 Num steps: 1928 Reward: 45.0 Training time per step: 0.010 Avg Reward (Last 100): 25.545 Epsilon: 0.100\n",
      "Episode: 2007 Duration: 0:00:11.834463 Num steps: 918 Reward: 19.0 Training time per step: 0.010 Avg Reward (Last 100): 25.396 Epsilon: 0.100\n",
      "Episode: 2008 Duration: 0:00:08.595348 Num steps: 667 Reward: 11.0 Training time per step: 0.010 Avg Reward (Last 100): 25.396 Epsilon: 0.100\n",
      "Episode: 2009 Duration: 0:00:17.809592 Num steps: 1383 Reward: 35.0 Training time per step: 0.010 Avg Reward (Last 100): 25.554 Epsilon: 0.100\n",
      "Episode: 2010 Duration: 0:00:18.118996 Num steps: 1405 Reward: 38.0 Training time per step: 0.010 Avg Reward (Last 100): 25.614 Epsilon: 0.100\n",
      "Episode: 2011 Duration: 0:00:17.132471 Num steps: 1333 Reward: 46.0 Training time per step: 0.010 Avg Reward (Last 100): 25.703 Epsilon: 0.100\n",
      "Episode: 2012 Duration: 0:00:11.541836 Num steps: 896 Reward: 30.0 Training time per step: 0.010 Avg Reward (Last 100): 25.871 Epsilon: 0.100\n",
      "Episode: 2013 Duration: 0:00:16.117338 Num steps: 1251 Reward: 24.0 Training time per step: 0.010 Avg Reward (Last 100): 25.950 Epsilon: 0.100\n",
      "Episode: 2014 Duration: 0:00:16.398589 Num steps: 1269 Reward: 36.0 Training time per step: 0.010 Avg Reward (Last 100): 26.168 Epsilon: 0.100\n",
      "Copied model parameters to target network. total_t = 880000, period = 10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 2015 Duration: 0:00:18.549825 Num steps: 1406 Reward: 34.0 Training time per step: 0.010 Avg Reward (Last 100): 26.337 Epsilon: 0.100\n",
      "Episode: 2016 Duration: 0:00:19.625550 Num steps: 1526 Reward: 35.0 Training time per step: 0.010 Avg Reward (Last 100): 26.564 Epsilon: 0.100\n",
      "Episode: 2017 Duration: 0:00:13.378748 Num steps: 1042 Reward: 17.0 Training time per step: 0.010 Avg Reward (Last 100): 26.347 Epsilon: 0.100\n",
      "Episode: 2018 Duration: 0:00:16.488992 Num steps: 1280 Reward: 40.0 Training time per step: 0.010 Avg Reward (Last 100): 26.535 Epsilon: 0.100\n",
      "Episode: 2019 Duration: 0:00:14.927117 Num steps: 1160 Reward: 29.0 Training time per step: 0.010 Avg Reward (Last 100): 26.693 Epsilon: 0.100\n",
      "Episode: 2020 Duration: 0:00:09.041398 Num steps: 704 Reward: 14.0 Training time per step: 0.010 Avg Reward (Last 100): 26.475 Epsilon: 0.100\n",
      "Episode: 2021 Duration: 0:00:14.166178 Num steps: 1101 Reward: 23.0 Training time per step: 0.010 Avg Reward (Last 100): 26.436 Epsilon: 0.100\n",
      "Episode: 2022 Duration: 0:00:17.145100 Num steps: 1335 Reward: 31.0 Training time per step: 0.010 Avg Reward (Last 100): 26.515 Epsilon: 0.100\n",
      "Copied model parameters to target network. total_t = 890000, period = 10000\n",
      "Episode: 2023 Duration: 0:00:19.986129 Num steps: 1515 Reward: 36.0 Training time per step: 0.010 Avg Reward (Last 100): 26.644 Epsilon: 0.100\n",
      "Episode: 2024 Duration: 0:00:11.944772 Num steps: 929 Reward: 16.0 Training time per step: 0.010 Avg Reward (Last 100): 26.376 Epsilon: 0.100\n",
      "Episode: 2025 Duration: 0:00:15.961745 Num steps: 1241 Reward: 23.0 Training time per step: 0.010 Avg Reward (Last 100): 26.109 Epsilon: 0.100\n",
      "Episode: 2026 Duration: 0:00:18.825976 Num steps: 1461 Reward: 43.0 Training time per step: 0.010 Avg Reward (Last 100): 26.327 Epsilon: 0.100\n",
      "Episode: 2027 Duration: 0:00:12.700224 Num steps: 989 Reward: 27.0 Training time per step: 0.010 Avg Reward (Last 100): 26.406 Epsilon: 0.100\n",
      "Episode: 2028 Duration: 0:00:18.813260 Num steps: 1462 Reward: 35.0 Training time per step: 0.010 Avg Reward (Last 100): 26.525 Epsilon: 0.100\n",
      "Episode: 2029 Duration: 0:00:17.681109 Num steps: 1374 Reward: 35.0 Training time per step: 0.010 Avg Reward (Last 100): 26.653 Epsilon: 0.100\n",
      "Episode: 2030 Duration: 0:00:15.031967 Num steps: 1169 Reward: 46.0 Training time per step: 0.010 Avg Reward (Last 100): 26.861 Epsilon: 0.100\n",
      "Copied model parameters to target network. total_t = 900000, period = 10000\n",
      "Episode: 2031 Duration: 0:00:13.983256 Num steps: 1048 Reward: 23.0 Training time per step: 0.010 Avg Reward (Last 100): 26.861 Epsilon: 0.100\n",
      "Episode: 2032 Duration: 0:00:13.022437 Num steps: 1015 Reward: 21.0 Training time per step: 0.010 Avg Reward (Last 100): 26.703 Epsilon: 0.100\n",
      "Episode: 2033 Duration: 0:00:18.021837 Num steps: 1402 Reward: 28.0 Training time per step: 0.010 Avg Reward (Last 100): 26.713 Epsilon: 0.100\n",
      "Episode: 2034 Duration: 0:00:16.653427 Num steps: 1298 Reward: 28.0 Training time per step: 0.010 Avg Reward (Last 100): 26.683 Epsilon: 0.100\n",
      "Episode: 2035 Duration: 0:00:16.426852 Num steps: 1282 Reward: 31.0 Training time per step: 0.010 Avg Reward (Last 100): 26.584 Epsilon: 0.100\n",
      "Episode: 2036 Duration: 0:00:17.105365 Num steps: 1330 Reward: 33.0 Training time per step: 0.010 Avg Reward (Last 100): 26.733 Epsilon: 0.100\n",
      "Episode: 2037 Duration: 0:00:12.797611 Num steps: 994 Reward: 19.0 Training time per step: 0.010 Avg Reward (Last 100): 26.485 Epsilon: 0.100\n",
      "Episode: 2038 Duration: 0:00:08.428876 Num steps: 656 Reward: 14.0 Training time per step: 0.010 Avg Reward (Last 100): 26.475 Epsilon: 0.100\n",
      "Episode: 2039 Duration: 0:00:16.055841 Num steps: 1248 Reward: 19.0 Training time per step: 0.010 Avg Reward (Last 100): 26.406 Epsilon: 0.100\n",
      "Copied model parameters to target network. total_t = 910000, period = 10000\n",
      "Episode: 2040 Duration: 0:00:20.561121 Num steps: 1564 Reward: 34.0 Training time per step: 0.010 Avg Reward (Last 100): 26.594 Epsilon: 0.100\n",
      "Episode: 2041 Duration: 0:00:19.129953 Num steps: 1494 Reward: 34.0 Training time per step: 0.010 Avg Reward (Last 100): 26.802 Epsilon: 0.100\n",
      "Episode: 2042 Duration: 0:00:16.399921 Num steps: 1276 Reward: 32.0 Training time per step: 0.010 Avg Reward (Last 100): 26.970 Epsilon: 0.100\n",
      "Episode: 2043 Duration: 0:00:11.976703 Num steps: 934 Reward: 17.0 Training time per step: 0.010 Avg Reward (Last 100): 26.693 Epsilon: 0.100\n",
      "Episode: 2044 Duration: 0:00:09.204814 Num steps: 713 Reward: 15.0 Training time per step: 0.010 Avg Reward (Last 100): 26.574 Epsilon: 0.100\n",
      "Episode: 2045 Duration: 0:00:13.601876 Num steps: 1054 Reward: 26.0 Training time per step: 0.010 Avg Reward (Last 100): 26.693 Epsilon: 0.100\n",
      "Episode: 2046 Duration: 0:00:16.377940 Num steps: 1273 Reward: 30.0 Training time per step: 0.010 Avg Reward (Last 100): 26.822 Epsilon: 0.100\n",
      "Episode: 2047 Duration: 0:00:16.888252 Num steps: 1317 Reward: 38.0 Training time per step: 0.010 Avg Reward (Last 100): 26.960 Epsilon: 0.100\n",
      "Copied model parameters to target network. total_t = 920000, period = 10000\n",
      "Episode: 2048 Duration: 0:00:21.405795 Num steps: 1631 Reward: 51.0 Training time per step: 0.010 Avg Reward (Last 100): 27.297 Epsilon: 0.100\n",
      "Episode: 2049 Duration: 0:00:12.118679 Num steps: 941 Reward: 21.0 Training time per step: 0.010 Avg Reward (Last 100): 27.356 Epsilon: 0.100\n",
      "Episode: 2050 Duration: 0:00:08.126441 Num steps: 634 Reward: 10.0 Training time per step: 0.010 Avg Reward (Last 100): 27.069 Epsilon: 0.100\n",
      "Episode: 2051 Duration: 0:00:16.108768 Num steps: 1254 Reward: 21.0 Training time per step: 0.010 Avg Reward (Last 100): 27.079 Epsilon: 0.100\n",
      "Episode: 2052 Duration: 0:00:08.579205 Num steps: 670 Reward: 10.0 Training time per step: 0.010 Avg Reward (Last 100): 26.950 Epsilon: 0.100\n",
      "Episode: 2053 Duration: 0:00:13.364779 Num steps: 1038 Reward: 25.0 Training time per step: 0.010 Avg Reward (Last 100): 26.901 Epsilon: 0.100\n",
      "Episode: 2054 Duration: 0:00:07.555080 Num steps: 590 Reward: 8.0 Training time per step: 0.010 Avg Reward (Last 100): 26.792 Epsilon: 0.100\n",
      "Episode: 2055 Duration: 0:00:14.762654 Num steps: 1147 Reward: 22.0 Training time per step: 0.010 Avg Reward (Last 100): 26.644 Epsilon: 0.100\n",
      "Episode: 2056 Duration: 0:00:11.571368 Num steps: 902 Reward: 17.0 Training time per step: 0.010 Avg Reward (Last 100): 26.614 Epsilon: 0.100\n",
      "Episode: 2057 Duration: 0:00:10.998434 Num steps: 855 Reward: 17.0 Training time per step: 0.010 Avg Reward (Last 100): 26.594 Epsilon: 0.100\n",
      "Copied model parameters to target network. total_t = 930000, period = 10000\n",
      "Episode: 2058 Duration: 0:00:17.302803 Num steps: 1306 Reward: 32.0 Training time per step: 0.010 Avg Reward (Last 100): 26.723 Epsilon: 0.100\n",
      "Episode: 2059 Duration: 0:00:14.402780 Num steps: 1120 Reward: 23.0 Training time per step: 0.010 Avg Reward (Last 100): 26.693 Epsilon: 0.100\n",
      "Episode: 2060 Duration: 0:00:09.993104 Num steps: 777 Reward: 16.0 Training time per step: 0.010 Avg Reward (Last 100): 26.584 Epsilon: 0.100\n",
      "Episode: 2061 Duration: 0:00:19.824940 Num steps: 1545 Reward: 43.0 Training time per step: 0.010 Avg Reward (Last 100): 26.822 Epsilon: 0.100\n",
      "Episode: 2062 Duration: 0:00:13.440865 Num steps: 1045 Reward: 27.0 Training time per step: 0.010 Avg Reward (Last 100): 26.822 Epsilon: 0.100\n",
      "Episode: 2063 Duration: 0:00:14.513693 Num steps: 1127 Reward: 20.0 Training time per step: 0.010 Avg Reward (Last 100): 26.911 Epsilon: 0.100\n",
      "Episode: 2064 Duration: 0:00:16.290348 Num steps: 1271 Reward: 29.0 Training time per step: 0.010 Avg Reward (Last 100): 26.990 Epsilon: 0.100\n",
      "Episode: 2065 Duration: 0:00:12.176250 Num steps: 945 Reward: 23.0 Training time per step: 0.010 Avg Reward (Last 100): 26.832 Epsilon: 0.100\n",
      "Episode: 2066 Duration: 0:00:08.508399 Num steps: 663 Reward: 10.0 Training time per step: 0.010 Avg Reward (Last 100): 26.673 Epsilon: 0.100\n",
      "Episode: 2067 Duration: 0:00:14.309176 Num steps: 1111 Reward: 23.0 Training time per step: 0.010 Avg Reward (Last 100): 26.624 Epsilon: 0.100\n",
      "Copied model parameters to target network. total_t = 940000, period = 10000\n",
      "Episode: 2068 Duration: 0:00:11.159800 Num steps: 832 Reward: 20.0 Training time per step: 0.010 Avg Reward (Last 100): 26.703 Epsilon: 0.100\n",
      "Episode: 2069 Duration: 0:00:14.910274 Num steps: 1161 Reward: 27.0 Training time per step: 0.010 Avg Reward (Last 100): 26.713 Epsilon: 0.100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 2070 Duration: 0:00:13.684662 Num steps: 1064 Reward: 21.0 Training time per step: 0.010 Avg Reward (Last 100): 26.634 Epsilon: 0.100\n",
      "Episode: 2071 Duration: 0:00:16.947446 Num steps: 1313 Reward: 39.0 Training time per step: 0.010 Avg Reward (Last 100): 26.723 Epsilon: 0.100\n",
      "Episode: 2072 Duration: 0:00:12.281502 Num steps: 954 Reward: 21.0 Training time per step: 0.010 Avg Reward (Last 100): 26.446 Epsilon: 0.100\n",
      "Episode: 2073 Duration: 0:00:10.250245 Num steps: 798 Reward: 16.0 Training time per step: 0.010 Avg Reward (Last 100): 26.208 Epsilon: 0.100\n",
      "Episode: 2074 Duration: 0:00:08.934188 Num steps: 696 Reward: 14.0 Training time per step: 0.010 Avg Reward (Last 100): 26.178 Epsilon: 0.100\n",
      "Episode: 2075 Duration: 0:00:11.916310 Num steps: 925 Reward: 18.0 Training time per step: 0.010 Avg Reward (Last 100): 26.158 Epsilon: 0.100\n",
      "Episode: 2076 Duration: 0:00:11.963178 Num steps: 928 Reward: 16.0 Training time per step: 0.010 Avg Reward (Last 100): 26.188 Epsilon: 0.100\n",
      "Episode: 2077 Duration: 0:00:12.169674 Num steps: 945 Reward: 22.0 Training time per step: 0.010 Avg Reward (Last 100): 26.198 Epsilon: 0.100\n",
      "Episode: 2078 Duration: 0:00:07.401825 Num steps: 574 Reward: 11.0 Training time per step: 0.010 Avg Reward (Last 100): 26.040 Epsilon: 0.100\n",
      "Copied model parameters to target network. total_t = 950000, period = 10000\n",
      "Episode: 2079 Duration: 0:00:11.438472 Num steps: 854 Reward: 17.0 Training time per step: 0.010 Avg Reward (Last 100): 25.970 Epsilon: 0.100\n",
      "Episode: 2080 Duration: 0:00:13.370145 Num steps: 1043 Reward: 39.0 Training time per step: 0.010 Avg Reward (Last 100): 26.129 Epsilon: 0.100\n",
      "Episode: 2081 Duration: 0:00:11.730138 Num steps: 913 Reward: 16.0 Training time per step: 0.010 Avg Reward (Last 100): 25.891 Epsilon: 0.100\n",
      "Episode: 2082 Duration: 0:00:14.435310 Num steps: 1123 Reward: 17.0 Training time per step: 0.010 Avg Reward (Last 100): 25.891 Epsilon: 0.100\n",
      "Episode: 2083 Duration: 0:00:15.597016 Num steps: 1216 Reward: 27.0 Training time per step: 0.010 Avg Reward (Last 100): 26.000 Epsilon: 0.100\n",
      "Episode: 2084 Duration: 0:00:11.750313 Num steps: 915 Reward: 14.0 Training time per step: 0.010 Avg Reward (Last 100): 25.663 Epsilon: 0.100\n",
      "Episode: 2085 Duration: 0:00:12.228790 Num steps: 952 Reward: 22.0 Training time per step: 0.010 Avg Reward (Last 100): 25.614 Epsilon: 0.100\n",
      "Episode: 2086 Duration: 0:00:19.485469 Num steps: 1520 Reward: 40.0 Training time per step: 0.010 Avg Reward (Last 100): 25.693 Epsilon: 0.100\n",
      "Episode: 2087 Duration: 0:00:11.449514 Num steps: 891 Reward: 18.0 Training time per step: 0.010 Avg Reward (Last 100): 25.465 Epsilon: 0.100\n",
      "Copied model parameters to target network. total_t = 960000, period = 10000\n",
      "Episode: 2088 Duration: 0:00:16.900648 Num steps: 1280 Reward: 43.0 Training time per step: 0.010 Avg Reward (Last 100): 25.693 Epsilon: 0.100\n",
      "Episode: 2089 Duration: 0:00:10.280994 Num steps: 799 Reward: 13.0 Training time per step: 0.010 Avg Reward (Last 100): 25.663 Epsilon: 0.100\n",
      "Episode: 2090 Duration: 0:00:12.410737 Num steps: 969 Reward: 18.0 Training time per step: 0.010 Avg Reward (Last 100): 25.604 Epsilon: 0.100\n",
      "Episode: 2091 Duration: 0:00:08.106960 Num steps: 629 Reward: 10.0 Training time per step: 0.010 Avg Reward (Last 100): 25.287 Epsilon: 0.100\n",
      "Episode: 2092 Duration: 0:00:25.143214 Num steps: 1961 Reward: 69.0 Training time per step: 0.010 Avg Reward (Last 100): 25.584 Epsilon: 0.100\n",
      "Episode: 2093 Duration: 0:00:19.471989 Num steps: 1519 Reward: 39.0 Training time per step: 0.010 Avg Reward (Last 100): 25.653 Epsilon: 0.100\n",
      "Episode: 2094 Duration: 0:00:11.803453 Num steps: 917 Reward: 18.0 Training time per step: 0.010 Avg Reward (Last 100): 25.653 Epsilon: 0.100\n",
      "Episode: 2095 Duration: 0:00:09.991371 Num steps: 774 Reward: 12.0 Training time per step: 0.010 Avg Reward (Last 100): 25.545 Epsilon: 0.100\n",
      "Episode: 2096 Duration: 0:00:11.041797 Num steps: 859 Reward: 19.0 Training time per step: 0.010 Avg Reward (Last 100): 25.366 Epsilon: 0.100\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
